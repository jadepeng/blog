<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"blog.iflyresearch.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="JadePeng的技术笔记本">
<meta property="og:type" content="website">
<meta property="og:title" content="JadePeng的技术笔记本">
<meta property="og:url" content="http://blog.iflyresearch.com/page/7/index.html">
<meta property="og:site_name" content="JadePeng的技术笔记本">
<meta property="og:description" content="JadePeng的技术笔记本">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="JadePeng">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://blog.iflyresearch.com/page/7/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>JadePeng的技术笔记本</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">JadePeng的技术笔记本</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">爱学习爱分享</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-博客">

    <a href="/categories/%E5%8D%9A%E5%AE%A2/" rel="section"><i class="fa fa-th fa-fw"></i>博客</a>

  </li>
        <li class="menu-item menu-item-分类">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://blog.iflyresearch.com/2018/11/12/jqpeng-K8S%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="JadePeng">
      <meta itemprop="description" content="JadePeng的技术笔记本">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JadePeng的技术笔记本">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/11/12/jqpeng-K8S%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/" class="post-title-link" itemprop="url">K8S集群安装</a>
        </h2>

        <div class="post-meta">

         
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-11-12 09:18:00" itemprop="dateCreated datePublished" datetime="2018-11-12T09:18:00+08:00">2018-11-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-14 17:52:26" itemprop="dateModified" datetime="2021-05-14T17:52:26+08:00">2021-05-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%8D%9A%E5%AE%A2/" itemprop="url" rel="index"><span itemprop="name">博客</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%8D%9A%E5%AE%A2/jqpeng/" itemprop="url" rel="index"><span itemprop="name">jqpeng</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>79k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1:11</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>文章作者:jqpeng<br>原文链接: <a target="_blank" rel="noopener" href="https://www.cnblogs.com/xiaoqi/p/9944706.html">K8S集群安装</a></p>
<p>主要参考 <a target="_blank" rel="noopener" href="https://github.com/opsnull/follow-me-install-kubernetes-cluster">https://github.com/opsnull/follow-me-install-kubernetes-cluster</a></p>
<h2 id="01-系统初始化和全局变量"><a href="#01-系统初始化和全局变量" class="headerlink" title="01.系统初始化和全局变量"></a>01.系统初始化和全局变量</h2><h3 id="添加-k8s-和-docker-账户"><a href="#添加-k8s-和-docker-账户" class="headerlink" title="添加 k8s 和 docker 账户"></a>添加 k8s 和 docker 账户</h3><p>在每台机器上添加 k8s 账户，可以无密码 sudo：</p>
<pre><code>$ sudo useradd -m k8s
$ sudo visudo
$ sudo grep &#39;%wheel.*NOPASSWD: ALL&#39; /etc/sudoers
%wheel    ALL=(ALL)    NOPASSWD: ALL
$ sudo gpasswd -a k8s wheel
</code></pre>
<p>在每台机器上添加 docker 账户，将 k8s 账户添加到 docker 组中，同时配置 dockerd 参数：</p>
<pre><code>$ sudo useradd -m docker
$ sudo gpasswd -a k8s docker
$ sudo mkdir -p  /etc/docker/
$ cat /etc/docker/daemon.json
&#123;
    &quot;registry-mirrors&quot;: [&quot;https://hub-mirror.c.163.com&quot;, &quot;https://docker.mirrors.ustc.edu.cn&quot;],
    &quot;max-concurrent-downloads&quot;: 20
&#125;
</code></pre>
<h3 id="无密码-ssh-登录其它节点"><a href="#无密码-ssh-登录其它节点" class="headerlink" title="无密码 ssh 登录其它节点"></a>无密码 ssh 登录其它节点</h3><p>ssh-copy-id root@docker86-18<br> ssh-copy-id root@docker86-21<br> ssh-copy-id root@docker86-91<br> ssh-copy-id root@docker86-9</p>
<p>ssh-copy-id k8s@docker86-155<br> ssh-copy-id k8s@docker86-18<br> ssh-copy-id root@docker86-21<br> ssh-copy-id root@docker86-91<br> ssh-copy-id root@docker86-9</p>
<pre><code>source ./environment.sh
for node_ip in $&#123;NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    ssh root@$&#123;node_ip&#125; &quot;mkdir -p /opt/k8s/bin &amp;&amp; chown -R k8s /opt/k8s &amp;&amp; mkdir -p /etc/kubernetes/cert &amp;&amp;chown -R k8s /etc/kubernetes &amp;&amp; mkdir -p /etc/etcd/cert &amp;&amp; chown -R k8s /etc/etcd/cert &amp;&amp;  mkdir -p /var/lib/etcd &amp;&amp; chown -R k8s /etc/etcd/cert&quot;
    scp environment.sh k8s@$&#123;node_ip&#125;:/opt/k8s/bin/
    ssh k8s@$&#123;node_ip&#125; &quot;chmod +x /opt/k8s/bin/*&quot;
  done
</code></pre>
<h3 id="定义全局变量"><a href="#定义全局变量" class="headerlink" title="定义全局变量"></a>定义全局变量</h3><pre><code>cat &lt;&lt;EOF &gt;environment.sh 
#!/usr/bin/bash

# 生成 EncryptionConfig 所需的加密 key
ENCRYPTION_KEY=$(head -c 32 /dev/urandom | base64)

# 最好使用 当前未用的网段 来定义服务网段和 Pod 网段

# 服务网段，部署前路由不可达，部署后集群内路由可达(kube-proxy 和 ipvs 保证)
SERVICE_CIDR=&quot;10.69.0.0/16&quot;

# Pod 网段，建议 /16 段地址，部署前路由不可达，部署后集群内路由可达(flanneld 保证)
CLUSTER_CIDR=&quot;170.22.0.0/16&quot;

# 服务端口范围 (NodePort Range)
export NODE_PORT_RANGE=&quot;10000-40000&quot;

# 集群各机器 IP 数组
export NODE_IPS=(192.168.86.154 192.168.86.155 192.168.86.156 192.168.86.18 192.168.86.21 192.168.86.91 192.168.86.9)

# etcd节点
export ETCD_NODE_IPS=(192.168.86.154 192.168.86.155 192.168.86.156)

# 集群各 IP 对应的 主机名数组
export NODE_NAMES=(docker86-154 docker86-155 docker86-156 docker86-18 docker86-21 docker86-91 docker86-9)

# kube-apiserver 的 VIP（HA 组件 keepalived 发布的 IP）
export MASTER_VIP=192.168.86.214

# kube-apiserver VIP 地址（HA 组件 haproxy 监听 8443 端口）
export KUBE_APISERVER=&quot;https://$&#123;MASTER_VIP&#125;:8443&quot;

# HA 节点，配置 VIP 的网络接口名称
export VIP_IF=&quot;em1&quot;

# etcd 集群服务地址列表
export ETCD_ENDPOINTS=&quot;https://192.168.86.154:2379,https://192.168.86.155:2379,https://192.168.86.156:2379&quot;

# etcd 集群间通信的 IP 和端口
export ETCD_NODES=&quot;docker86-154=https://192.168.86.154:2380,docker86-155=https://192.168.86.155:2380,docker86-156=https://192.168.86.156:2380&quot;

# flanneld 网络配置前缀
export FLANNEL_ETCD_PREFIX=&quot;/kubernetes/network&quot;

# kubernetes 服务 IP (一般是 SERVICE_CIDR 中第一个IP)
export CLUSTER_KUBERNETES_SVC_IP=&quot;10.69.0.1&quot;

# 集群 DNS 服务 IP (从 SERVICE_CIDR 中预分配)
export CLUSTER_DNS_SVC_IP=&quot;10.69.0.2&quot;

# 集群 DNS 域名
export CLUSTER_DNS_DOMAIN=&quot;cluster.local.&quot;

# 将二进制目录 /opt/k8s/bin 加到 PATH 中
export PATH=/opt/k8s/bin:$PATH
EOF
</code></pre>
<p>然后，把全局变量定义脚本拷贝到所有节点的 /opt/k8s/bin 目录：</p>
<pre><code>source ./environment.sh
for node_ip in $&#123;NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    scp environment.sh k8s@$&#123;node_ip&#125;:/opt/k8s/bin/
    ssh k8s@$&#123;node_ip&#125; &quot;chmod +x /opt/k8s/bin/*&quot;
  done
</code></pre>
<h3 id="CA证书"><a href="#CA证书" class="headerlink" title="CA证书"></a>CA证书</h3><p>配置文件：<br> 17520h 2年，最大2年</p>
<pre><code>cat &gt; ca-config.json &lt;&lt;EOF
&#123;
  &quot;signing&quot;: &#123;
    &quot;default&quot;: &#123;
      &quot;expiry&quot;: &quot;17520h&quot;
    &#125;,
    &quot;profiles&quot;: &#123;
      &quot;kubernetes&quot;: &#123;
        &quot;usages&quot;: [
            &quot;signing&quot;,
            &quot;key encipherment&quot;,
            &quot;server auth&quot;,
            &quot;client auth&quot;
        ],
        &quot;expiry&quot;: &quot;87600h&quot;
      &#125;
    &#125;
  &#125;
&#125;
EOF
</code></pre>
<p>ca证书签名请求</p>
<pre><code>cat &gt; ca-csr.json &lt;&lt;EOF
&#123;
  &quot;CN&quot;: &quot;kubernetes&quot;,
  &quot;key&quot;: &#123;
    &quot;algo&quot;: &quot;rsa&quot;,
    &quot;size&quot;: 2048
  &#125;,
  &quot;names&quot;: [
    &#123;
      &quot;C&quot;: &quot;CN&quot;,
      &quot;ST&quot;: &quot;BeiJing&quot;,
      &quot;L&quot;: &quot;BeiJing&quot;,
      &quot;O&quot;: &quot;k8s&quot;,
      &quot;OU&quot;: &quot;4Paradigm&quot;
    &#125;
  ]
&#125;
EOF
</code></pre>
<ul>
<li>CN：<code>Common Name</code>，kube-apiserver 从证书中提取该字段作为请求的**用户名 (User Name)**，浏览器使用该字段验证网站是否合法；</li>
<li>O：<code>Organization</code>，kube-apiserver 从证书中提取该字段作为请求用户所属的**组 (Group)**；</li>
<li>kube-apiserver 将提取的 User、Group 作为 <code>RBAC</code> 授权的用户标识；</li>
</ul>
<h4 id="生成-CA-证书和私钥"><a href="#生成-CA-证书和私钥" class="headerlink" title="生成 CA 证书和私钥"></a>生成 CA 证书和私钥</h4><pre><code>cfssl gencert -initca ca-csr.json | cfssljson -bare ca
ls ca*
</code></pre>
<p>将生成的 CA 证书、秘钥文件、配置文件拷贝到所有节点的 /etc/kubernetes/cert 目录下：</p>
<pre><code>source /opt/k8s/bin/environment.sh # 导入 NODE_IPS 环境变量
for node_ip in $&#123;NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    ssh root@$&#123;node_ip&#125; &quot;mkdir -p /etc/kubernetes/cert &amp;&amp; chown -R k8s /etc/kubernetes&quot;
    scp ca*.pem ca-config.json k8s@$&#123;node_ip&#125;:/etc/kubernetes/cert
  done
</code></pre>
<h3 id="客户端安装"><a href="#客户端安装" class="headerlink" title="客户端安装"></a>客户端安装</h3><p>wget <a target="_blank" rel="noopener" href="https://dl.k8s.io/v1.12.1/kubernetes-client-linux-amd64.tar.gz">https://dl.k8s.io/v1.12.1/kubernetes-client-linux-amd64.tar.gz</a><br> tar -xzvf kubernetes-client-linux-amd64.tar.gz</p>
<p>分发到所有使用 kubectl 的节点：</p>
<pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    scp kubernetes/client/bin/kubectl k8s@$&#123;node_ip&#125;:/opt/k8s/bin/
    ssh k8s@$&#123;node_ip&#125; &quot;chmod +x /opt/k8s/bin/*&quot;
  done
</code></pre>
<h3 id="创建-admin-证书和私钥"><a href="#创建-admin-证书和私钥" class="headerlink" title="创建 admin 证书和私钥"></a>创建 admin 证书和私钥</h3><p>kubectl 与 apiserver https 安全端口通信，apiserver 对提供的证书进行认证和授权。</p>
<p>kubectl 作为集群的管理工具，需要被授予最高权限。这里创建具有最高权限的 admin 证书。</p>
<p>创建证书签名请求：</p>
<pre><code>cat &gt; admin-csr.json &lt;&lt;EOF
&#123;
  &quot;CN&quot;: &quot;admin&quot;,
  &quot;hosts&quot;: [],
  &quot;key&quot;: &#123;
    &quot;algo&quot;: &quot;rsa&quot;,
    &quot;size&quot;: 2048
  &#125;,
  &quot;names&quot;: [
    &#123;
      &quot;C&quot;: &quot;CN&quot;,
      &quot;ST&quot;: &quot;BeiJing&quot;,
      &quot;L&quot;: &quot;BeiJing&quot;,
      &quot;O&quot;: &quot;system:masters&quot;,
      &quot;OU&quot;: &quot;4Paradigm&quot;
    &#125;
  ]
&#125;
EOF
</code></pre>
<p>O 为 system:masters，kube-apiserver 收到该证书后将请求的 Group 设置为 system:masters；<br> 预定义的 ClusterRoleBinding cluster-admin 将 Group system:masters 与 Role cluster-admin 绑定，该 Role 授予所有 API的权限；<br> 该证书只会被 kubectl 当做 client 证书使用，所以 hosts 字段为空；</p>
<h3 id="生成证书和私钥："><a href="#生成证书和私钥：" class="headerlink" title="生成证书和私钥："></a>生成证书和私钥：</h3><pre><code>cfssl gencert -ca=/etc/kubernetes/cert/ca.pem \
  -ca-key=/etc/kubernetes/cert/ca-key.pem \
  -config=/etc/kubernetes/cert/ca-config.json \
  -profile=kubernetes admin-csr.json | cfssljson -bare admin
ls admin*
</code></pre>
<h3 id="创建-kubeconfig-文件"><a href="#创建-kubeconfig-文件" class="headerlink" title="创建 kubeconfig 文件"></a>创建 kubeconfig 文件</h3><p>kubeconfig 为 kubectl 的配置文件，包含访问 apiserver 的所有信息，如 apiserver 地址、CA 证书和自身使用的证书；</p>
<pre><code>source /opt/k8s/bin/environment.sh
# 设置集群参数
kubectl config set-cluster kubernetes \
  --certificate-authority=/etc/kubernetes/cert/ca.pem \
  --embed-certs=true \
  --server=$&#123;KUBE_APISERVER&#125; \
  --kubeconfig=kubectl.kubeconfig

# 设置客户端认证参数
kubectl config set-credentials admin \
  --client-certificate=admin.pem \
  --client-key=admin-key.pem \
  --embed-certs=true \
  --kubeconfig=kubectl.kubeconfig

# 设置上下文参数
kubectl config set-context kubernetes \
  --cluster=kubernetes \
  --user=admin \
  --kubeconfig=kubectl.kubeconfig
  
# 设置默认上下文
kubectl config use-context kubernetes --kubeconfig=kubectl.kubeconfig
--certificate-authority：验证 kube-apiserver 证书的根证书；
--client-certificate、--client-key：刚生成的 admin 证书和私钥，连接 kube-apiserver 时使用；
--embed-certs=true：将 ca.pem 和 admin.pem 证书内容嵌入到生成的 kubectl.kubeconfig 文件中(不加时，写入的是证书文件路径)；
</code></pre>
<h3 id="分发-kubeconfig-文件"><a href="#分发-kubeconfig-文件" class="headerlink" title="分发 kubeconfig 文件"></a>分发 kubeconfig 文件</h3><p>分发到所有使用 kubectl 命令的节点：</p>
<pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    ssh k8s@$&#123;node_ip&#125; &quot;mkdir -p ~/.kube&quot;
    scp kubectl.kubeconfig k8s@$&#123;node_ip&#125;:~/.kube/config
    ssh root@$&#123;node_ip&#125; &quot;mkdir -p ~/.kube&quot;
    scp kubectl.kubeconfig root@$&#123;node_ip&#125;:~/.kube/config
  done
</code></pre>
<p>保存到用户的 ~/.kube/config 文件；</p>
<h2 id="etcd安装"><a href="#etcd安装" class="headerlink" title="etcd安装"></a>etcd安装</h2><p>到 <a target="_blank" rel="noopener" href="https://github.com/coreos/etcd/releases">https://github.com/coreos/etcd/releases</a> 页面下载最新版本的发布包：</p>
<pre><code>wget https://github.com/etcd-io/etcd/releases/download/v3.3.10/etcd-v3.3.10-linux-amd64.tar.gz
tar -xvf etcd-v3.3.10-linux-amd64.tar.gz
</code></pre>
<h3 id="分发二进制文件到集群所有节点："><a href="#分发二进制文件到集群所有节点：" class="headerlink" title="分发二进制文件到集群所有节点："></a>分发二进制文件到集群所有节点：</h3><pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    scp etcd-v3.3.10-linux-amd64/etcd* k8s@$&#123;node_ip&#125;:/opt/k8s/bin
    ssh k8s@$&#123;node_ip&#125; &quot;chmod +x /opt/k8s/bin/*&quot;
  done
</code></pre>
<h3 id="创建-etcd-证书和私钥"><a href="#创建-etcd-证书和私钥" class="headerlink" title="创建 etcd 证书和私钥"></a>创建 etcd 证书和私钥</h3><p>创建证书签名请求：</p>
<pre><code>cat &gt; etcd-csr.json &lt;&lt;EOF
&#123;
  &quot;CN&quot;: &quot;etcd&quot;,
  &quot;hosts&quot;: [
    &quot;127.0.0.1&quot;,
    &quot;192.168.86.156&quot;,
    &quot;192.168.86.155&quot;,
    &quot;192.168.86.154&quot;
  ],
  &quot;key&quot;: &#123;
    &quot;algo&quot;: &quot;rsa&quot;,
    &quot;size&quot;: 2048
  &#125;,
  &quot;names&quot;: [
    &#123;
      &quot;C&quot;: &quot;CN&quot;,
      &quot;ST&quot;: &quot;BeiJing&quot;,
      &quot;L&quot;: &quot;BeiJing&quot;,
      &quot;O&quot;: &quot;k8s&quot;,
      &quot;OU&quot;: &quot;4Paradigm&quot;
    &#125;
  ]
&#125;
EOF
</code></pre>
<h3 id="生成证书和私钥：-1"><a href="#生成证书和私钥：-1" class="headerlink" title="生成证书和私钥："></a>生成证书和私钥：</h3><pre><code>cfssl gencert -ca=/etc/kubernetes/cert/ca.pem \
    -ca-key=/etc/kubernetes/cert/ca-key.pem \
    -config=/etc/kubernetes/cert/ca-config.json \
    -profile=kubernetes etcd-csr.json | cfssljson -bare etcd
ls etcd*
</code></pre>
<h3 id="分发生成的证书和私钥到各-etcd-节点："><a href="#分发生成的证书和私钥到各-etcd-节点：" class="headerlink" title="分发生成的证书和私钥到各 etcd 节点："></a>分发生成的证书和私钥到各 etcd 节点：</h3><pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    ssh root@$&#123;node_ip&#125; &quot;mkdir -p /etc/etcd/cert &amp;&amp; chown -R k8s /etc/etcd/cert&quot;
    scp etcd*.pem k8s@$&#123;node_ip&#125;:/etc/etcd/cert/
  done
</code></pre>
<p>ETCD_NODE_IPS</p>
<h3 id="创建-etcd-的-systemd-unit-模板文件"><a href="#创建-etcd-的-systemd-unit-模板文件" class="headerlink" title="创建 etcd 的 systemd unit 模板文件"></a>创建 etcd 的 systemd unit 模板文件</h3><p>cat &gt; etcd.service.template &lt;&lt;EOF<br> [Unit]<br> Description=Etcd Server<br> After=network.target<br> After=network-online.target<br> Wants=network-online.target<br> Documentation=<a target="_blank" rel="noopener" href="https://github.com/coreos">https://github.com/coreos</a></p>
<p>[Service]<br> User=k8s<br> Type=notify<br> WorkingDirectory=/var/lib/etcd/<br> ExecStart=/opt/k8s/bin/etcd \<br> –data-dir=/var/lib/etcd \<br> –name=##NODE_NAME## \</p>
<p>–cert-file=/etc/etcd/cert/etcd.pem \<br> –key-file=/etc/etcd/cert/etcd-key.pem \<br> –trusted-ca-file=/etc/kubernetes/cert/ca.pem \<br> –peer-cert-file=/etc/etcd/cert/etcd.pem \<br> –peer-key-file=/etc/etcd/cert/etcd-key.pem \<br> –peer-trusted-ca-file=/etc/kubernetes/cert/ca.pem \<br> –peer-client-cert-auth \<br> –client-cert-auth \<br> –listen-peer-urls=https://##NODE_IP##:2380 \<br> –initial-advertise-peer-urls=https://##NODE_IP##:2380 \<br> –listen-client-urls=https://##NODE_IP##:2379,<a target="_blank" rel="noopener" href="http://127.0.0.1:2379/">http://127.0.0.1:2379</a> \<br> –advertise-client-urls=https://##NODE_IP##:2379 \<br> –initial-cluster-token=etcd-cluster-0 \<br> –initial-cluster=${ETCD_NODES} \<br> –initial-cluster-state=new<br> Restart=on-failure<br> RestartSec=5<br> LimitNOFILE=65536</p>
<p>[Install]<br> WantedBy=multi-user.target<br> EOF</p>
<p>User：指定以 k8s 账户运行；<br> WorkingDirectory、–data-dir：指定工作目录和数据目录为 /var/lib/etcd，需在启动服务前创建这个目录；<br> –name：指定节点名称，当 –initial-cluster-state 值为 new 时，–name 的参数值必须位于 –initial-cluster 列表中；<br> –cert-file、–key-file：etcd server 与 client 通信时使用的证书和私钥；<br> –trusted-ca-file：签名 client 证书的 CA 证书，用于验证 client 证书；<br> –peer-cert-file、–peer-key-file：etcd 与 peer 通信使用的证书和私钥；<br> –peer-trusted-ca-file：签名 peer 证书的 CA 证书，用于验证 peer 证书；</p>
<h3 id="为各节点创建和分发-etcd-systemd-unit-文件"><a href="#为各节点创建和分发-etcd-systemd-unit-文件" class="headerlink" title="为各节点创建和分发 etcd systemd unit 文件"></a>为各节点创建和分发 etcd systemd unit 文件</h3><pre><code>source /opt/k8s/bin/environment.sh
for (( i=0; i &lt; 3; i++ ))
  do
    sed -e &quot;s/##NODE_NAME##/$&#123;NODE_NAMES[i]&#125;/&quot; -e &quot;s/##NODE_IP##/$&#123;NODE_IPS[i]&#125;/&quot; etcd.service.template &gt; etcd-$&#123;NODE_IPS[i]&#125;.service 
  done
ls *.service
</code></pre>
<p>分发生成的 systemd unit 文件：</p>
<p>source /opt/k8s/bin/environment.sh<br> for node_ip in ${ETCD_NODE_IPS[@]}<br> do<br> echo “&gt;&gt;&gt; ${node_ip}”<br> ssh root@${node_ip} “mkdir -p /var/lib/etcd &amp;&amp; chown -R k8s /var/lib/etcd”<br> scp etcd-${node_ip}.service root@${node_ip}:/etc/systemd/system/etcd.service<br> done</p>
<h3 id="启动-etcd-服务"><a href="#启动-etcd-服务" class="headerlink" title="启动 etcd 服务"></a>启动 etcd 服务</h3><p>source ./environment.sh<br> for node_ip in ${ETCD_NODE_IPS[@]}<br> do<br> echo “&gt;&gt;&gt; ${node_ip}”<br> ssh root@${node_ip} “systemctl daemon-reload &amp;&amp; systemctl enable etcd &amp;&amp; systemctl restart etcd &amp;”<br> done</p>
<p>etcd 进程首次启动时会等待其它节点的 etcd 加入集群，命令 systemctl start etcd 会卡住一段时间，为正常现象。</p>
<h3 id="检查启动结果"><a href="#检查启动结果" class="headerlink" title="检查启动结果"></a>检查启动结果</h3><pre><code>source ./environment.sh
for node_ip in $&#123;ETCD_NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    ssh k8s@$&#123;node_ip&#125; &quot;systemctl status etcd|grep Active&quot;
  done
</code></pre>
<p>确保状态为 active (running)，否则查看日志，确认原因：</p>
<p>$ journalctl -u etcd</p>
<h3 id="验证服务状态"><a href="#验证服务状态" class="headerlink" title="验证服务状态"></a>验证服务状态</h3><p>部署完 etcd 集群后，在任一 etc 节点上执行如下命令：</p>
<p>source ./environment.sh<br> for node_ip in ${ETCD_NODE_IPS[@]}<br> do<br> echo “&gt;&gt;&gt; ${node_ip}”<br> ETCDCTL_API=3 /opt/k8s/bin/etcdctl<br> –endpoints=https://${node_ip}:2379<br> –cacert=/etc/kubernetes/cert/ca.pem<br> –cert=/etc/etcd/cert/etcd.pem<br> –key=/etc/etcd/cert/etcd-key.pem endpoint health<br> done<br> 预期输出：</p>
<blockquote>
<blockquote>
<blockquote>
<p>192.168.86.154<br><a target="_blank" rel="noopener" href="https://192.168.86.154:2379/">https://192.168.86.154:2379</a> is healthy: successfully committed proposal: took = 2.197007ms</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>192.168.86.155<br><a target="_blank" rel="noopener" href="https://192.168.86.155:2379/">https://192.168.86.155:2379</a> is healthy: successfully committed proposal: took = 2.299328ms</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>192.168.86.156<br><a target="_blank" rel="noopener" href="https://192.168.86.156:2379/">https://192.168.86.156:2379</a> is healthy: successfully committed proposal: took = 2.014274ms</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="05-部署-flannel-网络"><a href="#05-部署-flannel-网络" class="headerlink" title="05.部署 flannel 网络"></a>05.部署 flannel 网络</h2><p>kubernetes 要求集群内各节点(包括 master 节点)能通过 Pod 网段互联互通。flannel 使用 vxlan 技术为各节点创建一个可以互通的 Pod 网络，使用的端口为 UDP 8472，需要开放该端口（如公有云 AWS 等）。</p>
<p>flannel 第一次启动时，从 etcd 获取 Pod 网段信息，为本节点分配一个未使用的 /24 段地址，然后创建 flannel.1（也可能是其它名称，如 flannel1 等） 接口。</p>
<p>flannel 将分配的 Pod 网段信息写入 /run/flannel/docker 文件，docker 后续使用这个文件中的环境变量设置 docker0 网桥。</p>
<h3 id="下载和分发-flanneld-二进制文件"><a href="#下载和分发-flanneld-二进制文件" class="headerlink" title="下载和分发 flanneld 二进制文件"></a>下载和分发 flanneld 二进制文件</h3><p>到 <a target="_blank" rel="noopener" href="https://github.com/coreos/flannel/releases">https://github.com/coreos/flannel/releases</a> 页面下载最新版本的发布包：</p>
<pre><code>mkdir flannel
wget https://github.com/coreos/flannel/releases/download/v0.10.0/flannel-v0.10.0-linux-amd64.tar.gz
tar -xzvf flannel-v0.10.0-linux-amd64.tar.gz -C flannel
</code></pre>
<h3 id="创建证书签名请求："><a href="#创建证书签名请求：" class="headerlink" title="创建证书签名请求："></a>创建证书签名请求：</h3><pre><code>cat &gt; flanneld-csr.json &lt;&lt;EOF
&#123;
  &quot;CN&quot;: &quot;flanneld&quot;,
  &quot;hosts&quot;: [],
  &quot;key&quot;: &#123;
    &quot;algo&quot;: &quot;rsa&quot;,
    &quot;size&quot;: 2048
  &#125;,
  &quot;names&quot;: [
    &#123;
      &quot;C&quot;: &quot;CN&quot;,
      &quot;ST&quot;: &quot;BeiJing&quot;,
      &quot;L&quot;: &quot;BeiJing&quot;,
      &quot;O&quot;: &quot;k8s&quot;,
      &quot;OU&quot;: &quot;4Paradigm&quot;
    &#125;
  ]
&#125;
EOF
</code></pre>
<p>该证书只会被 kubectl 当做 client 证书使用，所以 hosts 字段为空；<br> 生成证书和私钥：</p>
<pre><code>cfssl gencert -ca=/etc/kubernetes/cert/ca.pem \
  -ca-key=/etc/kubernetes/cert/ca-key.pem \
  -config=/etc/kubernetes/cert/ca-config.json \
  -profile=kubernetes flanneld-csr.json | cfssljson -bare flanneld
ls flanneld*pem
</code></pre>
<p>分发 flanneld 二进制文件和flannel 证书、私钥 到集群所有节点：</p>
<pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    scp  flannel/&#123;flanneld,mk-docker-opts.sh&#125; k8s@$&#123;node_ip&#125;:/opt/k8s/bin/
    ssh k8s@$&#123;node_ip&#125; &quot;chmod +x /opt/k8s/bin/*&quot;
    ssh root@$&#123;node_ip&#125; &quot;mkdir -p /etc/flanneld/cert &amp;&amp; chown -R k8s /etc/flanneld&quot;scp flanneld*.pem k8s@$&#123;node_ip&#125;:/etc/flanneld/cert
  done
</code></pre>
<p>创建<br> flannel 从 etcd 集群存取网段分配信息，而 etcd 集群启用了双向 x509 证书认证，所以需要为 flanneld 生成证书和私钥。</p>
<p>向 etcd 写入集群 Pod 网段信息<br> 注意：本步骤只需执行一次。</p>
<pre><code>source /opt/k8s/bin/environment.sh
etcdctl \
  --endpoints=$&#123;ETCD_ENDPOINTS&#125; \
  --ca-file=/etc/kubernetes/cert/ca.pem \
  --cert-file=/etc/flanneld/cert/flanneld.pem \
  --key-file=/etc/flanneld/cert/flanneld-key.pem \
  set $&#123;FLANNEL_ETCD_PREFIX&#125;/config &#39;&#123;&quot;Network&quot;:&quot;&#39;$&#123;CLUSTER_CIDR&#125;&#39;&quot;, &quot;SubnetLen&quot;: 24, &quot;Backend&quot;: &#123;&quot;Type&quot;: &quot;vxlan&quot;&#125;&#125;&#39;
</code></pre>
<p>flanneld 当前版本 (v0.10.0) 不支持 etcd v3，故使用 etcd v2 API 写入配置 key 和网段数据；<br> 写入的 Pod 网段 ${CLUSTER_CIDR} 必须是 /16 段地址，必须与 kube-controller-manager 的 –cluster-cidr 参数值一致；</p>
<h3 id="创建-flanneld-的-systemd-unit-文件"><a href="#创建-flanneld-的-systemd-unit-文件" class="headerlink" title="创建 flanneld 的 systemd unit 文件"></a>创建 flanneld 的 systemd unit 文件</h3><pre><code>source /opt/k8s/bin/environment.sh
export IFACE=eno1 # 有的为em1，eth0
cat &gt; flanneld.service &lt;&lt; EOF
[Unit]
Description=Flanneld overlay address etcd agent
After=network.target
After=network-online.target
Wants=network-online.target
After=etcd.service
Before=docker.service

[Service]
Type=notify
ExecStart=/opt/k8s/bin/flanneld \\
  -etcd-cafile=/etc/kubernetes/cert/ca.pem \\
  -etcd-certfile=/etc/flanneld/cert/flanneld.pem \\
  -etcd-keyfile=/etc/flanneld/cert/flanneld-key.pem \\
  -etcd-endpoints=$&#123;ETCD_ENDPOINTS&#125; \\
  -etcd-prefix=$&#123;FLANNEL_ETCD_PREFIX&#125; \\
  -iface=$&#123;IFACE&#125;
ExecStartPost=/opt/k8s/bin/mk-docker-opts.sh -k DOCKER_NETWORK_OPTIONS -d /run/flannel/docker
Restart=on-failure

[Install]
WantedBy=multi-user.target
RequiredBy=docker.service
EOF
</code></pre>
<p>mk-docker-opts.sh 脚本将分配给 flanneld 的 Pod 子网网段信息写入 /run/flannel/docker 文件，后续 docker 启动时使用这个文件中的环境变量配置 docker0 网桥；<br> flanneld 使用系统缺省路由所在的接口与其它节点通信，对于有多个网络接口（如内网和公网）的节点，可以用 -iface 参数指定通信接口，如上面的 eth0 接口;<br> flanneld 运行时需要 root 权限；<br> 完整 unit 见 flanneld.service</p>
<p>注意：<br> 有的IFACE=eno1，有的为em1，eth，通过ifconfig查看</p>
<h3 id="分发-flanneld-systemd-unit-文件到所有节点"><a href="#分发-flanneld-systemd-unit-文件到所有节点" class="headerlink" title="分发 flanneld systemd unit 文件到所有节点"></a>分发 flanneld systemd unit 文件到所有节点</h3><pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    scp flanneld.service root@$&#123;node_ip&#125;:/etc/systemd/system/
  done
</code></pre>
<h3 id="启动-flanneld-服务"><a href="#启动-flanneld-服务" class="headerlink" title="启动 flanneld 服务"></a>启动 flanneld 服务</h3><pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    ssh root@$&#123;node_ip&#125; &quot;systemctl daemon-reload &amp;&amp; systemctl enable flanneld &amp;&amp; systemctl restart flanneld&quot;
  done
</code></pre>
<h3 id="检查启动结果-1"><a href="#检查启动结果-1" class="headerlink" title="检查启动结果"></a>检查启动结果</h3><pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    ssh k8s@$&#123;node_ip&#125; &quot;systemctl status flanneld|grep Active&quot;
  done
</code></pre>
<p>确保状态为 active (running)，否则查看日志，确认原因：</p>
<p>$ journalctl -u flanneld</p>
<h3 id="检查分配给各-flanneld-的-Pod-网段信息"><a href="#检查分配给各-flanneld-的-Pod-网段信息" class="headerlink" title="检查分配给各 flanneld 的 Pod 网段信息"></a>检查分配给各 flanneld 的 Pod 网段信息</h3><p>查看集群 Pod 网段(/16)：</p>
<p>source /opt/k8s/bin/environment.sh<br> etcdctl<br> –endpoints=${ETCD_ENDPOINTS}<br> –ca-file=/etc/kubernetes/cert/ca.pem<br> –cert-file=/etc/flanneld/cert/flanneld.pem<br> –key-file=/etc/flanneld/cert/flanneld-key.pem<br> get ${FLANNEL_ETCD_PREFIX}/config<br> 输出：</p>
<p>{“Network”:”170.22.0.0/16”, “SubnetLen”: 24, “Backend”: {“Type”: “vxlan”}}</p>
<p>查看已分配的 Pod 子网段列表(/24):</p>
<p>source /opt/k8s/bin/environment.sh<br> etcdctl<br> –endpoints=${ETCD_ENDPOINTS}<br> –ca-file=/etc/kubernetes/cert/ca.pem<br> –cert-file=/etc/flanneld/cert/flanneld.pem<br> –key-file=/etc/flanneld/cert/flanneld-key.pem<br> ls ${FLANNEL_ETCD_PREFIX}/subnets<br> 输出：</p>
<p>/kubernetes/network/subnets/170.22.76.0-24<br> /kubernetes/network/subnets/170.22.84.0-24<br> /kubernetes/network/subnets/170.22.45.0-24<br> /kubernetes/network/subnets/170.22.7.0-24<br> /kubernetes/network/subnets/170.22.12.0-24<br> /kubernetes/network/subnets/170.22.78.0-24<br> /kubernetes/network/subnets/170.22.5.0-24</p>
<p>查看某一 Pod 网段对应的节点 IP 和 flannel 接口地址:</p>
<p>source /opt/k8s/bin/environment.sh<br> etcdctl<br> –endpoints=${ETCD_ENDPOINTS}<br> –ca-file=/etc/kubernetes/cert/ca.pem<br> –cert-file=/etc/flanneld/cert/flanneld.pem<br> –key-file=/etc/flanneld/cert/flanneld-key.pem<br> get ${FLANNEL_ETCD_PREFIX}/subnets/170.22.76.0-24<br> 输出：</p>
<p>{“PublicIP”:”192.168.86.156”,”BackendType”:”vxlan”,”BackendData”:{“VtepMAC”:”6a:aa:ca:8a:ac:ed”}}</p>
<p>验证各节点能通过 Pod 网段互通<br> 在各节点上部署 flannel 后，检查是否创建了 flannel 接口(名称可能为 flannel0、flannel.0、flannel.1 等)：</p>
<p>source /opt/k8s/bin/environment.sh<br> for node_ip in ${NODE_IPS[@]}<br> do<br> echo “&gt;&gt;&gt; ${node_ip}”<br> ssh ${node_ip} “/usr/sbin/ip addr show flannel.1|grep -w inet”<br> done<br> 输出：</p>
<p>inet 172.30.81.0/32 scope global flannel.1<br> inet 172.30.29.0/32 scope global flannel.1<br> inet 172.30.39.0/32 scope global flannel.1<br> 在各节点上 ping 所有 flannel 接口 IP，确保能通：</p>
<p>source /opt/k8s/bin/environment.sh<br> for node_ip in ${NODE_IPS[@]}<br> do<br> echo “&gt;&gt;&gt; ${node_ip}”<br> ssh ${node_ip} “ping -c 1 172.30.81.0”<br> ssh ${node_ip} “ping -c 1 172.30.29.0”<br> ssh ${node_ip} “ping -c 1 172.30.39.0”<br> done</p>
<h2 id="06-0-部署-master-节点"><a href="#06-0-部署-master-节点" class="headerlink" title="06-0.部署 master 节点"></a>06-0.部署 master 节点</h2><p>kubernetes master 节点运行如下组件：</p>
<p>kube-apiserver<br> kube-scheduler<br> kube-controller-manager<br> kube-scheduler 和 kube-controller-manager 可以以集群模式运行，通过 leader 选举产生一个工作进程，其它进程处于阻塞模式。</p>
<p>对于 kube-apiserver，可以运行多个实例（本文档是 3 实例），但对其它组件需要提供统一的访问地址，该地址需要高可用。本文档使用 keepalived 和 haproxy 实现 kube-apiserver VIP 高可用和负载均衡。</p>
<h3 id="下载最新版本的二进制文件"><a href="#下载最新版本的二进制文件" class="headerlink" title="下载最新版本的二进制文件"></a>下载最新版本的二进制文件</h3><p>从 CHANGELOG页面 下载 server tarball 文件（需要翻墙）</p>
<pre><code>wget https://dl.k8s.io/v1.12.1/kubernetes-server-linux-amd64.tar.gz
tar -xzvf kubernetes-server-linux-amd64.tar.gz
</code></pre>
<p>将二进制文件拷贝到所有 所有节点：</p>
<pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    scp kubernetes/server/bin/* k8s@$&#123;node_ip&#125;:/opt/k8s/bin/
    ssh k8s@$&#123;node_ip&#125; &quot;chmod +x /opt/k8s/bin/*&quot;
  done
</code></pre>
<p>如果有老版本运行，先停止：</p>
<pre><code>systemctl stop kubelet.service 
systemctl stop kube-controller-manager.service 
systemctl stop kube-apiserver.service 
systemctl stop kube-proxy.service 
systemctl stop kube-scheduler.service
systemctl stop etcd
systemctl stop 
</code></pre>
<h2 id="06-1-部署高可用组件（keepalived-haproxy"><a href="#06-1-部署高可用组件（keepalived-haproxy" class="headerlink" title="06-1.部署高可用组件（keepalived+haproxy)"></a>06-1.部署高可用组件（keepalived+haproxy)</h2><p>使用 keepalived 和 haproxy 实现 kube-apiserver 高可用的步骤：</p>
<ul>
<li>keepalived 提供 kube-apiserver 对外服务的 VIP；</li>
<li>haproxy 监听 VIP，后端连接所有 kube-apiserver 实例，提供健康检查和负载均衡功能；</li>
<li>运行 keepalived 和 haproxy 的节点称为 LB 节点。由于 keepalived 是一主多备运行模式，故至少两个 LB 节点。</li>
</ul>
<p>本文档复用 master 节点的三台机器，haproxy 监听的端口(8443) 需要与 kube-apiserver 的端口 6443 不同，避免冲突。</p>
<p>keepalived 在运行过程中周期检查本机的 haproxy 进程状态，如果检测到 haproxy 进程异常，则触发重新选主的过程，VIP 将飘移到新选出来的主节点，从而实现 VIP 的高可用。</p>
<p>所有组件（如 kubeclt、apiserver、controller-manager、scheduler 等）都通过 VIP 和 haproxy 监听的 8443 端口访问 kube-apiserver 服务。</p>
<h3 id="安装软件包"><a href="#安装软件包" class="headerlink" title="安装软件包"></a>安装软件包</h3><pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    ssh root@$&#123;node_ip&#125; &quot;yum install -y keepalived haproxy&quot;
  done
</code></pre>
<p>ubuntu机器，apt-get install</p>
<h3 id="配置和下发-haproxy-配置文件"><a href="#配置和下发-haproxy-配置文件" class="headerlink" title="配置和下发 haproxy 配置文件"></a>配置和下发 haproxy 配置文件</h3><p>haproxy 配置文件：</p>
<pre><code>cat &gt; haproxy.cfg &lt;&lt;EOF
 global
     log /dev/log    local0
     log /dev/log    local1 notice
     chroot /var/lib/haproxy
     stats socket /var/run/haproxy-admin.sock mode 660 level admin
     stats timeout 30s
     user haproxy
     group haproxy
     daemon
     nbproc 1
 
 defaults
     log     global
     timeout connect 5000
     timeout client  10m
     timeout server  10m
 
 listen  admin_stats
     bind 0.0.0.0:10080
     mode http
     log 127.0.0.1 local0 err
     stats refresh 30s
     stats uri /status
     stats realm welcome login\ Haproxy
     stats auth admin:123456
     stats hide-version
     stats admin if TRUE
 
 listen kube-master
     bind 0.0.0.0:8443
     mode tcp
     option tcplog
     balance source
     server 192.168.86.154 192.168.86.154:6443 check inter 2000 fall 2 rise 2 weight 1
     server 192.168.86.155 192.168.86.155:6443 check inter 2000 fall 2 rise 2 weight 1
     server 192.168.86.156 192.168.86.156:6443 check inter 2000 fall 2 rise 2 weight 1
EOF
</code></pre>
<ul>
<li>haproxy 在 10080 端口输出 status 信息；</li>
<li>haproxy 监听所有接口的 8443 端口，该端口与环境变量 ${KUBE_APISERVER} 指定的端口必须一致；</li>
<li>server 字段列出所有 kube-apiserver 监听的 IP 和端口；</li>
</ul>
<p>下发 haproxy.cfg 到所有 master 节点：</p>
<pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;ETCD_NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    scp haproxy.cfg root@$&#123;node_ip&#125;:/etc/haproxy
  done
</code></pre>
<p>起 haproxy 服务</p>
<pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;ETCD_NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    ssh root@$&#123;node_ip&#125; &quot;systemctl restart haproxy&quot;
  done
</code></pre>
<p>检查 haproxy 服务状态</p>
<pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;ETCD_NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    ssh root@$&#123;node_ip&#125; &quot;systemctl status haproxy|grep Active&quot;
  done
</code></pre>
<p>确保状态为 active (running)，否则查看日志，确认原因：</p>
<blockquote>
<blockquote>
<blockquote>
<p>192.168.86.154<br> Active: active (running) since Tue 2018-11-06 10:48:13 CST; 5s ago</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>192.168.86.155<br> Active: active (running) since Tue 2018-11-06 10:48:14 CST; 5s ago</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>192.168.86.156<br> Active: active (running) since Tue 2018-11-06 10:48:13 CST; 5s ago</p>
</blockquote>
</blockquote>
</blockquote>
<p>journalctl -u haproxy<br> 检查 haproxy 是否监听 8443 端口：</p>
<pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;ETCD_NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    ssh root@$&#123;node_ip&#125; &quot;netstat -lnpt|grep haproxy&quot;
  done
</code></pre>
<p>确保输出类似于:</p>
<p>tcp        0      0 0.0.0.0:8443            0.0.0.0:*               LISTEN      45606/haproxy</p>
<h3 id="配置和下发-keepalived-配置文件"><a href="#配置和下发-keepalived-配置文件" class="headerlink" title="配置和下发 keepalived 配置文件"></a>配置和下发 keepalived 配置文件</h3><p>keepalived 是一主（master）多备（backup）运行模式，故有两种类型的配置文件。master 配置文件只有一份，backup 配置文件视节点数目而定，对于本文档而言，规划如下：</p>
<p>master: 192.168.86.156<br> backup：192.168.86.155，192.168.86.154</p>
<p>master 配置文件：</p>
<pre><code>source /opt/k8s/bin/environment.sh
cat  &gt; keepalived-master.conf &lt;&lt;EOF
global_defs &#123;
    router_id lb-master-105
&#125;

vrrp_script check-haproxy &#123;
    script &quot;killall -0 haproxy&quot;
    interval 5
    weight -30
&#125;

vrrp_instance VI-kube-master &#123;
    state MASTER
    priority 120
    dont_track_primary
    interface $&#123;VIP_IF&#125;
    virtual_router_id 68
    advert_int 3
    track_script &#123;
        check-haproxy
    &#125;
    virtual_ipaddress &#123;
        $&#123;MASTER_VIP&#125;
    &#125;
&#125;
EOF
</code></pre>
<p>VIP 所在的接口（interface ${VIP_IF}）为 em1<br> 使用 killall -0 haproxy 命令检查所在节点的 haproxy 进程是否正常。如果异常则将权重减少（-30）,从而触发重新选主过程；<br> router_id、virtual_router_id 用于标识属于该 HA 的 keepalived 实例，如果有多套 keepalived HA，则必须各不相同；<br> backup 配置文件：</p>
<p>source /opt/k8s/bin/environment.sh<br> cat  &gt; keepalived-backup.conf &lt;&lt;EOF<br> global_defs {<br> router_id lb-backup-105<br> }</p>
<p>vrrp_script check-haproxy {<br> script “killall -0 haproxy”<br> interval 5<br> weight -30<br> }</p>
<p>vrrp_instance VI-kube-master {<br> state BACKUP<br> priority 110<br> dont_track_primary<br> interface ${VIP_IF}<br> virtual_router_id 68<br> advert_int 3<br> track_script {<br> check-haproxy<br> }<br> virtual_ipaddress {<br> ${MASTER_VIP}<br> }<br> }<br> EOF</p>
<p>VIP 所在的接口（interface ${VIP_IF}）为 em1<br> 使用 killall -0 haproxy 命令检查所在节点的 haproxy 进程是否正常。如果异常则将权重减少（-30）,从而触发重新选主过程；<br> router_id、virtual_router_id 用于标识属于该 HA 的 keepalived 实例，如果有多套 keepalived HA，则必须各不相同；<br> priority 的值必须小于 master 的值；</p>
<h3 id="下发-keepalived-配置文件"><a href="#下发-keepalived-配置文件" class="headerlink" title="下发 keepalived 配置文件"></a>下发 keepalived 配置文件</h3><p>下发 master 配置文件：</p>
<pre><code>scp keepalived-master.conf root@172.27.129.105:/etc/keepalived/keepalived.conf
</code></pre>
<p>下发 backup 配置文件：</p>
<pre><code>scp keepalived-backup.conf root@172.27.129.111:/etc/keepalived/keepalived.conf
scp keepalived-backup.conf root@172.27.129.112:/etc/keepalived/keepalived.conf
</code></pre>
<p>起 keepalived 服务</p>
<pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;ETCD_NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    ssh root@$&#123;node_ip&#125; &quot;systemctl restart keepalived&quot;
  done
</code></pre>
<p>检查 keepalived 服务<br> source /opt/k8s/bin/environment.sh<br> for node_ip in ${ETCD_NODE_IPS[@]}<br> do<br> echo “&gt;&gt;&gt; ${node_ip}”<br> ssh root@${node_ip} “systemctl status keepalived|grep Active”<br> done<br> 确保状态为 active (running)，否则查看日志（journalctl -u keepalived），确认原因：</p>
<blockquote>
<blockquote>
<blockquote>
<p>192.168.86.154<br> Active: active (running) since Tue 2018-11-06 10:54:01 CST; 17s ago</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>192.168.86.155<br> Active: active (running) since Tue 2018-11-06 10:54:03 CST; 18s ago</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>192.168.86.156<br> Active: active (running) since Tue 2018-11-06 10:54:03 CST; 17s ago</p>
</blockquote>
</blockquote>
</blockquote>
<p>查看 VIP 所在的节点，确保可以 ping 通 VIP：</p>
<p>source /opt/k8s/bin/environment.sh<br> for node_ip in ${NODE_IPS[@]}<br> do<br> echo “&gt;&gt;&gt; ${node_ip}”<br> ssh ${node_ip} “/usr/sbin/ip addr show ${VIP_IF}”<br> ssh ${node_ip} “ping -c 1 ${MASTER_VIP}”<br> done<br> 查看 haproxy 状态页面<br> 浏览器访问 ${MASTER_VIP}:10080/status 地址，查看 haproxy 状态页面：</p>
<h2 id="06-1-部署-kube-apiserver-组件"><a href="#06-1-部署-kube-apiserver-组件" class="headerlink" title="06-1.部署 kube-apiserver 组件"></a>06-1.部署 kube-apiserver 组件</h2><p>使用 keepalived 和 haproxy 部署一个 3 节点高可用 master 集群的步骤，对应的 LB VIP 为环境变量 ${MASTER_VIP}。</p>
<h3 id="创建-kubernetes-证书和私钥"><a href="#创建-kubernetes-证书和私钥" class="headerlink" title="创建 kubernetes 证书和私钥"></a>创建 kubernetes 证书和私钥</h3><pre><code>source /opt/k8s/bin/environment.sh
cat &gt; kubernetes-csr.json &lt;&lt;EOF
&#123;
  &quot;CN&quot;: &quot;kubernetes&quot;,
  &quot;hosts&quot;: [
    &quot;127.0.0.1&quot;,
    &quot;192.168.86.156&quot;,
    &quot;192.168.86.155&quot;,
    &quot;192.168.86.154&quot;,
    &quot;192.168.86.9&quot;,
    &quot;$&#123;MASTER_VIP&#125;&quot;,
    &quot;$&#123;CLUSTER_KUBERNETES_SVC_IP&#125;&quot;,
    &quot;kubernetes&quot;,
    &quot;kubernetes.default&quot;,
    &quot;kubernetes.default.svc&quot;,
    &quot;kubernetes.default.svc.local&quot;,
    &quot;kubernetes.default.svc.local.com&quot;
  ],
  &quot;key&quot;: &#123;
    &quot;algo&quot;: &quot;rsa&quot;,
    &quot;size&quot;: 2048
  &#125;,
  &quot;names&quot;: [
    &#123;
      &quot;C&quot;: &quot;CN&quot;,
      &quot;ST&quot;: &quot;BeiJing&quot;,
      &quot;L&quot;: &quot;BeiJing&quot;,
      &quot;O&quot;: &quot;k8s&quot;,
      &quot;OU&quot;: &quot;4Paradigm&quot;
    &#125;
  ]
&#125;
EOF
</code></pre>
<ul>
<li>hosts 字段指定授权使用该证书的 IP 或域名列表，这里列出了 VIP 、apiserver 节点 IP、kubernetes 服务 IP 和域名</li>
<li>域名最后字符不能是 .(如不能为 kubernetes.default.svc.cluster.local.)，否则解析时失败，提示： x509: cannot parse dnsName “kubernetes.default.svc.cluster.local.”；</li>
<li>如果使用非 cluster.local 域名，如 opsnull.com，则需要修改域名列表中的最后两个域名为：kubernetes.default.svc.opsnull、kubernetes.default.svc.opsnull.com</li>
<li>kubernetes 服务 IP 是 apiserver 自动创建的，一般是 –service-cluster-ip-range 参数指定的网段的第一个IP，后续可以通过如下命令获取：kubectl get svc kubernetes</li>
</ul>
<p>生成证书和私钥：</p>
<pre><code>cfssl gencert -ca=/etc/kubernetes/cert/ca.pem \
  -ca-key=/etc/kubernetes/cert/ca-key.pem \
  -config=/etc/kubernetes/cert/ca-config.json \
  -profile=kubernetes kubernetes-csr.json | cfssljson -bare kubernetes
ls kubernetes*pem
</code></pre>
<p>将生成的证书和私钥文件拷贝到 master 节点：</p>
<pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;ETCD_NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    ssh root@$&#123;node_ip&#125; &quot;mkdir -p /etc/kubernetes/cert/ &amp;&amp; sudo chown -R k8s /etc/kubernetes/cert/&quot;
    scp kubernetes*.pem k8s@$&#123;node_ip&#125;:/etc/kubernetes/cert/
  done
</code></pre>
<p>k8s 账户可以读写 /etc/kubernetes/cert/ 目录；</p>
<h3 id="创建加密配置文件"><a href="#创建加密配置文件" class="headerlink" title="创建加密配置文件"></a>创建加密配置文件</h3><pre><code>source /opt/k8s/bin/environment.sh
cat &gt; encryption-config.yaml &lt;&lt;EOF
kind: EncryptionConfig
apiVersion: v1
resources:
  - resources:
      - secrets
    providers:
      - aescbc:
          keys:
            - name: key1
              secret: $&#123;ENCRYPTION_KEY&#125;
      - identity: &#123;&#125;
EOF

将加密配置文件拷贝到 master 节点的 /etc/kubernetes 目录下：

source /opt/k8s/bin/environment.sh
for node_ip in $&#123;ETCD_NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    scp encryption-config.yaml root@$&#123;node_ip&#125;:/etc/kubernetes/
  done
</code></pre>
<h3 id="创建-kube-apiserver-systemd-unit-模板文件"><a href="#创建-kube-apiserver-systemd-unit-模板文件" class="headerlink" title="创建 kube-apiserver systemd unit 模板文件"></a>创建 kube-apiserver systemd unit 模板文件</h3><pre><code>source /opt/k8s/bin/environment.sh
cat &gt; kube-apiserver.service.template &lt;&lt;EOF
[Unit]
Description=Kubernetes API Server
Documentation=https://github.com/GoogleCloudPlatform/kubernetes
After=network.target

[Service]
ExecStart=/opt/k8s/bin/kube-apiserver \\
  --enable-admission-plugins=Initializers,NamespaceLifecycle,NodeRestriction,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota \\
  --anonymous-auth=false \\
  --experimental-encryption-provider-config=/etc/kubernetes/encryption-config.yaml \\
  --advertise-address=##NODE_IP## \\
  --bind-address=##NODE_IP## \\
  --insecure-port=0 \\
  --authorization-mode=Node,RBAC \\
  --runtime-config=api/all \\
  --enable-bootstrap-token-auth \\
  --service-cluster-ip-range=$&#123;SERVICE_CIDR&#125; \\
  --service-node-port-range=$&#123;NODE_PORT_RANGE&#125; \\
  --tls-cert-file=/etc/kubernetes/cert/kubernetes.pem \\
  --tls-private-key-file=/etc/kubernetes/cert/kubernetes-key.pem \\
  --client-ca-file=/etc/kubernetes/cert/ca.pem \\
  --kubelet-client-certificate=/etc/kubernetes/cert/kubernetes.pem \\
  --kubelet-client-key=/etc/kubernetes/cert/kubernetes-key.pem \\
  --service-account-key-file=/etc/kubernetes/cert/ca-key.pem \\
  --etcd-cafile=/etc/kubernetes/cert/ca.pem \\
  --etcd-certfile=/etc/kubernetes/cert/kubernetes.pem \\
  --etcd-keyfile=/etc/kubernetes/cert/kubernetes-key.pem \\
  --etcd-servers=$&#123;ETCD_ENDPOINTS&#125; \\
  --enable-swagger-ui=true \\
  --allow-privileged=true \\
  --apiserver-count=3 \\
  --audit-log-maxage=30 \\
  --audit-log-maxbackup=3 \\
  --audit-log-maxsize=100 \\
  --audit-log-path=/var/log/kube-apiserver-audit.log \\
  --event-ttl=1h \\
  --alsologtostderr=true \\
  --logtostderr=false \\
  --log-dir=/var/log/kubernetes \\
  --v=2
Restart=on-failure
RestartSec=5
Type=notify
User=k8s
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target
EOF
</code></pre>
<ul>
<li>–experimental-encryption-provider-config：启用加密特性；</li>
<li>–authorization-mode=Node,RBAC： 开启 Node 和 RBAC 授权模式，拒绝未授权的请求；</li>
<li>–enable-admission-plugins：启用 ServiceAccount 和 NodeRestriction；</li>
<li>–service-account-key-file：签名 ServiceAccount Token 的公钥文件，kube-controller-manager 的 –service-account-private-key-file 指定私钥文件，两者配对使用；</li>
<li>–tls-*-file：指定 apiserver 使用的证书、私钥和 CA 文件。–client-ca-file 用于验证 client (kue-controller-manager、kube-scheduler、kubelet、kube-proxy 等)请求所带的证书；</li>
<li>–kubelet-client-certificate、–kubelet-client-key：如果指定，则使用 https 访问 kubelet APIs；需要为证书对应的用户(上面 kubernetes*.pem 证书的用户为 kubernetes) 用户定义 RBAC 规则，否则访问 kubelet API * 时提示未授权；</li>
<li>–bind-address： 不能为 127.0.0.1，否则外界不能访问它的安全端口 6443；</li>
<li>–insecure-port=0：关闭监听非安全端口(8080)；</li>
<li>–service-cluster-ip-range： 指定 Service Cluster IP 地址段；</li>
<li>–service-node-port-range： 指定 NodePort 的端口范围；</li>
<li>–runtime-config=api/all=true： 启用所有版本的 APIs，如 autoscaling/v2alpha1；</li>
<li>–enable-bootstrap-token-auth：启用 kubelet bootstrap 的 token 认证；</li>
<li>–apiserver-count=3：指定集群运行模式，多台 kube-apiserver 会通过 leader 选举产生一个工作节点，其它节点处于阻塞状态；</li>
<li>User=k8s：使用 k8s 账户运行；</li>
</ul>
<h3 id="为各节点创建和分发-kube-apiserver-systemd-unit-文件"><a href="#为各节点创建和分发-kube-apiserver-systemd-unit-文件" class="headerlink" title="为各节点创建和分发 kube-apiserver systemd unit 文件"></a>为各节点创建和分发 kube-apiserver systemd unit 文件</h3><p>替换模板文件中的变量，为各节点创建 systemd unit 文件：</p>
<pre><code>source /opt/k8s/bin/environment.sh
for (( i=0; i &lt; 3; i++ ))
  do
    sed -e &quot;s/##NODE_NAME##/$&#123;NODE_NAMES[i]&#125;/&quot; -e &quot;s/##NODE_IP##/$&#123;NODE_IPS[i]&#125;/&quot; kube-apiserver.service.template &gt; kube-apiserver-$&#123;NODE_IPS[i]&#125;.service 
  done
ls kube-apiserver*.service
</code></pre>
<p>分发生成的 systemd unit 文件</p>
<pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;ETCD_NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    ssh root@$&#123;node_ip&#125; &quot;mkdir -p /var/log/kubernetes &amp;&amp; chown -R k8s /var/log/kubernetes&quot;
    scp kube-apiserver-$&#123;node_ip&#125;.service root@$&#123;node_ip&#125;:/etc/systemd/system/kube-apiserver.service
  done
</code></pre>
<h3 id="启动-kube-apiserver-服务"><a href="#启动-kube-apiserver-服务" class="headerlink" title="启动 kube-apiserver 服务"></a>启动 kube-apiserver 服务</h3><p>source /opt/k8s/bin/environment.sh<br> for node_ip in ${ETCD_NODE_IPS[@]}<br> do<br> echo “&gt;&gt;&gt; ${node_ip}”<br> ssh root@${node_ip} “systemctl daemon-reload &amp;&amp; systemctl enable kube-apiserver &amp;&amp; systemctl restart kube-apiserver”<br> done</p>
<h3 id="检查-kube-apiserver-运行状态"><a href="#检查-kube-apiserver-运行状态" class="headerlink" title="检查 kube-apiserver 运行状态"></a>检查 kube-apiserver 运行状态</h3><pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;ETCD_NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    ssh root@$&#123;node_ip&#125; &quot;systemctl status kube-apiserver |grep &#39;Active:&#39;&quot;
  done
</code></pre>
<p>确保状态为 active (running)，否则到 master 节点查看日志，确认原因：</p>
<p>journalctl -u kube-apiserver</p>
<h3 id="打印-kube-apiserver-写入-etcd-的数据"><a href="#打印-kube-apiserver-写入-etcd-的数据" class="headerlink" title="打印 kube-apiserver 写入 etcd 的数据"></a>打印 kube-apiserver 写入 etcd 的数据</h3><p>source /opt/k8s/bin/environment.sh<br> ETCDCTL_API=3 etcdctl<br> –endpoints=${ETCD_ENDPOINTS}<br> –cacert=/etc/kubernetes/cert/ca.pem<br> –cert=/etc/etcd/cert/etcd.pem<br> –key=/etc/etcd/cert/etcd-key.pem<br> get /registry/ –prefix –keys-only</p>
<p>检查集群信息</p>
<pre><code>kubectl cluster-info
kubectl get all --all-namespaces
kubectl get componentstatuses
</code></pre>
<p>检查 kube-apiserver 监听的端口<br> sudo netstat -lnpt|grep kube<br> tcp        0      0 172.27.129.105:6443     0.0.0.0:*               LISTEN      13075/kube-apiserve</p>
<p>6443: 接收 https 请求的安全端口，对所有请求做认证和授权；<br> 由于关闭了非安全端口，故没有监听 8080；</p>
<h3 id="授予-kubernetes-证书访问-kubelet-API-的权限"><a href="#授予-kubernetes-证书访问-kubelet-API-的权限" class="headerlink" title="授予 kubernetes 证书访问 kubelet API 的权限"></a>授予 kubernetes 证书访问 kubelet API 的权限</h3><p>在执行 kubectl exec、run、logs 等命令时，apiserver 会转发到 kubelet。这里定义 RBAC 规则，授权 apiserver 调用 kubelet API。</p>
<pre><code>kubectl create clusterrolebinding kube-apiserver:kubelet-apis --clusterrole=system:kubelet-api-admin --user kubernetes
</code></pre>
<h2 id="06-3-部署高可用-kube-controller-manager-集群"><a href="#06-3-部署高可用-kube-controller-manager-集群" class="headerlink" title="06-3.部署高可用 kube-controller-manager 集群"></a>06-3.部署高可用 kube-controller-manager 集群</h2><p>该集群包含 3 个节点，启动后将通过竞争选举机制产生一个 leader 节点，其它节点为阻塞状态。当 leader 节点不可用后，剩余节点将再次进行选举产生新的 leader 节点，从而保证服务的可用性。</p>
<p>为保证通信安全，本文档先生成 x509 证书和私钥，kube-controller-manager 在如下两种情况下使用该证书：</p>
<p>与 kube-apiserver 的安全端口通信时;<br> 在安全端口(https，10252) 输出 prometheus 格式的 metrics；</p>
<h3 id="创建-kube-controller-manager-证书和私钥"><a href="#创建-kube-controller-manager-证书和私钥" class="headerlink" title="创建 kube-controller-manager 证书和私钥"></a>创建 kube-controller-manager 证书和私钥</h3><p>创建证书签名请求：</p>
<pre><code>cat &gt; kube-controller-manager-csr.json &lt;&lt;EOF
&#123;
    &quot;CN&quot;: &quot;system:kube-controller-manager&quot;,
    &quot;key&quot;: &#123;
        &quot;algo&quot;: &quot;rsa&quot;,
        &quot;size&quot;: 2048
    &#125;,
    &quot;hosts&quot;: [
      &quot;127.0.0.1&quot;,
      &quot;192.168.86.156&quot;,  &quot;192.168.86.155&quot;,  &quot;192.168.86.154&quot;
    ],
    &quot;names&quot;: [
      &#123;
        &quot;C&quot;: &quot;CN&quot;,
        &quot;ST&quot;: &quot;BeiJing&quot;,
        &quot;L&quot;: &quot;BeiJing&quot;,
        &quot;O&quot;: &quot;system:kube-controller-manager&quot;,
        &quot;OU&quot;: &quot;4Paradigm&quot;
      &#125;
    ]
&#125;
EOF
</code></pre>
<p>hosts 列表包含所有 kube-controller-manager 节点 IP；<br> CN 为 system:kube-controller-manager、O 为 system:kube-controller-manager，kubernetes 内置的 ClusterRoleBindings system:kube-controller-manager 赋予 kube-controller-manager 工作所需的权限。<br> 生成证书和私钥：</p>
<pre><code>cfssl gencert -ca=/etc/kubernetes/cert/ca.pem \
  -ca-key=/etc/kubernetes/cert/ca-key.pem \
  -config=/etc/kubernetes/cert/ca-config.json \
  -profile=kubernetes kube-controller-manager-csr.json | cfssljson -bare kube-controller-manager
</code></pre>
<p>将生成的证书和私钥分发到所有 master 节点：</p>
<pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;ETCD_NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    scp kube-controller-manager*.pem k8s@$&#123;node_ip&#125;:/etc/kubernetes/cert/
  done
</code></pre>
<h3 id="创建和分发-kubeconfig-文件"><a href="#创建和分发-kubeconfig-文件" class="headerlink" title="创建和分发 kubeconfig 文件"></a>创建和分发 kubeconfig 文件</h3><p>kubeconfig 文件包含访问 apiserver 的所有信息，如 apiserver 地址、CA 证书和自身使用的证书；</p>
<pre><code>source /opt/k8s/bin/environment.sh
kubectl config set-cluster kubernetes \
  --certificate-authority=/etc/kubernetes/cert/ca.pem \
  --embed-certs=true \
  --server=$&#123;KUBE_APISERVER&#125; \
  --kubeconfig=kube-controller-manager.kubeconfig

kubectl config set-credentials system:kube-controller-manager \
  --client-certificate=kube-controller-manager.pem \
  --client-key=kube-controller-manager-key.pem \
  --embed-certs=true \
  --kubeconfig=kube-controller-manager.kubeconfig

kubectl config set-context system:kube-controller-manager \
  --cluster=kubernetes \
  --user=system:kube-controller-manager \
  --kubeconfig=kube-controller-manager.kubeconfig

kubectl config use-context system:kube-controller-manager --kubeconfig=kube-controller-manager.kubeconfig
</code></pre>
<p>分发 kubeconfig 到所有 master 节点：</p>
<pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;ETCD_NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    scp kube-controller-manager.kubeconfig k8s@$&#123;node_ip&#125;:/etc/kubernetes/
  done
</code></pre>
<h3 id="创建和分发-kube-controller-manager-systemd-unit-文件"><a href="#创建和分发-kube-controller-manager-systemd-unit-文件" class="headerlink" title="创建和分发 kube-controller-manager systemd unit 文件"></a>创建和分发 kube-controller-manager systemd unit 文件</h3><pre><code>source /opt/k8s/bin/environment.sh
cat &gt; kube-controller-manager.service &lt;&lt;EOF
[Unit]
Description=Kubernetes Controller Manager
Documentation=https://github.com/GoogleCloudPlatform/kubernetes

[Service]
ExecStart=/opt/k8s/bin/kube-controller-manager \\
  --port=0 \\
  --secure-port=10252 \\
  --bind-address=127.0.0.1 \\
  --kubeconfig=/etc/kubernetes/kube-controller-manager.kubeconfig \\
  --service-cluster-ip-range=$&#123;SERVICE_CIDR&#125; \\
  --cluster-name=kubernetes \\
  --cluster-signing-cert-file=/etc/kubernetes/cert/ca.pem \\
  --cluster-signing-key-file=/etc/kubernetes/cert/ca-key.pem \\
  --experimental-cluster-signing-duration=17520h \\
  --root-ca-file=/etc/kubernetes/cert/ca.pem \\
  --service-account-private-key-file=/etc/kubernetes/cert/ca-key.pem \\
  --leader-elect=true \\
  --feature-gates=RotateKubeletServerCertificate=true \\
  --controllers=*,bootstrapsigner,tokencleaner \\
  --horizontal-pod-autoscaler-use-rest-clients=true \\
  --horizontal-pod-autoscaler-sync-period=10s \\
  --tls-cert-file=/etc/kubernetes/cert/kube-controller-manager.pem \\
  --tls-private-key-file=/etc/kubernetes/cert/kube-controller-manager-key.pem \\
  --use-service-account-credentials=true \\
  --alsologtostderr=true \\
  --logtostderr=false \\
  --log-dir=/var/log/kubernetes \\
  --v=2
Restart=on
Restart=on-failure
RestartSec=5
User=k8s

[Install]
WantedBy=multi-user.target
EOF
</code></pre>
<ul>
<li>–port=0：关闭监听 http /metrics 的请求，同时 –address 参数无效，–bind-address 参数有效；</li>
<li>–secure-port=10252、–bind-address=0.0.0.0: 在所有网络接口监听 10252 端口的 https /metrics 请求；</li>
<li>–kubeconfig：指定 kubeconfig 文件路径，kube-controller-manager 使用它连接和验证 kube-apiserver；</li>
<li>–cluster-signing-*-file：签名 TLS Bootstrap 创建的证书；</li>
<li>–experimental-cluster-signing-duration：指定 TLS Bootstrap 证书的有效期；</li>
<li>–root-ca-file：放置到容器 ServiceAccount 中的 CA 证书，用来对 kube-apiserver 的证书进行校验；</li>
<li>–service-account-private-key-file：签名 ServiceAccount 中 Token 的私钥文件，必须和 kube-apiserver 的 –service-account-key-file 指定的公钥文件配对使用；</li>
<li>–service-cluster-ip-range ：指定 Service Cluster IP 网段，必须和 kube-apiserver 中的同名参数一致；</li>
<li>–leader-elect=true：集群运行模式，启用选举功能；被选为 leader 的节点负责处理工作，其它节点为阻塞状态；</li>
<li>–feature-gates=RotateKubeletServerCertificate=true：开启 kublet server 证书的自动更新特性；</li>
<li>–controllers=*,bootstrapsigner,tokencleaner：启用的控制器列表，tokencleaner 用于自动清理过期的 Bootstrap token；</li>
<li>–horizontal-pod-autoscaler-*：custom metrics 相关参数，支持 autoscaling/v2alpha1；</li>
<li>–tls-cert-file、–tls-private-key-file：使用 https 输出 metrics 时使用的 Server 证书和秘钥；</li>
<li>–use-service-account-credentials=true:</li>
<li>User=k8s：使用 k8s 账户运行；</li>
<li>kube-controller-manager 不对请求 https metrics 的 Client 证书进行校验，故不需要指定 –tls-ca-file 参数，而且该参数已被淘汰。</li>
</ul>
<p>分发 systemd unit 文件到所有 master 节点：</p>
<pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;ETCD_NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    scp kube-controller-manager.service root@$&#123;node_ip&#125;:/etc/systemd/system/
  done
</code></pre>
<h3 id="kube-controller-manager-的权限"><a href="#kube-controller-manager-的权限" class="headerlink" title="kube-controller-manager 的权限"></a>kube-controller-manager 的权限</h3><p>ClusteRole: system:kube-controller-manager 的权限很小，只能创建 secret、serviceaccount 等资源对象，各 controller 的权限分散到 ClusterRole system:controller:XXX 中。</p>
<p>需要在 kube-controller-manager 的启动参数中添加 –use-service-account-credentials=true 参数，这样 main controller 会为各 controller 创建对应的 ServiceAccount XXX-controller。</p>
<p>内置的 ClusterRoleBinding system:controller:XXX 将赋予各 XXX-controller ServiceAccount 对应的 ClusterRole system:controller:XXX 权限。</p>
<h3 id="启动-kube-controller-manager-服务"><a href="#启动-kube-controller-manager-服务" class="headerlink" title="启动 kube-controller-manager 服务"></a>启动 kube-controller-manager 服务</h3><pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;ETCD_NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    ssh root@$&#123;node_ip&#125; &quot;mkdir -p /var/log/kubernetes &amp;&amp; chown -R k8s /var/log/kubernetes&quot;
    ssh root@$&#123;node_ip&#125; &quot;systemctl daemon-reload &amp;&amp; systemctl enable kube-controller-manager &amp;&amp; systemctl restart kube-controller-manager&quot;
  done
</code></pre>
<p>必须先创建日志目录；</p>
<h3 id="检查服务运行状态"><a href="#检查服务运行状态" class="headerlink" title="检查服务运行状态"></a>检查服务运行状态</h3><p>source /opt/k8s/bin/environment.sh<br> for node_ip in ${ETCD_NODE_IPS[@]}<br> do<br> echo “&gt;&gt;&gt; ${node_ip}”<br> ssh k8s@${node_ip} “systemctl status kube-controller-manager|grep Active”<br> done<br> 确保状态为 active (running)，否则查看日志，确认原因：</p>
<pre><code>$ journalctl -u kube-controller-manager
</code></pre>
<h3 id="查看输出的-metric"><a href="#查看输出的-metric" class="headerlink" title="查看输出的 metric"></a>查看输出的 metric</h3><p>注意：以下命令在 kube-controller-manager 节点上执行。</p>
<p>kube-controller-manager 监听 10252 端口，接收 https 请求：</p>
<pre><code>$ sudo netstat -lnpt|grep kube-controll
tcp        0      0 127.0.0.1:10252         0.0.0.0:*               LISTEN      18377/kube-controll
$ curl -s --cacert /etc/kubernetes/cert/ca.pem https://127.0.0.1:10252/metrics |head
# HELP ClusterRoleAggregator_adds Total number of adds handled by workqueue: ClusterRoleAggregator
# TYPE ClusterRoleAggregator_adds counter
ClusterRoleAggregator_adds 3
# HELP ClusterRoleAggregator_depth Current depth of workqueue: ClusterRoleAggregator
# TYPE ClusterRoleAggregator_depth gauge
ClusterRoleAggregator_depth 0
# HELP ClusterRoleAggregator_queue_latency How long an item stays in workqueueClusterRoleAggregator before being requested.
# TYPE ClusterRoleAggregator_queue_latency summary
ClusterRoleAggregator_queue_latency&#123;quantile=&quot;0.5&quot;&#125; 57018
ClusterRoleAggregator_queue_latency&#123;quantile=&quot;0.9&quot;&#125; 57268
</code></pre>
<p>curl –cacert CA 证书用来验证 kube-controller-manager https server 证书；<br> 测试 kube-controller-manager 集群的高可用<br> 停掉一个或两个节点的 kube-controller-manager 服务，观察其它节点的日志，看是否获取了 leader 权限。</p>
<h3 id="查看当前的-leader"><a href="#查看当前的-leader" class="headerlink" title="查看当前的 leader"></a>查看当前的 leader</h3><pre><code>$ kubectl get endpoints kube-controller-manager --namespace=kube-system  -o yaml
apiVersion: v1
kind: Endpoints
metadata:
  annotations:
    control-plane.alpha.kubernetes.io/leader: &#39;&#123;&quot;holderIdentity&quot;:&quot;docker86-155_32dbaca9-e15f-11e8-87e7-e0db5521eb14&quot;,&quot;leaseDurationSeconds&quot;:15,&quot;acquireTime&quot;:&quot;2018-11-06T00:59:52Z&quot;,&quot;renewTime&quot;:&quot;2018-11-06T01:34:01Z&quot;,&quot;leaderTransitions&quot;:39&#125;&#39;
  creationTimestamp: 2018-10-10T15:18:11Z
  name: kube-controller-manager
  namespace: kube-system
  resourceVersion: &quot;6281708&quot;
  selfLink: /api/v1/namespaces/kube-system/endpoints/kube-controller-manager
  uid: b38d3ea9-cc9f-11e8-9cde-d4ae52a3b675
</code></pre>
<p>可见，当前的 leader 为docker86-155 节点。</p>
<p>参考<br> 关于 controller 权限和 use-service-account-credentials 参数：<a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/issues/48208">https://github.com/kubernetes/kubernetes/issues/48208</a><br> kublet 认证和授权：<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/admin/kubelet-authentication-authorization/#kubelet-authorization">https://kubernetes.io/docs/admin/kubelet-authentication-authorization/#kubelet-authorization</a></p>
<h2 id="06-3-部署高可用-kube-scheduler-集群"><a href="#06-3-部署高可用-kube-scheduler-集群" class="headerlink" title="06-3.部署高可用 kube-scheduler 集群"></a>06-3.部署高可用 kube-scheduler 集群</h2><p>该集群包含 3 个节点，启动后将通过竞争选举机制产生一个 leader 节点，其它节点为阻塞状态。当 leader 节点不可用后，剩余节点将再次进行选举产生新的 leader 节点，从而保证服务的可用性。</p>
<p>为保证通信安全，本文档先生成 x509 证书和私钥，kube-scheduler 在如下两种情况下使用该证书：</p>
<p>与 kube-apiserver 的安全端口通信;<br> 在安全端口(https，10251) 输出 prometheus 格式的 metrics；</p>
<h3 id="创建-kube-scheduler-证书和私钥"><a href="#创建-kube-scheduler-证书和私钥" class="headerlink" title="创建 kube-scheduler 证书和私钥"></a>创建 kube-scheduler 证书和私钥</h3><pre><code>cat &gt; kube-scheduler-csr.json &lt;&lt;EOF
&#123;
    &quot;CN&quot;: &quot;system:kube-scheduler&quot;,
    &quot;hosts&quot;: [
      &quot;127.0.0.1&quot;,
      &quot;192.168.86.156&quot;,  &quot;192.168.86.155&quot;,  &quot;192.168.86.154&quot;
    ],
    &quot;key&quot;: &#123;
        &quot;algo&quot;: &quot;rsa&quot;,
        &quot;size&quot;: 2048
    &#125;,
    &quot;names&quot;: [
      &#123;
        &quot;C&quot;: &quot;CN&quot;,
        &quot;ST&quot;: &quot;BeiJing&quot;,
        &quot;L&quot;: &quot;BeiJing&quot;,
        &quot;O&quot;: &quot;system:kube-scheduler&quot;,
        &quot;OU&quot;: &quot;4Paradigm&quot;
      &#125;
    ]
&#125;
EOF
</code></pre>
<p>生成证书和私钥：</p>
<pre><code>cfssl gencert -ca=/etc/kubernetes/cert/ca.pem \
  -ca-key=/etc/kubernetes/cert/ca-key.pem \
  -config=/etc/kubernetes/cert/ca-config.json \
  -profile=kubernetes kube-scheduler-csr.json | cfssljson -bare kube-scheduler
</code></pre>
<h3 id="创建和分发-kubeconfig-文件-1"><a href="#创建和分发-kubeconfig-文件-1" class="headerlink" title="创建和分发 kubeconfig 文件"></a>创建和分发 kubeconfig 文件</h3><p>kubeconfig 文件包含访问 apiserver 的所有信息，如 apiserver 地址、CA 证书和自身使用的证书；</p>
<pre><code>source /opt/k8s/bin/environment.sh
kubectl config set-cluster kubernetes \
  --certificate-authority=/etc/kubernetes/cert/ca.pem \
  --embed-certs=true \
  --server=$&#123;KUBE_APISERVER&#125; \
  --kubeconfig=kube-scheduler.kubeconfig

kubectl config set-credentials system:kube-scheduler \
  --client-certificate=kube-scheduler.pem \
  --client-key=kube-scheduler-key.pem \
  --embed-certs=true \
  --kubeconfig=kube-scheduler.kubeconfig

kubectl config set-context system:kube-scheduler \
  --cluster=kubernetes \
  --user=system:kube-scheduler \
  --kubeconfig=kube-scheduler.kubeconfig

kubectl config use-context system:kube-scheduler --kubeconfig=kube-scheduler.kubeconfig
</code></pre>
<p>分发 kubeconfig 到所有 master 节点：</p>
<pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;ETCD_NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    scp kube-scheduler.kubeconfig k8s@$&#123;node_ip&#125;:/etc/kubernetes/
  done
</code></pre>
<h3 id="创建和分发-kube-scheduler-systemd-unit-文件"><a href="#创建和分发-kube-scheduler-systemd-unit-文件" class="headerlink" title="创建和分发 kube-scheduler systemd unit 文件"></a>创建和分发 kube-scheduler systemd unit 文件</h3><pre><code>cat &gt; kube-scheduler.service &lt;&lt;EOF
[Unit]
Description=Kubernetes Scheduler
Documentation=https://github.com/GoogleCloudPlatform/kubernetes

[Service]
ExecStart=/opt/k8s/bin/kube-scheduler \\
  --address=127.0.0.1 \\
  --kubeconfig=/etc/kubernetes/kube-scheduler.kubeconfig \\
  --leader-elect=true \\
  --alsologtostderr=true \\
  --logtostderr=false \\
  --log-dir=/var/log/kubernetes \\
  --v=2
Restart=on-failure
RestartSec=5
User=k8s

[Install]
WantedBy=multi-user.target
EOF
</code></pre>
<p>–address：在 127.0.0.1:10251 端口接收 http /metrics 请求；kube-scheduler 目前还不支持接收 https 请求；<br> –kubeconfig：指定 kubeconfig 文件路径，kube-scheduler 使用它连接和验证 kube-apiserver；<br> –leader-elect=true：集群运行模式，启用选举功能；被选为 leader 的节点负责处理工作，其它节点为阻塞状态；<br> User=k8s：使用 k8s 账户运行；</p>
<h3 id="分发-systemd-unit-文件到所有-master-节点："><a href="#分发-systemd-unit-文件到所有-master-节点：" class="headerlink" title="分发 systemd unit 文件到所有 master 节点："></a>分发 systemd unit 文件到所有 master 节点：</h3><pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;ETCD_NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    scp kube-scheduler.service root@$&#123;node_ip&#125;:/etc/systemd/system/
  done
</code></pre>
<h3 id="启动-kube-scheduler-服务"><a href="#启动-kube-scheduler-服务" class="headerlink" title="启动 kube-scheduler 服务"></a>启动 kube-scheduler 服务</h3><pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;ETCD_NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    ssh root@$&#123;node_ip&#125; &quot;mkdir -p /var/log/kubernetes &amp;&amp; chown -R k8s /var/log/kubernetes&quot;
    ssh root@$&#123;node_ip&#125; &quot;systemctl daemon-reload &amp;&amp; systemctl enable kube-scheduler &amp;&amp; systemctl restart kube-scheduler&quot;
  done
</code></pre>
<p>必须先创建日志目录；</p>
<p>检查服务运行状态<br> source /opt/k8s/bin/environment.sh<br> for node_ip in ${ETCD_NODE_IPS[@]}<br> do<br> echo “&gt;&gt;&gt; ${node_ip}”<br> ssh k8s@${node_ip} “systemctl status kube-scheduler|grep Active”<br> done</p>
<p>确保状态为 active (running)，否则查看日志，确认原因：</p>
<pre><code>journalctl -u kube-scheduler
</code></pre>
<h3 id="查看输出的-metric-1"><a href="#查看输出的-metric-1" class="headerlink" title="查看输出的 metric"></a>查看输出的 metric</h3><p>注意：以下命令在 kube-scheduler 节点上执行。</p>
<p>kube-scheduler 监听 10251 端口，接收 http 请求：</p>
<p>$ sudo netstat -lnpt|grep kube-sche<br> tcp        0      0 127.0.0.1:10251         0.0.0.0:*               LISTEN      23783/kube-schedule<br> $ curl -s <a target="_blank" rel="noopener" href="http://127.0.0.1:10251/metrics">http://127.0.0.1:10251/metrics</a> |head</p>
<h1 id="HELP-apiserver-audit-event-total-Counter-of-audit-events-generated-and-sent-to-the-audit-backend"><a href="#HELP-apiserver-audit-event-total-Counter-of-audit-events-generated-and-sent-to-the-audit-backend" class="headerlink" title="HELP apiserver_audit_event_total Counter of audit events generated and sent to the audit backend."></a>HELP apiserver_audit_event_total Counter of audit events generated and sent to the audit backend.</h1><h1 id="TYPE-apiserver-audit-event-total-counter"><a href="#TYPE-apiserver-audit-event-total-counter" class="headerlink" title="TYPE apiserver_audit_event_total counter"></a>TYPE apiserver_audit_event_total counter</h1><p>apiserver_audit_event_total 0</p>
<h1 id="HELP-go-gc-duration-seconds-A-summary-of-the-GC-invocation-durations"><a href="#HELP-go-gc-duration-seconds-A-summary-of-the-GC-invocation-durations" class="headerlink" title="HELP go_gc_duration_seconds A summary of the GC invocation durations."></a>HELP go_gc_duration_seconds A summary of the GC invocation durations.</h1><h1 id="TYPE-go-gc-duration-seconds-summary"><a href="#TYPE-go-gc-duration-seconds-summary" class="headerlink" title="TYPE go_gc_duration_seconds summary"></a>TYPE go_gc_duration_seconds summary</h1><p>go_gc_duration_seconds{quantile=”0”} 9.7715e-05<br> go_gc_duration_seconds{quantile=”0.25”} 0.000107676<br> go_gc_duration_seconds{quantile=”0.5”} 0.00017868<br> go_gc_duration_seconds{quantile=”0.75”} 0.000262444<br> go_gc_duration_seconds{quantile=”1”} 0.001205223</p>
<h3 id="测试-kube-scheduler-集群的高可用"><a href="#测试-kube-scheduler-集群的高可用" class="headerlink" title="测试 kube-scheduler 集群的高可用"></a>测试 kube-scheduler 集群的高可用</h3><p>随便找一个或两个 master 节点，停掉 kube-scheduler 服务，看其它节点是否获取了 leader 权限（systemd 日志）。</p>
<p>查看当前的 leader<br> $ kubectl get endpoints kube-scheduler –namespace=kube-system  -o yaml<br> apiVersion: v1<br> kind: Endpoints<br> metadata:<br> annotations:<br> control-plane.alpha.kubernetes.io/leader: ‘{“holderIdentity”:”kube-node3_61f34593-6cc8-11e8-8af7-5254002f288e”,”leaseDurationSeconds”:15,”acquireTime”:”2018-06-10T16:09:56Z”,”renewTime”:”2018-06-10T16:20:54Z”,”leaderTransitions”:1}’<br> creationTimestamp: 2018-06-10T16:07:33Z<br> name: kube-scheduler<br> namespace: kube-system<br> resourceVersion: “4645”<br> selfLink: /api/v1/namespaces/kube-system/endpoints/kube-scheduler<br> uid: 62382d98-6cc8-11e8-96fa-525400ba84c6</p>
<h2 id="07-1-部署-docker-组件"><a href="#07-1-部署-docker-组件" class="headerlink" title="07-1.部署 docker 组件"></a>07-1.部署 docker 组件</h2><p>docker 是容器的运行环境，管理它的生命周期。kubelet 通过 Container Runtime Interface (CRI) 与 docker 进行交互。</p>
<h3 id="安装依赖包"><a href="#安装依赖包" class="headerlink" title="安装依赖包"></a>安装依赖包</h3><p>参考 <a href="07-0.%E9%83%A8%E7%BD%B2worker%E8%8A%82%E7%82%B9.md">07-0.部署worker节点.md</a></p>
<h3 id="下载和分发-docker-二进制文件"><a href="#下载和分发-docker-二进制文件" class="headerlink" title="下载和分发 docker 二进制文件"></a>下载和分发 docker 二进制文件</h3><p>到 <a target="_blank" rel="noopener" href="http://mirrors.ustc.edu.cn/docker-ce/linux/static/stable/x86_64/">http://mirrors.ustc.edu.cn/docker-ce/linux/static/stable/x86_64/</a> 页面下载最新发布包：</p>
<pre><code>wget http://mirrors.ustc.edu.cn/docker-ce/linux/static/stable/x86_64/docker-18.06.1-ce.tgz
tar -xvf docker-18.06.1-ce.tgz
</code></pre>
<p>分发二进制文件到所有 worker 节点：</p>
<pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    scp docker/docker*  k8s@$&#123;node_ip&#125;:/opt/k8s/bin/
    ssh k8s@$&#123;node_ip&#125; &quot;chmod +x /opt/k8s/bin/*&quot;
  done
</code></pre>
<h3 id="创建和分发-systemd-unit-文件"><a href="#创建和分发-systemd-unit-文件" class="headerlink" title="创建和分发 systemd unit 文件"></a>创建和分发 systemd unit 文件</h3><pre><code>cat &gt; docker.service &lt;&lt;&quot;EOF&quot;
[Unit]
Description=Docker Application Container Engine
Documentation=http://docs.docker.io

[Service]
Environment=&quot;PATH=/opt/k8s/bin:/bin:/sbin:/usr/bin:/usr/sbin&quot;
EnvironmentFile=-/run/flannel/docker
ExecStart=/opt/k8s/bin/dockerd --log-level=error $DOCKER_NETWORK_OPTIONS
ExecReload=/bin/kill -s HUP $MAINPID
Restart=on-failure
RestartSec=5
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity
Delegate=yes
KillMode=process

[Install]
WantedBy=multi-user.target
EOF
</code></pre>
<ul>
<li>EOF 前后有双引号，这样 bash 不会替换文档中的变量，如 $DOCKER_NETWORK_OPTIONS；</li>
<li>dockerd 运行时会调用其它 docker 命令，如 docker-proxy，所以需要将 docker 命令所在的目录加到 PATH 环境变量中；</li>
<li>flanneld 启动时将网络配置写入 <code>/run/flannel/docker</code> 文件中，dockerd 启动前读取该文件中的环境变量 <code>DOCKER_NETWORK_OPTIONS</code> ，然后设置 docker0 网桥网段；</li>
<li>如果指定了多个 <code>EnvironmentFile</code> 选项，则必须将 <code>/run/flannel/docker</code> 放在最后(确保 docker0 使用 flanneld 生成的 bip 参数)；</li>
<li>docker 需要以 root 用于运行；</li>
<li>docker 从 1.13 版本开始，可能将 <strong>iptables FORWARD chain的默认策略设置为DROP</strong>，从而导致 ping 其它 Node 上的 Pod IP 失败，遇到这种情况时，需要手动设置策略为 <code>ACCEPT</code>：</li>
</ul>
<pre><code>    $ sudo iptables -P FORWARD ACCEPT

并且把以下命令写入 `/etc/rc.local` 文件中，防止节点重启**iptables FORWARD chain的默认策略又还原为DROP**


    /sbin/iptables -P FORWARD ACCEPT
</code></pre>
<p>完整 unit 见 <a target="_blank" rel="noopener" href="https://github.com/opsnull/follow-me-install-kubernetes-cluster/blob/master/systemd/docker.service">docker.service</a></p>
<p>分发 systemd unit 文件到所有 worker 机器:</p>
<pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    scp docker.service root@$&#123;node_ip&#125;:/etc/systemd/system/
  done
</code></pre>
<h3 id="配置和分发-docker-配置文件"><a href="#配置和分发-docker-配置文件" class="headerlink" title="配置和分发 docker 配置文件"></a>配置和分发 docker 配置文件</h3><p>使用国内的仓库镜像服务器以加快 pull image 的速度，同时增加下载的并发数 (需要重启 dockerd 生效)：</p>
<pre><code>cat &gt; docker-daemon.json &lt;&lt;EOF
&#123;&quot;insecure-registries&quot;:[&quot;192.168.86.8:5000&quot;,&quot;registry.xxx.com&quot;],
    &quot;registry-mirrors&quot;: [&quot;https://jk4bb75a.mirror.aliyuncs.com&quot;, &quot;https://docker.mirrors.ustc.edu.cn&quot;],
    &quot;max-concurrent-downloads&quot;: 20
&#125;
EOF
</code></pre>
<p>分发 docker 配置文件到所有 work 节点：</p>
<pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    ssh root@$&#123;node_ip&#125; &quot;mkdir -p  /etc/docker/&quot;
    scp docker-daemon.json root@$&#123;node_ip&#125;:/etc/docker/daemon.json
  done
</code></pre>
<h3 id="启动-docker-服务"><a href="#启动-docker-服务" class="headerlink" title="启动 docker 服务"></a>启动 docker 服务</h3><pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    ssh root@$&#123;node_ip&#125; &quot;systemctl stop firewalld &amp;&amp; systemctl disable firewalld&quot;
    ssh root@$&#123;node_ip&#125; &quot;/usr/sbin/iptables -F &amp;&amp; /usr/sbin/iptables -X &amp;&amp; /usr/sbin/iptables -F -t nat &amp;&amp; /usr/sbin/iptables -X -t nat&quot;
    ssh root@$&#123;node_ip&#125; &quot;/usr/sbin/iptables -P FORWARD ACCEPT&quot;
    ssh root@$&#123;node_ip&#125; &quot;systemctl daemon-reload &amp;&amp; systemctl enable docker &amp;&amp; systemctl restart docker&quot;
    ssh root@$&#123;node_ip&#125; &#39;for intf in /sys/devices/virtual/net/docker0/brif/*; do echo 1 &gt; $intf/hairpin_mode; done&#39;
    ssh root@$&#123;node_ip&#125; &quot;sudo sysctl -p /etc/sysctl.d/kubernetes.conf&quot;
  done



source /opt/k8s/bin/environment.sh
for node_ip in $&#123;NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
     ssh root@$&#123;node_ip&#125; &quot;systemctl restart docker&quot;
  done
</code></pre>
<ul>
<li>关闭 firewalld(centos7)/ufw(ubuntu16.04)，否则可能会重复创建 iptables 规则；</li>
<li>清理旧的 iptables rules 和 chains 规则；</li>
<li>开启 docker0 网桥下虚拟网卡的 hairpin 模式;</li>
</ul>
<h3 id="检查服务运行状态-1"><a href="#检查服务运行状态-1" class="headerlink" title="检查服务运行状态"></a>检查服务运行状态</h3><pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    ssh k8s@$&#123;node_ip&#125; &quot;systemctl status docker|grep Active&quot;
  done
</code></pre>
<p>确保状态为 <code>active (running)</code>，否则查看日志，确认原因：</p>
<pre><code>$ journalctl -u docker
</code></pre>
<h4 id="检查-docker0-网桥"><a href="#检查-docker0-网桥" class="headerlink" title="检查 docker0 网桥"></a>检查 docker0 网桥</h4><pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    ssh k8s@$&#123;node_ip&#125; &quot;/usr/sbin/ip addr show flannel.1 &amp;&amp; /usr/sbin/ip addr show docker0&quot;
  done
</code></pre>
<p>确认各 work 节点的 docker0 网桥和 flannel.1 接口的 IP 处于同一个网段中(如下 172.30.39.0 和 172.30.39.1)：</p>
<pre><code>3: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN group default
    link/ether ce:2f:d6:53:e5:f3 brd ff:ff:ff:ff:ff:ff
    inet 172.30.39.0/32 scope global flannel.1
      valid_lft forever preferred_lft forever
    inet6 fe80::cc2f:d6ff:fe53:e5f3/64 scope link
      valid_lft forever preferred_lft forever
4: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default
    link/ether 02:42:bf:65:16:5c brd ff:ff:ff:ff:ff:ff
    inet 172.30.39.1/24 brd 172.30.39.255 scope global docker0
      valid_lft forever preferred_lft forever
</code></pre>
<h2 id="07-2-部署-kubelet-组件"><a href="#07-2-部署-kubelet-组件" class="headerlink" title="07-2.部署 kubelet 组件"></a>07-2.部署 kubelet 组件</h2><p>kublet 运行在每个 worker 节点上，接收 kube-apiserver 发送的请求，管理 Pod 容器，执行交互式命令，如 exec、run、logs 等。</p>
<p>kublet 启动时自动向 kube-apiserver 注册节点信息，内置的 cadvisor 统计和监控节点的资源使用情况。</p>
<p>为确保安全，本文档只开启接收 https 请求的安全端口，对请求进行认证和授权，拒绝未授权的访问(如 apiserver、heapster)。</p>
<h3 id="创建-kubelet-bootstrap-kubeconfig-文件"><a href="#创建-kubelet-bootstrap-kubeconfig-文件" class="headerlink" title="创建 kubelet bootstrap kubeconfig 文件"></a>创建 kubelet bootstrap kubeconfig 文件</h3><pre><code>source /opt/k8s/bin/environment.sh
for node_name in $&#123;NODE_NAMES[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_name&#125;&quot;

    # 创建 token
    export BOOTSTRAP_TOKEN=$(kubeadm token create \
      --description kubelet-bootstrap-token \
      --groups system:bootstrappers:$&#123;node_name&#125; \
      --kubeconfig ~/.kube/config)

    # 设置集群参数
    kubectl config set-cluster kubernetes \
      --certificate-authority=/etc/kubernetes/cert/ca.pem \
      --embed-certs=true \
      --server=$&#123;KUBE_APISERVER&#125; \
      --kubeconfig=kubelet-bootstrap-$&#123;node_name&#125;.kubeconfig

    # 设置客户端认证参数
    kubectl config set-credentials kubelet-bootstrap \
      --token=$&#123;BOOTSTRAP_TOKEN&#125; \
      --kubeconfig=kubelet-bootstrap-$&#123;node_name&#125;.kubeconfig

    # 设置上下文参数
    kubectl config set-context default \
      --cluster=kubernetes \
      --user=kubelet-bootstrap \
      --kubeconfig=kubelet-bootstrap-$&#123;node_name&#125;.kubeconfig

    # 设置默认上下文
    kubectl config use-context default --kubeconfig=kubelet-bootstrap-$&#123;node_name&#125;.kubeconfig
  done
</code></pre>
<ul>
<li>证书中写入 Token 而非证书，证书后续由 controller-manager 创建。</li>
</ul>
<p>查看 kubeadm 为各节点创建的 token：</p>
<pre><code>$ kubeadm token list --kubeconfig ~/.kube/config
TOKEN                     TTL       EXPIRES                     USAGES                   DESCRIPTION               EXTRA GROUPS
k0s2bj.7nvw1zi1nalyz4gz   23h       2018-06-14T15:14:31+08:00   authentication,signing   kubelet-bootstrap-token   system:bootstrappers:kube-node1
mkus5s.vilnjk3kutei600l   23h       2018-06-14T15:14:32+08:00   authentication,signing   kubelet-bootstrap-token   system:bootstrappers:kube-node3
zkiem5.0m4xhw0jc8r466nk   23h       2018-06-14T15:14:32+08:00   authentication,signing   kubelet-bootstrap-token   system:bootstrappers:kube-node2
</code></pre>
<ul>
<li>创建的 token 有效期为 1 天，超期后将不能再被使用，且会被 kube-controller-manager 的 tokencleaner 清理(如果启用该 controller 的话)；</li>
<li>kube-apiserver 接收 kubelet 的 bootstrap token 后，将请求的 user 设置为 system:bootstrap:<token id="">，group 设置为 system:bootstrappers；</token></li>
</ul>
<p>各 token 关联的 Secret：</p>
<pre><code>$ kubectl get secrets  -n kube-system
NAME                     TYPE                                  DATA      AGE
bootstrap-token-k0s2bj   bootstrap.kubernetes.io/token         7         1m
bootstrap-token-mkus5s   bootstrap.kubernetes.io/token         7         1m
bootstrap-token-zkiem5   bootstrap.kubernetes.io/token         7         1m
default-token-99st7      kubernetes.io/service-account-token   3         2d
</code></pre>
<h2 id="分发-bootstrap-kubeconfig-文件到所有-worker-节点"><a href="#分发-bootstrap-kubeconfig-文件到所有-worker-节点" class="headerlink" title="分发 bootstrap kubeconfig 文件到所有 worker 节点"></a>分发 bootstrap kubeconfig 文件到所有 worker 节点</h2><pre><code>source /opt/k8s/bin/environment.sh
for node_name in $&#123;NODE_NAMES[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_name&#125;&quot;
    scp kubelet-bootstrap-$&#123;node_name&#125;.kubeconfig k8s@$&#123;node_name&#125;:/etc/kubernetes/kubelet-bootstrap.kubeconfig
  done
</code></pre>
<h2 id="创建和分发-kubelet-参数配置文件"><a href="#创建和分发-kubelet-参数配置文件" class="headerlink" title="创建和分发 kubelet 参数配置文件"></a>创建和分发 kubelet 参数配置文件</h2><p>从 v1.10 开始，kubelet <strong>部分参数</strong>需在配置文件中配置，<code>kubelet --help</code> 会提示：</p>
<pre><code>DEPRECATED: This parameter should be set via the config file specified by the Kubelet&#39;s --config flag
</code></pre>
<p>创建 kubelet 参数配置模板文件：</p>
<pre><code>source /opt/k8s/bin/environment.sh
cat &gt; kubelet.config.json.template &lt;&lt;EOF
&#123;
  &quot;kind&quot;: &quot;KubeletConfiguration&quot;,
  &quot;apiVersion&quot;: &quot;kubelet.config.k8s.io/v1beta1&quot;,
  &quot;authentication&quot;: &#123;
    &quot;x509&quot;: &#123;
      &quot;clientCAFile&quot;: &quot;/etc/kubernetes/cert/ca.pem&quot;
    &#125;,
    &quot;webhook&quot;: &#123;
      &quot;enabled&quot;: true,
      &quot;cacheTTL&quot;: &quot;2m0s&quot;
    &#125;,
    &quot;anonymous&quot;: &#123;
      &quot;enabled&quot;: false
    &#125;
  &#125;,
  &quot;authorization&quot;: &#123;
    &quot;mode&quot;: &quot;Webhook&quot;,
    &quot;webhook&quot;: &#123;
      &quot;cacheAuthorizedTTL&quot;: &quot;5m0s&quot;,
      &quot;cacheUnauthorizedTTL&quot;: &quot;30s&quot;
    &#125;
  &#125;,
  &quot;address&quot;: &quot;##NODE_IP##&quot;,
  &quot;port&quot;: 10250,
  &quot;readOnlyPort&quot;: 0,
  &quot;cgroupDriver&quot;: &quot;cgroupfs&quot;,
  &quot;hairpinMode&quot;: &quot;promiscuous-bridge&quot;,
  &quot;serializeImagePulls&quot;: false,
  &quot;featureGates&quot;: &#123;
    &quot;RotateKubeletClientCertificate&quot;: true,
    &quot;RotateKubeletServerCertificate&quot;: true
  &#125;,
  &quot;clusterDomain&quot;: &quot;$&#123;CLUSTER_DNS_DOMAIN&#125;&quot;,
  &quot;clusterDNS&quot;: [&quot;$&#123;CLUSTER_DNS_SVC_IP&#125;&quot;]
&#125;
EOF
</code></pre>
<ul>
<li>address：API 监听地址，不能为 127.0.0.1，否则 kube-apiserver、heapster 等不能调用 kubelet 的 API；</li>
<li>readOnlyPort=0：关闭只读端口(默认 10255)，等效为未指定；</li>
<li>authentication.anonymous.enabled：设置为 false，不允许匿名访问 10250 端口；</li>
<li>authentication.x509.clientCAFile：指定签名客户端证书的 CA 证书，开启 HTTP 证书认证；</li>
<li>authentication.webhook.enabled=true：开启 HTTPs bearer token 认证；</li>
<li>对于未通过 x509 证书和 webhook 认证的请求(kube-apiserver 或其他客户端)，将被拒绝，提示 Unauthorized；</li>
<li>authroization.mode=Webhook：kubelet 使用 SubjectAccessReview API 查询 kube-apiserver 某 user、group 是否具有操作资源的权限(RBAC)；</li>
<li>featureGates.RotateKubeletClientCertificate、featureGates.RotateKubeletServerCertificate：自动 rotate 证书，证书的有效期取决于 kube-controller-manager 的 –experimental-cluster-signing-duration 参数；</li>
<li>需要 root 账户运行；</li>
</ul>
<p>为各节点创建和分发 kubelet 配置文件：</p>
<pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;NODE_IPS[@]&#125;
  do 
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    sed -e &quot;s/##NODE_IP##/$&#123;node_ip&#125;/&quot; kubelet.config.json.template &gt; kubelet.config-$&#123;node_ip&#125;.json
    scp kubelet.config-$&#123;node_ip&#125;.json root@$&#123;node_ip&#125;:/etc/kubernetes/kubelet.config.json
  done
</code></pre>
<p>替换后的 kubelet.config.json 文件： <a target="_blank" rel="noopener" href="https://github.com/opsnull/follow-me-install-kubernetes-cluster/blob/master/systemd/kubelet.config.json">kubelet.config.json</a></p>
<h2 id="创建和分发-kubelet-systemd-unit-文件"><a href="#创建和分发-kubelet-systemd-unit-文件" class="headerlink" title="创建和分发 kubelet systemd unit 文件"></a>创建和分发 kubelet systemd unit 文件</h2><p>创建 kubelet systemd unit 文件模板：</p>
<pre><code>cat &gt; kubelet.service.template &lt;&lt;EOF
[Unit]
Description=Kubernetes Kubelet
Documentation=https://github.com/GoogleCloudPlatform/kubernetes
After=docker.service
Requires=docker.service

[Service]
WorkingDirectory=/var/lib/kubelet
ExecStart=/opt/k8s/bin/kubelet \\
  --bootstrap-kubeconfig=/etc/kubernetes/kubelet-bootstrap.kubeconfig \\
  --cert-dir=/etc/kubernetes/cert \\
  --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \\
  --config=/etc/kubernetes/kubelet.config.json \\
  --hostname-override=##NODE_NAME## \\
  --pod-infra-container-image=registry.access.redhat.com/rhel7/pod-infrastructure:latest \\
  --allow-privileged=true \\
  --alsologtostderr=true \\
  --logtostderr=false \\
  --log-dir=/var/log/kubernetes \\
  --v=2
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
EOF
</code></pre>
<ul>
<li>如果设置了 <code>--hostname-override</code> 选项，则 <code>kube-proxy</code> 也需要设置该选项，否则会出现找不到 Node 的情况；</li>
<li><code>--bootstrap-kubeconfig</code>：指向 bootstrap kubeconfig 文件，kubelet 使用该文件中的用户名和 token 向 kube-apiserver 发送 TLS Bootstrapping 请求；</li>
<li>K8S approve kubelet 的 csr 请求后，在 <code>--cert-dir</code> 目录创建证书和私钥文件，然后写入 <code>--kubeconfig</code> 文件；</li>
</ul>
<p>替换后的 unit 文件：<a target="_blank" rel="noopener" href="https://github.com/opsnull/follow-me-install-kubernetes-cluster/blob/master/systemd/kubelet.service">kubelet.service</a></p>
<p>为各节点创建和分发 kubelet systemd unit 文件：</p>
<pre><code>source /opt/k8s/bin/environment.sh
for node_name in $&#123;NODE_NAMES[@]&#125;
  do 
    echo &quot;&gt;&gt;&gt; $&#123;node_name&#125;&quot;
    sed -e &quot;s/##NODE_NAME##/$&#123;node_name&#125;/&quot; kubelet.service.template &gt; kubelet-$&#123;node_name&#125;.service
    scp kubelet-$&#123;node_name&#125;.service root@$&#123;node_name&#125;:/etc/systemd/system/kubelet.service
  done
</code></pre>
<h2 id="Bootstrap-Token-Auth-和授予权限"><a href="#Bootstrap-Token-Auth-和授予权限" class="headerlink" title="Bootstrap Token Auth 和授予权限"></a>Bootstrap Token Auth 和授予权限</h2><p>kublet 启动时查找配置的 –kubeletconfig 文件是否存在，如果不存在则使用 –bootstrap-kubeconfig 向 kube-apiserver 发送证书签名请求 (CSR)。</p>
<p>kube-apiserver 收到 CSR 请求后，对其中的 Token 进行认证（事先使用 kubeadm 创建的 token），认证通过后将请求的 user 设置为 system:bootstrap:<token id="">，group 设置为 system:bootstrappers，这一过程称为 Bootstrap Token Auth。</token></p>
<p>默认情况下，这个 user 和 group 没有创建 CSR 的权限:q，kubelet 启动失败，错误日志如下：</p>
<pre><code>$ sudo journalctl -u kubelet -a |grep -A 2 &#39;certificatesigningrequests&#39;
May 06 06:42:36 kube-node1 kubelet[26986]: F0506 06:42:36.314378   26986 server.go:233] failed to run Kubelet: cannot create certificate signing request: certificatesigningrequests.certificates.k8s.io is forbidden: User &quot;system:bootstrap:lemy40&quot; cannot create certificatesigningrequests.certificates.k8s.io at the cluster scope
May 06 06:42:36 kube-node1 systemd[1]: kubelet.service: Main process exited, code=exited, status=255/n/a
May 06 06:42:36 kube-node1 systemd[1]: kubelet.service: Failed with result &#39;exit-code&#39;.
</code></pre>
<p>解决办法是：创建一个 clusterrolebinding，将 group system:bootstrappers 和 clusterrole system:node-bootstrapper 绑定：</p>
<pre><code>$ kubectl create clusterrolebinding kubelet-bootstrap --clusterrole=system:node-bootstrapper --group=system:bootstrappers
</code></pre>
<h2 id="启动-kubelet-服务"><a href="#启动-kubelet-服务" class="headerlink" title="启动 kubelet 服务"></a>启动 kubelet 服务</h2><pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;ETCD_NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    ssh root@$&#123;node_ip&#125; &quot;mkdir -p /var/lib/kubelet&quot;
    ssh root@$&#123;node_ip&#125; &quot;/usr/sbin/swapoff -a&quot;
    ssh root@$&#123;node_ip&#125; &quot;mkdir -p /var/log/kubernetes &amp;&amp; chown -R k8s /var/log/kubernetes&quot;
    ssh root@$&#123;node_ip&#125; &quot;systemctl daemon-reload &amp;&amp; systemctl enable kubelet &amp;&amp; systemctl restart kubelet&quot;
  done
</code></pre>
<ul>
<li>关闭 swap 分区，否则 kubelet 会启动失败；</li>
<li>必须先创建工作和日志目录；</li>
</ul>
<p>source /opt/k8s/bin/environment.sh<br> for node_ip in ${NODE_IPS[@]}<br> do<br> echo “&gt;&gt;&gt; ${node_ip}”<br> ssh root@${node_ip} “systemctl restart kubelet &amp;&amp; systemctl status kubelet|grep Active:”<br> done</p>
<pre><code>$ journalctl -u kubelet |tail
Jun 13 16:05:40 kube-node2 kubelet[22343]: I0613 16:05:40.388242   22343 feature_gate.go:226] feature gates: &amp;&#123;&#123;&#125; map[RotateKubeletServerCertificate:true RotateKubeletClientCertificate:true]&#125;
Jun 13 16:05:40 kube-node2 kubelet[22343]: I0613 16:05:40.394342   22343 mount_linux.go:211] Detected OS with systemd
Jun 13 16:05:40 kube-node2 kubelet[22343]: W0613 16:05:40.394494   22343 cni.go:171] Unable to update cni config: No networks found in /etc/cni/net.d
Jun 13 16:05:40 kube-node2 kubelet[22343]: I0613 16:05:40.399508   22343 server.go:376] Version: v1.10.4
Jun 13 16:05:40 kube-node2 kubelet[22343]: I0613 16:05:40.399583   22343 feature_gate.go:226] feature gates: &amp;&#123;&#123;&#125; map[RotateKubeletServerCertificate:true RotateKubeletClientCertificate:true]&#125;
Jun 13 16:05:40 kube-node2 kubelet[22343]: I0613 16:05:40.399736   22343 plugins.go:89] No cloud provider specified.
Jun 13 16:05:40 kube-node2 kubelet[22343]: I0613 16:05:40.399752   22343 server.go:492] No cloud provider specified: &quot;&quot; from the config file: &quot;&quot;
Jun 13 16:05:40 kube-node2 kubelet[22343]: I0613 16:05:40.399777   22343 bootstrap.go:58] Using bootstrap kubeconfig to generate TLS client cert, key and kubeconfig file
Jun 13 16:05:40 kube-node2 kubelet[22343]: I0613 16:05:40.446068   22343 csr.go:105] csr for this node already exists, reusing
Jun 13 16:05:40 kube-node2 kubelet[22343]: I0613 16:05:40.453761   22343 csr.go:113] csr for this node is still valid
</code></pre>
<p>kubelet 启动后使用 –bootstrap-kubeconfig 向 kube-apiserver 发送 CSR 请求，当这个 CSR 被 approve 后，kube-controller-manager 为 kubelet 创建 TLS 客户端证书、私钥和 –kubeletconfig 文件。</p>
<p>注意：kube-controller-manager 需要配置 <code>--cluster-signing-cert-file</code> 和 <code>--cluster-signing-key-file</code> 参数，才会为 TLS Bootstrap 创建证书和私钥。</p>
<pre><code>$ kubectl get csr
NAME                                                   AGE       REQUESTOR                 CONDITION
node-csr-QzuuQiuUfcSdp3j5W4B2UOuvQ_n9aTNHAlrLzVFiqrk   43s       system:bootstrap:zkiem5   Pending
node-csr-oVbPmU-ikVknpynwu0Ckz_MvkAO_F1j0hmbcDa__sGA   27s       system:bootstrap:mkus5s   Pending
node-csr-u0E1-ugxgotO_9FiGXo8DkD6a7-ew8sX2qPE6KPS2IY   13m       system:bootstrap:k0s2bj   Pending

$ kubectl get nodes
No resources found.
</code></pre>
<ul>
<li>三个 work 节点的 csr 均处于 pending 状态；</li>
</ul>
<h2 id="approve-kubelet-CSR-请求"><a href="#approve-kubelet-CSR-请求" class="headerlink" title="approve kubelet CSR 请求"></a>approve kubelet CSR 请求</h2><p>可以手动或自动 approve CSR 请求。推荐使用自动的方式，因为从 v1.8 版本开始，可以自动轮转approve csr 后生成的证书。</p>
<h3 id="手动-approve-CSR-请求"><a href="#手动-approve-CSR-请求" class="headerlink" title="手动 approve CSR 请求"></a>手动 approve CSR 请求</h3><p>查看 CSR 列表：</p>
<pre><code>$ kubectl get csr
NAME                                                   AGE       REQUESTOR                 CONDITION
node-csr-QzuuQiuUfcSdp3j5W4B2UOuvQ_n9aTNHAlrLzVFiqrk   43s       system:bootstrap:zkiem5   Pending
node-csr-oVbPmU-ikVknpynwu0Ckz_MvkAO_F1j0hmbcDa__sGA   27s       system:bootstrap:mkus5s   Pending
node-csr-u0E1-ugxgotO_9FiGXo8DkD6a7-ew8sX2qPE6KPS2IY   13m       system:bootstrap:k0s2bj   Pending
</code></pre>
<p>approve CSR：</p>
<pre><code>$ kubectl certificate approve node-csr-QzuuQiuUfcSdp3j5W4B2UOuvQ_n9aTNHAlrLzVFiqrk
certificatesigningrequest.certificates.k8s.io &quot;node-csr-QzuuQiuUfcSdp3j5W4B2UOuvQ_n9aTNHAlrLzVFiqrk&quot; approved
</code></pre>
<p>查看 Approve 结果：</p>
<pre><code>$ kubectl describe  csr node-csr-QzuuQiuUfcSdp3j5W4B2UOuvQ_n9aTNHAlrLzVFiqrk
Name:               node-csr-QzuuQiuUfcSdp3j5W4B2UOuvQ_n9aTNHAlrLzVFiqrk
Labels:             &lt;none&gt;
Annotations:        &lt;none&gt;
CreationTimestamp:  Wed, 13 Jun 2018 16:05:04 +0800
Requesting User:    system:bootstrap:zkiem5
Status:             Approved
Subject:
         Common Name:    system:node:kube-node2
         Serial Number:
         Organization:   system:nodes
Events:  &lt;none&gt;
</code></pre>
<ul>
<li><code>Requesting User</code>：请求 CSR 的用户，kube-apiserver 对它进行认证和授权；</li>
<li><code>Subject</code>：请求签名的证书信息；</li>
<li>证书的 CN 是 system:node:kube-node2， Organization 是 system:nodes，kube-apiserver 的 Node 授权模式会授予该证书的相关权限；</li>
</ul>
<h3 id="自动-approve-CSR-请求"><a href="#自动-approve-CSR-请求" class="headerlink" title="自动 approve CSR 请求"></a>自动 approve CSR 请求</h3><p>创建三个 ClusterRoleBinding，分别用于自动 approve client、renew client、renew server 证书：</p>
<pre><code>cat &gt; csr-crb.yaml &lt;&lt;EOF
 # Approve all CSRs for the group &quot;system:bootstrappers&quot;
 kind: ClusterRoleBinding
 apiVersion: rbac.authorization.k8s.io/v1
 metadata:
   name: auto-approve-csrs-for-group
 subjects:
 - kind: Group
   name: system:bootstrappers
   apiGroup: rbac.authorization.k8s.io
 roleRef:
   kind: ClusterRole
   name: system:certificates.k8s.io:certificatesigningrequests:nodeclient
   apiGroup: rbac.authorization.k8s.io
---
 # To let a node of the group &quot;system:nodes&quot; renew its own credentials
 kind: ClusterRoleBinding
 apiVersion: rbac.authorization.k8s.io/v1
 metadata:
   name: node-client-cert-renewal
 subjects:
 - kind: Group
   name: system:nodes
   apiGroup: rbac.authorization.k8s.io
 roleRef:
   kind: ClusterRole
   name: system:certificates.k8s.io:certificatesigningrequests:selfnodeclient
   apiGroup: rbac.authorization.k8s.io
---
# A ClusterRole which instructs the CSR approver to approve a node requesting a
# serving cert matching its client cert.
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: approve-node-server-renewal-csr
rules:
- apiGroups: [&quot;certificates.k8s.io&quot;]
  resources: [&quot;certificatesigningrequests/selfnodeserver&quot;]
  verbs: [&quot;create&quot;]
---
 # To let a node of the group &quot;system:nodes&quot; renew its own server credentials
 kind: ClusterRoleBinding
 apiVersion: rbac.authorization.k8s.io/v1
 metadata:
   name: node-server-cert-renewal
 subjects:
 - kind: Group
   name: system:nodes
   apiGroup: rbac.authorization.k8s.io
 roleRef:
   kind: ClusterRole
   name: approve-node-server-renewal-csr
   apiGroup: rbac.authorization.k8s.io
EOF
</code></pre>
<ul>
<li>auto-approve-csrs-for-group：自动 approve node 的第一次 CSR； 注意第一次 CSR 时，请求的 Group 为 system:bootstrappers；</li>
<li>node-client-cert-renewal：自动 approve node 后续过期的 client 证书，自动生成的证书 Group 为 system:nodes;</li>
<li>node-server-cert-renewal：自动 approve node 后续过期的 server 证书，自动生成的证书 Group 为 system:nodes;</li>
</ul>
<p>生效配置：</p>
<pre><code>$ kubectl apply -f csr-crb.yaml
</code></pre>
<h2 id="查看-kublet-的情况"><a href="#查看-kublet-的情况" class="headerlink" title="查看 kublet 的情况"></a>查看 kublet 的情况</h2><p>等待一段时间(1-10 分钟)，三个节点的 CSR 都被自动 approve：</p>
<pre><code>$ kubectl get csr
NAME                                                   AGE       REQUESTOR                 CONDITION
csr-98h25                                              6m        system:node:kube-node2    Approved,Issued
csr-lb5c9                                              7m        system:node:kube-node3    Approved,Issued
csr-m2hn4                                              14m       system:node:kube-node1    Approved,Issued平时
node-csr-7q7i0q4MF_K2TSEJj16At4CJFLlJkHIqei6nMIAaJCU   28m       system:bootstrap:k0s2bj   Approved,Issued
node-csr-ND77wk2P8k2lHBtgBaObiyYw0uz1Um7g2pRvveMF-c4   35m       system:bootstrap:mkus5s   Approved,Issued
node-csr-Nysmrw55nnM48NKwEJuiuCGmZoxouK4N8jiEHBtLQso   6m        system:bootstrap:zkiem5   Approved,Issued
node-csr-QzuuQiuUfcSdp3j5W4B2UOuvQ_n9aTNHAlrLzVFiqrk   1h        system:bootstrap:zkiem5   Approved,Issued
node-csr-oVbPmU-ikVknpynwu0Ckz_MvkAO_F1j0hmbcDa__sGA   1h        system:bootstrap:mkus5s   Approved,Issued
node-csr-u0E1-ugxgotO_9FiGXo8DkD6a7-ew8sX2qPE6KPS2IY   1h        system:bootstrap:k0s2bj   Approved,Issued
</code></pre>
<p>所有节点均 ready：</p>
<pre><code>$ kubectl get nodes
NAME         STATUS    ROLES     AGE       VERSION
kube-node1   Ready     &lt;none&gt;    18m       v1.10.4
kube-node2   Ready     &lt;none&gt;    10m       v1.10.4
kube-node3   Ready     &lt;none&gt;    11m       v1.10.4
</code></pre>
<p>kube-controller-manager 为各 node 生成了 kubeconfig 文件和公私钥：</p>
<pre><code>$ ls -l /etc/kubernetes/kubelet.kubeconfig
-rw------- 1 root root 2293 Jun 13 17:07 /etc/kubernetes/kubelet.kubeconfig

$ ls -l /etc/kubernetes/cert/|grep kubelet
-rw-r--r-- 1 root root 1046 Jun 13 17:07 kubelet-client.crt
-rw------- 1 root root  227 Jun 13 17:07 kubelet-client.key
-rw------- 1 root root 1334 Jun 13 17:07 kubelet-server-2018-06-13-17-07-45.pem
lrwxrwxrwx 1 root root   58 Jun 13 17:07 kubelet-server-current.pem -&gt; /etc/kubernetes/cert/kubelet-server-2018-06-13-17-07-45.pem
</code></pre>
<ul>
<li>kubelet-server 证书会周期轮转；</li>
</ul>
<h2 id="kubelet-提供的-API-接口"><a href="#kubelet-提供的-API-接口" class="headerlink" title="kubelet 提供的 API 接口"></a>kubelet 提供的 API 接口</h2><p>kublet 启动后监听多个端口，用于接收 kube-apiserver 或其它组件发送的请求：</p>
<pre><code>$ sudo netstat -lnpt|grep kubelet
tcp        0      0 172.27.129.111:4194     0.0.0.0:*               LISTEN      2490/kubelet
tcp        0      0 127.0.0.1:10248         0.0.0.0:*               LISTEN      2490/kubelet
tcp        0      0 172.27.129.111:10250    0.0.0.0:*               LISTEN      2490/kubelet
</code></pre>
<ul>
<li>4194: cadvisor http 服务；</li>
<li>10248: healthz http 服务；</li>
<li>10250: https API 服务；注意：未开启只读端口 10255；</li>
</ul>
<p>例如执行 <code>kubectl ec -it nginx-ds-5rmws -- sh</code> 命令时，kube-apiserver 会向 kubelet 发送如下请求：</p>
<pre><code>POST /exec/default/nginx-ds-5rmws/my-nginx?command=sh&amp;input=1&amp;output=1&amp;tty=1
</code></pre>
<p>kubelet 接收 10250 端口的 https 请求：</p>
<ul>
<li>/pods、/runningpods</li>
<li>/metrics、/metrics/cadvisor、/metrics/probes</li>
<li>/spec</li>
<li>/stats、/stats/container</li>
<li>/logs</li>
<li>/run/、”/exec/“, “/attach/“, “/portForward/“, “/containerLogs/“ 等管理；</li>
</ul>
<p>详情参考：<a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/server/server.go#L434:3">https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/server/server.go#L434:3</a></p>
<p>由于关闭了匿名认证，同时开启了 webhook 授权，所有访问 10250 端口 https API 的请求都需要被认证和授权。</p>
<p>预定义的 ClusterRole system:kubelet-api-admin 授予访问 kubelet 所有 API 的权限：</p>
<pre><code>$ kubectl describe clusterrole system:kubelet-api-admin
Name:         system:kubelet-api-admin
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources      Non-Resource URLs  Resource Names  Verbs
  ---------      -----------------  --------------  -----
  nodes          []                 []              [get list watch proxy]
  nodes/log      []                 []              [*]
  nodes/metrics  []                 []              [*]
  nodes/proxy    []                 []              [*]
  nodes/spec     []                 []              [*]
  nodes/stats    []                 []              [*]
</code></pre>
<h2 id="kublet-api-认证和授权"><a href="#kublet-api-认证和授权" class="headerlink" title="kublet api 认证和授权"></a>kublet api 认证和授权</h2><p>kublet 配置了如下认证参数：</p>
<ul>
<li>authentication.anonymous.enabled：设置为 false，不允许匿名访问 10250 端口；</li>
<li>authentication.x509.clientCAFile：指定签名客户端证书的 CA 证书，开启 HTTPs 证书认证；</li>
<li>authentication.webhook.enabled=true：开启 HTTPs bearer token 认证；</li>
</ul>
<p>同时配置了如下授权参数：</p>
<ul>
<li>authroization.mode=Webhook：开启 RBAC 授权；</li>
</ul>
<p>kubelet 收到请求后，使用 clientCAFile 对证书签名进行认证，或者查询 bearer token 是否有效。如果两者都没通过，则拒绝请求，提示 Unauthorized：</p>
<pre><code>$ curl -s --cacert /etc/kubernetes/cert/ca.pem https://192.168.86.156:10250/metrics
Unauthorized

$ curl -s --cacert /etc/kubernetes/cert/ca.pem -H &quot;Authorization: Bearer 123456&quot; https://172.27.129.111:10250/metrics
Unauthorized
</code></pre>
<p>通过认证后，kubelet 使用 SubjectAccessReview API 向 kube-apiserver 发送请求，查询证书或 token 对应的 user、group 是否有操作资源的权限(RBAC)；</p>
<p>证书认证和授权：</p>
<pre><code>$ # 权限不足的证书；
$ curl -s --cacert /etc/kubernetes/cert/ca.pem --cert /etc/kubernetes/cert/kube-controller-manager.pem --key /etc/kubernetes/cert/kube-controller-manager-key.pem https://172.27.129.111:10250/metrics
Forbidden (user=system:kube-controller-manager, verb=get, resource=nodes, subresource=metrics)

$ # 使用部署 kubectl 命令行工具时创建的、具有最高权限的 admin 证书；
$ curl -s --cacert /etc/kubernetes/cert/ca.pem --cert ./admin.pem --key ./admin-key.pem https://192.168.86.156:10250/metrics|head
# HELP apiserver_client_certificate_expiration_seconds Distribution of the remaining lifetime on the certificate used to authenticate a request.
# TYPE apiserver_client_certificate_expiration_seconds histogram
apiserver_client_certificate_expiration_seconds_bucket&#123;le=&quot;0&quot;&#125; 0
apiserver_client_certificate_expiration_seconds_bucket&#123;le=&quot;21600&quot;&#125; 0
apiserver_client_certificate_expiration_seconds_bucket&#123;le=&quot;43200&quot;&#125; 0
apiserver_client_certificate_expiration_seconds_bucket&#123;le=&quot;86400&quot;&#125; 0
apiserver_client_certificate_expiration_seconds_bucket&#123;le=&quot;172800&quot;&#125; 0
apiserver_client_certificate_expiration_seconds_bucket&#123;le=&quot;345600&quot;&#125; 0
apiserver_client_certificate_expiration_seconds_bucket&#123;le=&quot;604800&quot;&#125; 0
apiserver_client_certificate_expiration_seconds_bucket&#123;le=&quot;2.592e+06&quot;&#125; 0
</code></pre>
<ul>
<li><code>--cacert</code>、<code>--cert</code>、<code>--key</code> 的参数值必须是文件路径，如上面的 <code>./admin.pem</code> 不能省略 <code>./</code>，否则返回 <code>401 Unauthorized</code>；</li>
</ul>
<p>bear token 认证和授权：</p>
<p>创建一个 ServiceAccount，将它和 ClusterRole system:kubelet-api-admin 绑定，从而具有调用 kubelet API 的权限：</p>
<pre><code>kubectl create sa kubelet-api-test
kubectl create clusterrolebinding kubelet-api-test --clusterrole=system:kubelet-api-admin --serviceaccount=default:kubelet-api-test
SECRET=$(kubectl get secrets | grep kubelet-api-test | awk &#39;&#123;print $1&#125;&#39;)
TOKEN=$(kubectl describe secret $&#123;SECRET&#125; | grep -E &#39;^token&#39; | awk &#39;&#123;print $2&#125;&#39;)
echo $&#123;TOKEN&#125;

$ curl -s --cacert /etc/kubernetes/cert/ca.pem -H &quot;Authorization: Bearer $&#123;TOKEN&#125;&quot; https://172.27.129.111:10250/metrics|head
# HELP apiserver_client_certificate_expiration_seconds Distribution of the remaining lifetime on the certificate used to authenticate a request.
# TYPE apiserver_client_certificate_expiration_seconds histogram
apiserver_client_certificate_expiration_seconds_bucket&#123;le=&quot;0&quot;&#125; 0
apiserver_client_certificate_expiration_seconds_bucket&#123;le=&quot;21600&quot;&#125; 0
apiserver_client_certificate_expiration_seconds_bucket&#123;le=&quot;43200&quot;&#125; 0
apiserver_client_certificate_expiration_seconds_bucket&#123;le=&quot;86400&quot;&#125; 0
apiserver_client_certificate_expiration_seconds_bucket&#123;le=&quot;172800&quot;&#125; 0
apiserver_client_certificate_expiration_seconds_bucket&#123;le=&quot;345600&quot;&#125; 0
apiserver_client_certificate_expiration_seconds_bucket&#123;le=&quot;604800&quot;&#125; 0
apiserver_client_certificate_expiration_seconds_bucket&#123;le=&quot;2.592e+06&quot;&#125; 0
</code></pre>
<h3 id="cadvisor-和-metrics"><a href="#cadvisor-和-metrics" class="headerlink" title="cadvisor 和 metrics"></a>cadvisor 和 metrics</h3><p>cadvisor 统计所在节点各容器的资源(CPU、内存、磁盘、网卡)使用情况，分别在自己的 http web 页面(4194 端口)和 10250 以 promehteus metrics 的形式输出。</p>
<p>浏览器访问 <a target="_blank" rel="noopener" href="http://172.27.129.105:4194/containers/">http://172.27.129.105:4194/containers/</a> 可以查看到 cadvisor 的监控页面：</p>
<p><img src="/images/cadvisor-home.png" alt="cadvisor-home"></p>
<p>浏览器访问 <a target="_blank" rel="noopener" href="https://172.27.129.80:10250/metrics">https://172.27.129.80:10250/metrics</a> 和 <a target="_blank" rel="noopener" href="https://172.27.129.80:10250/metrics/cadvisor">https://172.27.129.80:10250/metrics/cadvisor</a> 分别返回 kublet 和 cadvisor 的 metrics。</p>
<p><img src="/images/cadvisor-metrics.png" alt="cadvisor-metrics"></p>
<p>注意：</p>
<ul>
<li>kublet.config.json 设置 authentication.anonymous.enabled 为 false，不允许匿名证书访问 10250 的 https 服务；</li>
<li>参考<a href="A.%E6%B5%8F%E8%A7%88%E5%99%A8%E8%AE%BF%E9%97%AEkube-apiserver%E5%AE%89%E5%85%A8%E7%AB%AF%E5%8F%A3.md">A.浏览器访问kube-apiserver安全端口.md</a>，创建和导入相关证书，然后访问上面的 10250 端口；</li>
</ul>
<h2 id="获取-kublet-的配置"><a href="#获取-kublet-的配置" class="headerlink" title="获取 kublet 的配置"></a>获取 kublet 的配置</h2><p>从 kube-apiserver 获取各 node 的配置：</p>
<p>curl -sSL –cacert /etc/kubernetes/cert/ca.pem –cert ./admin.pem –key ./admin-key.pem <a target="_blank" rel="noopener" href="https://192.168.86.214:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy">https://192.168.86.214:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</a></p>
<pre><code>$ source /opt/k8s/bin/environment.sh
$ # 使用部署 kubectl 命令行工具时创建的、具有最高权限的 admin 证书；
$ curl -sSL --cacert /etc/kubernetes/cert/ca.pem --cert ./admin.pem --key ./admin-key.pem $&#123;KUBE_APISERVER&#125;/api/v1/nodes/docker86-155/proxy/configz | jq \
  &#39;.kubeletconfig|.kind=&quot;KubeletConfiguration&quot;|.apiVersion=&quot;kubelet.config.k8s.io/v1beta1&quot;&#39;
&#123;
  &quot;syncFrequency&quot;: &quot;1m0s&quot;,
  &quot;fileCheckFrequency&quot;: &quot;20s&quot;,
  &quot;httpCheckFrequency&quot;: &quot;20s&quot;,
  &quot;address&quot;: &quot;172.27.129.80&quot;,
  &quot;port&quot;: 10250,
  &quot;readOnlyPort&quot;: 10255,
  &quot;authentication&quot;: &#123;
    &quot;x509&quot;: &#123;&#125;,
    &quot;webhook&quot;: &#123;
      &quot;enabled&quot;: false,
      &quot;cacheTTL&quot;: &quot;2m0s&quot;
    &#125;,
    &quot;anonymous&quot;: &#123;
      &quot;enabled&quot;: true
    &#125;
  &#125;,
  &quot;authorization&quot;: &#123;
    &quot;mode&quot;: &quot;AlwaysAllow&quot;,
    &quot;webhook&quot;: &#123;
      &quot;cacheAuthorizedTTL&quot;: &quot;5m0s&quot;,
      &quot;cacheUnauthorizedTTL&quot;: &quot;30s&quot;
    &#125;
  &#125;,
  &quot;registryPullQPS&quot;: 5,
  &quot;registryBurst&quot;: 10,
  &quot;eventRecordQPS&quot;: 5,
  &quot;eventBurst&quot;: 10,
  &quot;enableDebuggingHandlers&quot;: true,
  &quot;healthzPort&quot;: 10248,
  &quot;healthzBindAddress&quot;: &quot;127.0.0.1&quot;,
  &quot;oomScoreAdj&quot;: -999,
  &quot;clusterDomain&quot;: &quot;cluster.local.&quot;,
  &quot;clusterDNS&quot;: [
    &quot;10.254.0.2&quot;
  ],
  &quot;streamingConnectionIdleTimeout&quot;: &quot;4h0m0s&quot;,
  &quot;nodeStatusUpdateFrequency&quot;: &quot;10s&quot;,
  &quot;imageMinimumGCAge&quot;: &quot;2m0s&quot;,
  &quot;imageGCHighThresholdPercent&quot;: 85,
  &quot;imageGCLowThresholdPercent&quot;: 80,
  &quot;volumeStatsAggPeriod&quot;: &quot;1m0s&quot;,
  &quot;cgroupsPerQOS&quot;: true,
  &quot;cgroupDriver&quot;: &quot;cgroupfs&quot;,
  &quot;cpuManagerPolicy&quot;: &quot;none&quot;,
  &quot;cpuManagerReconcilePeriod&quot;: &quot;10s&quot;,
  &quot;runtimeRequestTimeout&quot;: &quot;2m0s&quot;,
  &quot;hairpinMode&quot;: &quot;promiscuous-bridge&quot;,
  &quot;maxPods&quot;: 110,
  &quot;podPidsLimit&quot;: -1,
  &quot;resolvConf&quot;: &quot;/etc/resolv.conf&quot;,
  &quot;cpuCFSQuota&quot;: true,
  &quot;maxOpenFiles&quot;: 1000000,
  &quot;contentType&quot;: &quot;application/vnd.kubernetes.protobuf&quot;,
  &quot;kubeAPIQPS&quot;: 5,
  &quot;kubeAPIBurst&quot;: 10,
  &quot;serializeImagePulls&quot;: false,
  &quot;evictionHard&quot;: &#123;
    &quot;imagefs.available&quot;: &quot;15%&quot;,
    &quot;memory.available&quot;: &quot;100Mi&quot;,
    &quot;nodefs.available&quot;: &quot;10%&quot;,
    &quot;nodefs.inodesFree&quot;: &quot;5%&quot;
  &#125;,
  &quot;evictionPressureTransitionPeriod&quot;: &quot;5m0s&quot;,
  &quot;enableControllerAttachDetach&quot;: true,
  &quot;makeIPTablesUtilChains&quot;: true,
  &quot;iptablesMasqueradeBit&quot;: 14,
  &quot;iptablesDropBit&quot;: 15,
  &quot;featureGates&quot;: &#123;
    &quot;RotateKubeletClientCertificate&quot;: true,
    &quot;RotateKubeletServerCertificate&quot;: true
  &#125;,
  &quot;failSwapOn&quot;: true,
  &quot;containerLogMaxSize&quot;: &quot;10Mi&quot;,
  &quot;containerLogMaxFiles&quot;: 5,
  &quot;enforceNodeAllocatable&quot;: [
    &quot;pods&quot;
  ],
  &quot;kind&quot;: &quot;KubeletConfiguration&quot;,
  &quot;apiVersion&quot;: &quot;kubelet.config.k8s.io/v1beta1&quot;
&#125;
</code></pre>
<p>或者参考代码中的注释：<a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/apis/kubeletconfig/v1beta1/types.go">https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/apis/kubeletconfig/v1beta1/types.go</a></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li>kubelet 认证和授权：<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet-authentication-authorization/">https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet-authentication-authorization/</a></li>
</ol>
<p>source /opt/k8s/bin/environment.sh<br> for node_ip in ${NODE_IPS[@]}<br> do<br> echo “&gt;&gt;&gt; ${node_ip}”<br> ssh root@${node_ip} “systemctl daemon-reload &amp;&amp; systemctl enable kubelet &amp;&amp; systemctl restart kubelet”<br> done</p>
<p>source /opt/k8s/bin/environment.sh</p>
<p>for node_ip in ${ETCD_NODE_IPS[@]}<br> do<br> echo “&gt;&gt;&gt; ${node_ip}”<br> ssh root@${node_ip} “mkdir -p /var/lib/kube-proxy”<br> ssh root@${node_ip} “mkdir -p /var/log/kubernetes &amp;&amp; chown -R k8s /var/log/kubernetes”<br> ssh root@${node_ip} “systemctl daemon-reload &amp;&amp; systemctl enable kube-proxy &amp;&amp; systemctl restart kube-proxy”<br> done</p>
<p>source /opt/k8s/bin/environment.sh</p>
<p>for node_ip in ${NODE_IPS[@]}<br> do<br> echo “&gt;&gt;&gt; ${node_ip}”<br> scp /usr/local/bin/pull-google-container root@${node_ip}:/usr/local/bin/<br> ssh root@${node_ip} “/usr/local/bin/pull-google-container k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.0”<br> done</p>
<p>192.168.86.18 192.168.86.21 192.168.86.91 192.168.86.9</p>
<p>cat &lt;&lt;EOF | kubectl apply -f -<br> kind: ClusterRoleBinding<br> apiVersion: rbac.authorization.k8s.io/v1beta1<br> metadata:<br> name: heapster-kubelet-api<br> roleRef:<br> apiGroup: rbac.authorization.k8s.io<br> kind: ClusterRole<br> name: system:kubelet-api-admin<br> subjects:</p>
<ul>
<li>kind: ServiceAccount  </li>
</ul>
<p>name: heapster  </p>
<p>namespace: kube-system  </p>
<p>EOF</p>
<h2 id="07-3-部署-kube-proxy-组件"><a href="#07-3-部署-kube-proxy-组件" class="headerlink" title="07-3.部署 kube-proxy 组件"></a>07-3.部署 kube-proxy 组件</h2><p>kube-proxy 运行在所有 worker 节点上，，它监听 apiserver 中 service 和 Endpoint 的变化情况，创建路由规则来进行服务负载均衡。</p>
<p>本文档讲解部署 kube-proxy 的部署，使用 ipvs 模式。</p>
<h3 id="下载和分发-kube-proxy-二进制文件"><a href="#下载和分发-kube-proxy-二进制文件" class="headerlink" title="下载和分发 kube-proxy 二进制文件"></a>下载和分发 kube-proxy 二进制文件</h3><p>参考 <a href="06-0.%E9%83%A8%E7%BD%B2master%E8%8A%82%E7%82%B9.md">06-0.部署master节点.md</a></p>
<h3 id="安装依赖包-1"><a href="#安装依赖包-1" class="headerlink" title="安装依赖包"></a>安装依赖包</h3><p>各节点需要安装 <code>ipvsadm</code> 和 <code>ipset</code> 命令，加载 <code>ip_vs</code> 内核模块。</p>
<p>参考 <a href="07-0.%E9%83%A8%E7%BD%B2worker%E8%8A%82%E7%82%B9.md">07-0.部署worker节点.md</a></p>
<h3 id="创建-kube-proxy-证书"><a href="#创建-kube-proxy-证书" class="headerlink" title="创建 kube-proxy 证书"></a>创建 kube-proxy 证书</h3><p>创建证书签名请求：</p>
<pre><code>cat &gt; kube-proxy-csr.json &lt;&lt;EOF
&#123;
  &quot;CN&quot;: &quot;system:kube-proxy&quot;,
  &quot;key&quot;: &#123;
    &quot;algo&quot;: &quot;rsa&quot;,
    &quot;size&quot;: 2048
  &#125;,
  &quot;names&quot;: [
    &#123;
      &quot;C&quot;: &quot;CN&quot;,
      &quot;ST&quot;: &quot;BeiJing&quot;,
      &quot;L&quot;: &quot;BeiJing&quot;,
      &quot;O&quot;: &quot;k8s&quot;,
      &quot;OU&quot;: &quot;4Paradigm&quot;
    &#125;
  ]
&#125;
EOF
</code></pre>
<ul>
<li>CN：指定该证书的 User 为 <code>system:kube-proxy</code>；</li>
<li>预定义的 RoleBinding <code>system:node-proxier</code> 将User <code>system:kube-proxy</code> 与 Role <code>system:node-proxier</code> 绑定，该 Role 授予了调用 <code>kube-apiserver</code> Proxy 相关 API 的权限；</li>
<li>该证书只会被 kube-proxy 当做 client 证书使用，所以 hosts 字段为空；</li>
</ul>
<p>生成证书和私钥：</p>
<pre><code>cfssl gencert -ca=/etc/kubernetes/cert/ca.pem \
  -ca-key=/etc/kubernetes/cert/ca-key.pem \
  -config=/etc/kubernetes/cert/ca-config.json \
  -profile=kubernetes  kube-proxy-csr.json | cfssljson -bare kube-proxy
</code></pre>
<h2 id="创建和分发-kubeconfig-文件-2"><a href="#创建和分发-kubeconfig-文件-2" class="headerlink" title="创建和分发 kubeconfig 文件"></a>创建和分发 kubeconfig 文件</h2><pre><code>source /opt/k8s/bin/environment.sh
kubectl config set-cluster kubernetes \
  --certificate-authority=/etc/kubernetes/cert/ca.pem \
  --embed-certs=true \
  --server=$&#123;KUBE_APISERVER&#125; \
  --kubeconfig=kube-proxy.kubeconfig

kubectl config set-credentials kube-proxy \
  --client-certificate=kube-proxy.pem \
  --client-key=kube-proxy-key.pem \
  --embed-certs=true \
  --kubeconfig=kube-proxy.kubeconfig

kubectl config set-context default \
  --cluster=kubernetes \
  --user=kube-proxy \
  --kubeconfig=kube-proxy.kubeconfig

kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig
</code></pre>
<ul>
<li><code>--embed-certs=true</code>：将 ca.pem 和 admin.pem 证书内容嵌入到生成的 kubectl-proxy.kubeconfig 文件中(不加时，写入的是证书文件路径)；</li>
</ul>
<p>分发 kubeconfig 文件：</p>
<pre><code>source /opt/k8s/bin/environment.sh
for node_name in $&#123;NODE_NAMES[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_name&#125;&quot;
    scp kube-proxy.kubeconfig k8s@$&#123;node_name&#125;:/etc/kubernetes/
  done
</code></pre>
<h2 id="创建-kube-proxy-配置文件"><a href="#创建-kube-proxy-配置文件" class="headerlink" title="创建 kube-proxy 配置文件"></a>创建 kube-proxy 配置文件</h2><p>从 v1.10 开始，kube-proxy <strong>部分参数</strong>可以配置文件中配置。可以使用 <code>--write-config-to</code> 选项生成该配置文件，或者参考 kubeproxyconfig 的类型定义源文件 ：<a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/blob/master/pkg/proxy/apis/kubeproxyconfig/types.go">https://github.com/kubernetes/kubernetes/blob/master/pkg/proxy/apis/kubeproxyconfig/types.go</a></p>
<p>创建 kube-proxy config 文件模板：</p>
<pre><code>cat &gt;kube-proxy.config.yaml.template &lt;&lt;EOF
apiVersion: kubeproxy.config.k8s.io/v1alpha1
bindAddress: ##NODE_IP##
clientConnection:
  kubeconfig: /etc/kubernetes/kube-proxy.kubeconfig
clusterCIDR: $&#123;CLUSTER_CIDR&#125;
healthzBindAddress: ##NODE_IP##:10256
hostnameOverride: ##NODE_NAME##
kind: KubeProxyConfiguration
metricsBindAddress: ##NODE_IP##:10249
mode: &quot;ipvs&quot;
EOF
</code></pre>
<ul>
<li><code>bindAddress</code>: 监听地址；</li>
<li><code>clientConnection.kubeconfig</code>: 连接 apiserver 的 kubeconfig 文件；</li>
<li><code>clusterCIDR</code>: kube-proxy 根据 <code>--cluster-cidr</code> 判断集群内部和外部流量，指定 <code>--cluster-cidr</code> 或 <code>--masquerade-all</code> 选项后 kube-proxy 才会对访问 Service IP 的请求做 SNAT；</li>
<li><code>hostnameOverride</code>: 参数值必须与 kubelet 的值一致，否则 kube-proxy 启动后会找不到该 Node，从而不会创建任何 ipvs 规则；</li>
<li><code>mode</code>: 使用 ipvs 模式；</li>
</ul>
<p>为各节点创建和分发 kube-proxy 配置文件：</p>
<pre><code>source /opt/k8s/bin/environment.sh
for (( i=0; i &lt; 7; i++ ))
  do 
    echo &quot;&gt;&gt;&gt; $&#123;NODE_NAMES[i]&#125;&quot;
    sed -e &quot;s/##NODE_NAME##/$&#123;NODE_NAMES[i]&#125;/&quot; -e &quot;s/##NODE_IP##/$&#123;NODE_IPS[i]&#125;/&quot; kube-proxy.config.yaml.template &gt; kube-proxy-$&#123;NODE_NAMES[i]&#125;.config.yaml
    scp kube-proxy-$&#123;NODE_NAMES[i]&#125;.config.yaml root@$&#123;NODE_NAMES[i]&#125;:/etc/kubernetes/kube-proxy.config.yaml
  done
</code></pre>
<p>替换后的 kube-proxy.config.yaml 文件：<a target="_blank" rel="noopener" href="https://github.com/opsnull/follow-me-install-kubernetes-cluster/blob/master/systemd/kube-proxy.config.yaml">kube-proxy.config.yaml</a></p>
<h2 id="创建和分发-kube-proxy-systemd-unit-文件"><a href="#创建和分发-kube-proxy-systemd-unit-文件" class="headerlink" title="创建和分发 kube-proxy systemd unit 文件"></a>创建和分发 kube-proxy systemd unit 文件</h2><pre><code>source /opt/k8s/bin/environment.sh
cat &gt; kube-proxy.service &lt;&lt;EOF
[Unit]
Description=Kubernetes Kube-Proxy Server
Documentation=https://github.com/GoogleCloudPlatform/kubernetes
After=network.target

[Service]
WorkingDirectory=/var/lib/kube-proxy
ExecStart=/opt/k8s/bin/kube-proxy \\
  --config=/etc/kubernetes/kube-proxy.config.yaml \\
  --alsologtostderr=true \\
  --logtostderr=false \\
  --log-dir=/var/log/kubernetes \\
  --v=2
Restart=on-failure
RestartSec=5
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target
EOF
</code></pre>
<p>替换后的 unit 文件：<a target="_blank" rel="noopener" href="https://github.com/opsnull/follow-me-install-kubernetes-cluster/blob/master/systemd/kube-proxy.service">kube-proxy.service</a></p>
<p>分发 kube-proxy systemd unit 文件：</p>
<pre><code>source /opt/k8s/bin/environment.sh
for node_name in $&#123;NODE_NAMES[@]&#125;
  do 
    echo &quot;&gt;&gt;&gt; $&#123;node_name&#125;&quot;
    scp kube-proxy.service root@$&#123;node_name&#125;:/etc/systemd/system/
  done
</code></pre>
<h3 id="启动-kube-proxy-服务"><a href="#启动-kube-proxy-服务" class="headerlink" title="启动 kube-proxy 服务"></a>启动 kube-proxy 服务</h3><pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    ssh root@$&#123;node_ip&#125; &quot;mkdir -p /var/lib/kube-proxy&quot;
    ssh root@$&#123;node_ip&#125; &quot;mkdir -p /var/log/kubernetes &amp;&amp; chown -R k8s /var/log/kubernetes&quot;
    ssh root@$&#123;node_ip&#125; &quot;systemctl daemon-reload &amp;&amp; systemctl enable kube-proxy &amp;&amp; systemctl restart kube-proxy&quot;
  done
</code></pre>
<ul>
<li>必须先创建工作和日志目录；</li>
</ul>
<h3 id="检查启动结果-2"><a href="#检查启动结果-2" class="headerlink" title="检查启动结果"></a>检查启动结果</h3><pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    ssh k8s@$&#123;node_ip&#125; &quot;systemctl status kube-proxy|grep Active&quot;
  done
</code></pre>
<p>确保状态为 <code>active (running)</code>，否则查看日志，确认原因：</p>
<pre><code>journalctl -u kube-proxy
</code></pre>
<h2 id="查看监听端口和-metrics"><a href="#查看监听端口和-metrics" class="headerlink" title="查看监听端口和 metrics"></a>查看监听端口和 metrics</h2><pre><code>[k8s@kube-node1 ~]$ sudo netstat -lnpt|grep kube-prox
tcp        0      0 172.27.129.105:10249    0.0.0.0:*               LISTEN      16847/kube-proxy
tcp        0      0 172.27.129.105:10256    0.0.0.0:*               LISTEN      16847/kube-proxy
</code></pre>
<ul>
<li>10249：http prometheus metrics port;</li>
<li>10256：http healthz port;</li>
</ul>
<h2 id="查看-ipvs-路由规则"><a href="#查看-ipvs-路由规则" class="headerlink" title="查看 ipvs 路由规则"></a>查看 ipvs 路由规则</h2><pre><code>source /opt/k8s/bin/environment.sh
for node_ip in $&#123;NODE_IPS[@]&#125;
  do
    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;
    ssh root@$&#123;node_ip&#125; &quot;/usr/sbin/ipvsadm -ln&quot;
  done
</code></pre>
<p>预期输出：</p>
<pre><code>&gt;&gt;&gt; 172.27.129.105
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  10.254.0.1:443 rr persistent 10800
  -&gt; 172.27.129.105:6443          Masq    1      0          0
&gt;&gt;&gt; 172.27.129.111
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  10.254.0.1:443 rr persistent 10800
  -&gt; 172.27.129.105:6443          Masq    1      0          0
&gt;&gt;&gt; 172.27.129.112
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  10.254.0.1:443 rr persistent 10800
  -&gt; 172.27.129.105:6443          Masq    1      0          0
</code></pre>
<p>可见将所有到 kubernetes cluster ip 443 端口的请求都转发到 kube-apiserver 的 6443 端口；</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://blog.iflyresearch.com/2018/09/28/jqpeng-XNginx%20%20-%20nginx%20%E9%9B%86%E7%BE%A4%E5%8F%AF%E8%A7%86%E5%8C%96%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="JadePeng">
      <meta itemprop="description" content="JadePeng的技术笔记本">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JadePeng的技术笔记本">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/09/28/jqpeng-XNginx%20%20-%20nginx%20%E9%9B%86%E7%BE%A4%E5%8F%AF%E8%A7%86%E5%8C%96%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/" class="post-title-link" itemprop="url">XNginx  - nginx 集群可视化管理工具</a>
        </h2>

        <div class="post-meta">

         
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-09-28 17:30:00" itemprop="dateCreated datePublished" datetime="2018-09-28T17:30:00+08:00">2018-09-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-14 17:52:26" itemprop="dateModified" datetime="2021-05-14T17:52:26+08:00">2021-05-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%8D%9A%E5%AE%A2/" itemprop="url" rel="index"><span itemprop="name">博客</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%8D%9A%E5%AE%A2/jqpeng/" itemprop="url" rel="index"><span itemprop="name">jqpeng</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>9.4k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>9 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>文章作者:jqpeng<br>原文链接: <a target="_blank" rel="noopener" href="https://www.cnblogs.com/xiaoqi/p/xnginx.html">XNginx  - nginx 集群可视化管理工具</a></p>
<p>之前团队的nginx管理，都是运维同学每次去修改配置文件，然后重启，非常不方便，一直想找一个可以方便管理nginx集群的工具，翻遍web，未寻到可用之物，于是自己设计开发了一个。</p>
<h2 id="效果预览"><a href="#效果预览" class="headerlink" title="效果预览"></a>效果预览</h2><ol>
<li>集群group管理界面</li>
</ol>
<p><img src="https://www.github.com/jadepeng/blogpic/raw/master/pic/28/1538116402607.png" alt="Xnginx pic1"></p>
<p>可以管理group的节点，配置文件，修改后可以一键重启所有节点，且配置文件出错时会提示错误，不会影响线上服务。</p>
<p>2.集群Node节点管理</p>
<p><img src="https://www.github.com/jadepeng/blogpic/raw/master/pic/28/1538116456272.png" alt="集群节点"></p>
<p>3 .集群Node节点日志查看</p>
<p><img src="https://www.github.com/jadepeng/blogpic/raw/master/pic/28/1538116799984.png" alt="集群日志管理"></p>
<ol>
<li>生成的配置文件预览</li>
</ol>
<p><img src="https://www.github.com/jadepeng/blogpic/raw/master/pic/28/1538116495120.png" alt="配置文件"></p>
<ol>
<li>vhost管理</li>
</ol>
<p><img src="https://www.github.com/jadepeng/blogpic/raw/master/pic/28/1538116669140.png" alt="Vhost管理"></p>
<h2 id="设计思路"><a href="#设计思路" class="headerlink" title="设计思路"></a>设计思路</h2><p>数据结构：<br> 一个nginxGroup，拥有多个NginxNode，共享同一份配置文件。</p>
<p>分布式架构：Manager节点+agent节点+web管理<br> 每个nginx机器部署一个agent，agent启动后自动注册到manager，通过web可以设置agent所属group，以及管理group的配置文件。</p>
<p>配置文件变更后，manager生成配置文件，分发给存活的agent，检验OK后，控制agent重启nginx。</p>
<h2 id="关键技术点"><a href="#关键技术点" class="headerlink" title="关键技术点"></a>关键技术点</h2><h3 id="分布式管理"><a href="#分布式管理" class="headerlink" title="分布式管理"></a>分布式管理</h3><p>一般分布式可以借助zookeeper等注册中心来实现，作为java项目，其实使用EurekaServer就可以了：</p>
<p>manager加入eureka依赖：</p>
<pre><code>    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
        &lt;artifactId&gt;spring-cloud-starter&lt;/artifactId&gt;
    &lt;/dependency&gt;

    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
        &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;
    &lt;/dependency&gt;
</code></pre>
<p>然后在入口程序添加 @EnableEurekaServer</p>
<p>agent 添加注册配置：</p>
<pre><code>eureka:instance:    prefer-ip-address: trueclient:    service-url:        defaultZone: http://admin:admin@ip:3002/eureka/
</code></pre>
<p>manager 节点获取存活的agent，可以通过EurekaServerContextHolder来获取注册的agent，同时可以通过定时任务自动发现新节点。</p>
<pre><code>public class NginxNodeDiscover &#123;

    private static final String AGENT_NAME = &quot;XNGINXAGENT&quot;;

    private PeerAwareInstanceRegistry getRegistry() &#123;
        return getServerContext().getRegistry();
    &#125;

    private EurekaServerContext getServerContext() &#123;
        return EurekaServerContextHolder.getInstance().getServerContext();
    &#125;

    @Autowired
    NginxNodeRepository nginxNodeRepository;

    @Scheduled(fixedRate = 60000)
    public void discoverNginxNode() &#123;
        List&lt;String&gt; nodes = getAliveAgents();
        nodes.stream().forEach(node-&gt;&#123;
            if(!nginxNodeRepository.findByAgent(node).isPresent())&#123;
                NginxNode nginxNode = new NginxNode();
                nginxNode.setAgent(node);
                nginxNode.setName(node);
                nginxNodeRepository.save(nginxNode);
            &#125;
        &#125;);
    &#125;

    public List&lt;String&gt; getAliveAgents() &#123;
        List&lt;String&gt; instances = new ArrayList&lt;&gt;();
        List&lt;Application&gt; sortedApplications = getRegistry().getSortedApplications();
        Optional&lt;Application&gt; targetApp = sortedApplications.stream().filter(a-&gt;a.getName().equals(AGENT_NAME)).findFirst();
        if(targetApp.isPresent())&#123;
            Application app = targetApp.get();
            for (InstanceInfo info : app.getInstances()) &#123;
                instances.add(info.getHomePageUrl());
            &#125;
        &#125;
        return instances;
    &#125;
&#125;
</code></pre>
<h3 id="RPC调用"><a href="#RPC调用" class="headerlink" title="RPC调用"></a>RPC调用</h3><p>manager 需要控制agent，按最简单的方案，agent提供rest服务，从Eureka获取地址后直接调用就可以了，另外可以借助feign来方便调用。</p>
<p>定义接口：</p>
<pre><code>public interface NginxAgentManager &#123;

    @RequestLine(&quot;GET /nginx/start&quot;)
     RuntimeBuilder.RuntimeResult start() ;

    @RequestLine(&quot;GET /nginx/status&quot;)
     RuntimeBuilder.RuntimeResult status() ;

    @RequestLine(&quot;GET /nginx/reload&quot;)
     RuntimeBuilder.RuntimeResult reload() ;

    @RequestLine(&quot;GET /nginx/stop&quot;)
     RuntimeBuilder.RuntimeResult stop();

    @RequestLine(&quot;GET /nginx/testConfiguration&quot;)
     RuntimeBuilder.RuntimeResult testConfiguration();

    @RequestLine(&quot;GET /nginx/kill&quot;)
     RuntimeBuilder.RuntimeResult kill() ;

    @RequestLine(&quot;GET /nginx/restart&quot;)
     RuntimeBuilder.RuntimeResult restart() ;

    @RequestLine(&quot;GET /nginx/info&quot;)
     NginxInfo info();

    @RequestLine(&quot;GET /nginx/os&quot;)
     OperationalSystemInfo os() ;

    @RequestLine(&quot;GET /nginx/accesslogs/&#123;lines&#125;&quot;)
    List&lt;NginxLoggerVM&gt; getAccesslogs(@Param(&quot;lines&quot;) int lines);

    @RequestLine(&quot;GET /nginx/errorlogs/&#123;lines&#125;&quot;)
    List&lt;NginxLoggerVM&gt; getErrorLogs(@Param(&quot;lines&quot;) int lines);

&#125;
</code></pre>
<p>agent 实现功能：</p>
<pre><code>@RestController
@RequestMapping(&quot;/nginx&quot;)
public class NginxResource &#123;

   ...

    @PostMapping(&quot;/update&quot;)
    @Timed
    public String  update(@RequestBody NginxConf conf)&#123;
        if(conf.getSslDirectives()!=null)&#123;
            for(SslDirective sslDirective : conf.getSslDirectives())&#123;
                nginxControl.conf(sslDirective.getCommonName(),sslDirective.getContent());
            &#125;
        &#125;
        return updateConfig(conf.getConf());
    &#125;

    @GetMapping(&quot;/accesslogs/&#123;lines&#125;&quot;)
    @Timed
    public List&lt;NginxLoggerVM&gt; getAccesslogs(@PathVariable Integer lines) &#123;
        return nginxControl.getAccessLogs(lines);
    &#125;


&#125;
</code></pre>
<p>manager 调用;</p>
<p>先生成一个Proxy实例，其中nodeurl是agent节点的url地址</p>
<pre><code>    public NginxAgentManager getAgentManager(String nodeUrl)&#123;
        return Feign.builder()
            .options(new Request.Options(1000, 3500))
            .retryer(new Retryer.Default(5000, 5000, 3))
            .requestInterceptor(new HeaderRequestInterceptor())
            .encoder(new GsonEncoder())
            .decoder(new GsonDecoder())
            .target(NginxAgentManager.class, nodeUrl);
    &#125;
</code></pre>
<p>然后调用就简单了，比如要启动group：</p>
<pre><code>public void start(String groupId)&#123;
        operateGroup(groupId,((conf, node) -&gt; &#123;
            NginxAgentManager manager = getAgentManager(node.getAgent());

            String result = manager.update(conf);
            if(!result.equals(&quot;success&quot;))&#123;
                throw new XNginxException(&quot;node &quot;+ node.getAgent()+&quot; update config file failed!&quot;);
            &#125;

            RuntimeBuilder.RuntimeResult runtimeResult =   manager.start();
            if(!runtimeResult.isSuccess())&#123;
                throw new XNginxException(&quot;node &quot;+ node.getAgent()+&quot; start failed,&quot;+runtimeResult.getOutput());
            &#125;
        &#125;));
    &#125;

    public void operateGroup(String groupId,BiConsumer&lt;NginxConf,NginxNode&gt; action)&#123;

        List&lt;String&gt; alivedNodes = nodeDiscover.getAliveAgents();
        if(alivedNodes.size() == 0)&#123;
            throw new XNginxException(&quot;no alived agent!&quot;);
        &#125;
        List&lt;NginxNode&gt; nginxNodes = nodeRepository.findAllByGroupId(groupId);
        if(nginxNodes.size() ==0)&#123;
            throw new XNginxException(&quot;the group has no nginx Nodes!&quot;);
        &#125;

        NginxConf conf = nginxConfigService.genConfig(groupId);

        for(NginxNode node : nginxNodes)&#123;

            if(!alivedNodes.contains(node.getAgent()))&#123;
                continue;
            &#125;

            action.accept(conf, node);
       &#125;
    &#125;
</code></pre>
<h3 id="Nginx-配置管理"><a href="#Nginx-配置管理" class="headerlink" title="Nginx 配置管理"></a>Nginx 配置管理</h3><p>nginx的核心是各种Directive（指令），最核心的是vhost和Location。</p>
<p>我们先来定义VHOST：</p>
<pre><code>public class VirtualHostDirective implements Directive &#123;
private Integer port = 80;private String aliases;private boolean enableSSL;private SslDirective sslCertificate;private SslDirective sslCertificateKey;private List&lt;LocationDirective&gt; locations;
private String root;private  String index;private String access_log;
&#125;
</code></pre>
<p>其中核心的LocationDirective，设计思路是passAddress存储location的目标地址，可以是url，也可以是upstream，通过type来区分，同时如果有upstream，则通过proxy来设置负载信息。</p>
<pre><code>public class LocationDirective &#123;
public static final String PROXY = &quot;PROXY&quot;;public static final String UWSGI = &quot;UWSGI&quot;;public static final String FASTCGI = &quot;FASTCGI&quot;;public static final String COMMON = &quot;STATIC&quot;;
private String path;
private String type = COMMON;
private ProxyDirective proxy;
private List&lt;String&gt; rewrites;
private String advanced;
private String passAddress;&#125;
</code></pre>
<p>再来看ProxyDirective，通过balance来区分是普通的url还是upstream，如果是upstream，servers存储负载的服务器。</p>
<pre><code>public class ProxyDirective implements Directive &#123;
public static final String BALANCE_UPSTREAM = &quot;upstream&quot;;public static final String BALANCE_URL = &quot;url&quot;;

private String name;
private String strategy;
/** *  Upstream balance type : upsteam,url */private String balance = BALANCE_UPSTREAM;
private List&lt;UpstreamDirectiveServer&gt; servers;&#125;
</code></pre>
<h3 id="历史数据导入"><a href="#历史数据导入" class="headerlink" title="历史数据导入"></a>历史数据导入</h3><p>已经有了配置信息，可以通过解析导入系统，解析就是常规的文本解析，这里不再赘述。</p>
<p>核心思想就是通过匹配大括号，将配置文件分成block，然后通过正则等提取信息,比如下面的代码拆分出server{…}</p>
<pre><code>private List&lt;String&gt; blocks() &#123;
        List&lt;String&gt; blocks = new ArrayList&lt;&gt;();
        List&lt;String&gt; lines = Arrays.asList(fileContent.split(&quot;\n&quot;));

        AtomicInteger atomicInteger = new AtomicInteger(0);
        AtomicInteger currentLine = new AtomicInteger(1);
        Integer indexStart = 0;
        Integer serverStartIndex = 0;
        for (String line : lines) &#123;
            if (line.contains(&quot;&#123;&quot;)) &#123;
                atomicInteger.getAndIncrement();
                if (line.contains(&quot;server&quot;)) &#123;
                    indexStart = currentLine.get() - 1;
                    serverStartIndex = atomicInteger.get() - 1;
                &#125;
            &#125; else if (line.contains(&quot;&#125;&quot;)) &#123;
                atomicInteger.getAndDecrement();
                if (atomicInteger.get() == serverStartIndex) &#123;
                    if (lines.get(indexStart).trim().startsWith(&quot;server&quot;)) &#123;
                        blocks.add(StringUtils.join(lines.subList(indexStart, currentLine.get()), &quot;\n&quot;));
                    &#125;
                &#125;
            &#125;
            currentLine.getAndIncrement();
        &#125;
        return blocks;
    &#125;
</code></pre>
<h3 id="配置文件生成"><a href="#配置文件生成" class="headerlink" title="配置文件生成"></a>配置文件生成</h3><p>配置文件生成，一般是通过模板引擎，这里也不例外，使用了Velocity库。</p>
<pre><code>    public static StringWriter mergeFileTemplate(String pTemplatePath, Map&lt;String, Object&gt; pDto) &#123;
        if (StringUtils.isEmpty(pTemplatePath)) &#123;
            throw new NullPointerException(&quot;????????????&quot;);
        &#125;
        StringWriter writer = new StringWriter();
        Template template;
        try &#123;
            template = ve.getTemplate(pTemplatePath);
        &#125; catch (Exception e) &#123;
            throw new RuntimeException(&quot;????????&quot;, e);
        &#125;
        VelocityContext context = VelocityHelper.convertDto2VelocityContext(pDto);
        try &#123;
            template.merge(context, writer);
        &#125; catch (Exception e) &#123;
            throw new RuntimeException(&quot;????????&quot;, e);
        &#125;
        return writer;
    &#125;
</code></pre>
<p>定义模板：</p>
<pre><code>#if($&#123;config.user&#125;)user $&#123;config.user&#125;;#end
#if($&#123;config.workerProcesses&#125;== 0 )
worker_processes auto;
#else
worker_processes  $&#123;config.workerProcesses&#125;;
#end
pid        /opt/xnginx/settings/nginx.pid;

events &#123;
    multi_accept off;
    worker_connections $&#123;config.workerConnections&#125;;
&#125;

...
</code></pre>
<p>生成配置文件;</p>
<pre><code>    public static StringWriter buildNginxConfString(ServerConfig serverConfig, List&lt;VirtualHostDirective&gt; hostDirectiveList, List&lt;ProxyDirective&gt; proxyDirectiveList) &#123;
        Map&lt;String,Object&gt; map = new HashMap&lt;&gt;();
        map.put(&quot;config&quot;,serverConfig);
        map.put(&quot;upstreams&quot;, proxyDirectiveList);
        map.put(&quot;hosts&quot;,hostDirectiveList);
        return VelocityHelper.mergeFileTemplate(NGINX_CONF_VM, map);
    &#125;
</code></pre>
<h3 id="管理web"><a href="#管理web" class="headerlink" title="管理web"></a>管理web</h3><p>管理web基于<a target="_blank" rel="noopener" href="https://www.cnblogs.com/xiaoqi/p/angular-ng-alain.html">ng-alain框架</a>，typescript+angular mvvm开发起来，和后端没有本质区别</p>
<p>开发相对简单，这里不赘述。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>目前只实现了基本的管理功能，后续可根据需要再继续补充完善，比如支持业务、负责人等信息管理维护。</p>
<hr>
<blockquote>
<p>作者：Jadepeng<br> 出处：jqpeng的技术记事本–<a target="_blank" rel="noopener" href="http://www.cnblogs.com/xiaoqi">http://www.cnblogs.com/xiaoqi</a><br> 您的支持是对博主最大的鼓励，感谢您的认真阅读。<br> 本文版权归作者所有，欢迎转载，但未经作者同意必须保留此段声明，且在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。</p>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://blog.iflyresearch.com/2018/08/27/jqpeng-APM%20%E5%8E%9F%E7%90%86%E4%B8%8E%E6%A1%86%E6%9E%B6%E9%80%89%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="JadePeng">
      <meta itemprop="description" content="JadePeng的技术笔记本">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JadePeng的技术笔记本">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/08/27/jqpeng-APM%20%E5%8E%9F%E7%90%86%E4%B8%8E%E6%A1%86%E6%9E%B6%E9%80%89%E5%9E%8B/" class="post-title-link" itemprop="url">APM 原理与框架选型</a>
        </h2>

        <div class="post-meta">

         
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-08-27 15:59:00" itemprop="dateCreated datePublished" datetime="2018-08-27T15:59:00+08:00">2018-08-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-14 17:52:26" itemprop="dateModified" datetime="2021-05-14T17:52:26+08:00">2021-05-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%8D%9A%E5%AE%A2/" itemprop="url" rel="index"><span itemprop="name">博客</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%8D%9A%E5%AE%A2/jqpeng/" itemprop="url" rel="index"><span itemprop="name">jqpeng</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>5.5k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>5 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>文章作者:jqpeng<br>原文链接: <a target="_blank" rel="noopener" href="https://www.cnblogs.com/xiaoqi/p/apm.html">APM 原理与框架选型</a></p>
<p>发些存稿:)</p>
<h2 id="0-APM简介"><a href="#0-APM简介" class="headerlink" title="0. APM简介"></a>0. APM简介</h2><p>随着微服务架构的流行，一次请求往往需要涉及到多个服务，因此服务性能监控和排查就变得更复杂：</p>
<ul>
<li>不同的服务可能由不同的团队开发、甚至可能使用不同的编程语言来实现</li>
<li>服务有可能布在了几千台服务器，横跨多个不同的数据中心</li>
</ul>
<p>因此，就需要一些可以帮助理解系统行为、用于分析性能问题的工具，以便发生故障的时候，能够快速定位和解决问题，这就是APM系统，全称是（<strong>A</strong>pplication <strong>P</strong>erformance <strong>M</strong>onitor，当然也有叫 <strong>A</strong>pplication <strong>P</strong>erformance <strong>M</strong>anagement tools）</p>
<p>AMP最早是谷歌公开的论文提到的 <a target="_blank" rel="noopener" href="http://bigbully.github.io/Dapper-translation">Google Dapper</a>。Dapper是Google生产环境下的分布式跟踪系统，自从Dapper发展成为一流的监控系统之后，给google的开发者和运维团队帮了大忙，所以谷歌公开论文分享了Dapper。</p>
<h2 id="1-谷歌Dapper介绍"><a href="#1-谷歌Dapper介绍" class="headerlink" title="1. 谷歌Dapper介绍"></a>1. 谷歌Dapper介绍</h2><h3 id="1-1-Dapper的挑战"><a href="#1-1-Dapper的挑战" class="headerlink" title="1.1 Dapper的挑战"></a>1.1 <strong>Dapper的挑战</strong></h3><p>在google的首页页面，提交一个查询请求后，会经历什么：</p>
<ul>
<li>可能对上百台查询服务器发起了一个Web查询，每一个查询都有自己的Index</li>
<li>这个查询可能会被发送到多个的子系统，这些子系统分别用来处理广告、进行拼写检查或是查找一些像图片、视频或新闻这样的特殊结果</li>
<li>根据每个子系统的查询结果进行筛选，得到最终结果，最后汇总到页面上</li>
</ul>
<p>总结一下：</p>
<ul>
<li>一次全局搜索有可能调用上千台服务器，涉及各种服务。</li>
<li>用户对搜索的耗时是很敏感的，而任何一个子系统的低效都导致导致最终的搜索耗时</li>
</ul>
<p>如果一次查询耗时不正常，工程师怎么来排查到底是由哪个服务调用造成的？</p>
<ul>
<li>首先，这个工程师可能无法准确的定位到这次全局搜索是调用了哪些服务，因为新的服务、乃至服务上的某个片段，都有可能在任何时间上过线或修改过，有可能是面向用户功能，也有可能是一些例如针对性能或安全认证方面的功能改进</li>
<li>其次，你不能苛求这个工程师对所有参与这次全局搜索的服务都了如指掌，每一个服务都有可能是由不同的团队开发或维护的</li>
<li>再次，这些暴露出来的服务或服务器有可能同时还被其他客户端使用着，所以这次全局搜索的性能问题甚至有可能是由其他应用造成的</li>
</ul>
<p>从上面可以看出Dapper需要：</p>
<ul>
<li>无所不在的部署，无所不在的重要性不言而喻，因为在使用跟踪系统的进行监控时，即便只有一小部分没被监控到，那么人们对这个系统是不是值得信任都会产生巨大的质疑</li>
<li>持续的监控</li>
</ul>
<h3 id="1-2-Dapper的三个具体设计目标"><a href="#1-2-Dapper的三个具体设计目标" class="headerlink" title="1.2 Dapper的三个具体设计目标"></a>1.2 Dapper的三个具体设计目标</h3><ol>
<li><strong>性能消耗低</strong><br> APM组件服务的影响应该做到足够小。<strong>服务调用埋点本身会带来性能损耗，这就需要调用跟踪的低损耗，实际中还会通过配置采样率的方式，选择一部分请求去分析请求路径</strong>。在一些高度优化过的服务，即使一点点损耗也会很容易察觉到，而且有可能迫使在线服务的部署团队不得不将跟踪系统关停。</li>
<li><strong>应用透明</strong>，也就是<strong>代码的侵入性小</strong><br> <strong>即也作为业务组件，应当尽可能少入侵或者无入侵其他业务系统，对于使用方透明，减少开发人员的负担</strong>。<br> 对于应用的程序员来说，是不需要知道有跟踪系统这回事的。如果一个跟踪系统想生效，就必须需要依赖应用的开发者主动配合，那么这个跟踪系统也太脆弱了，往往由于跟踪系统在应用中植入代码的bug或疏忽导致应用出问题，这样才是无法满足对跟踪系统“无所不在的部署”这个需求。</li>
<li><strong>可扩展性</strong><br> <strong>一个优秀的调用跟踪系统必须支持分布式部署，具备良好的可扩展性。能够支持的组件越多当然越好</strong>。或者提供便捷的插件开发API，对于一些没有监控到的组件，应用开发者也可以自行扩展。</li>
<li><strong>数据的分析</strong><br> <strong>数据的分析要快 ，分析的维度尽可能多</strong>。跟踪系统能提供足够快的信息反馈，就可以对生产环境下的异常状况做出快速反应。<strong>分析的全面，能够避免二次开发</strong>。</li>
</ol>
<h3 id="1-3-Dapper的分布式跟踪原理"><a href="#1-3-Dapper的分布式跟踪原理" class="headerlink" title="1.3 Dapper的分布式跟踪原理"></a>1.3 Dapper的分布式跟踪原理</h3><p>先来看一次请求调用示例：</p>
<ol>
<li>包括：前端（A），两个中间层（B和C），以及两个后端（D和E）</li>
<li>当用户发起一个请求时，首先到达前端A服务，然后分别对B服务和C服务进行RPC调用；</li>
<li>B服务处理完给A做出响应，但是C服务还需要和后端的D服务和E服务交互之后再返还给A服务，最后由A服务来响应用户的请求；</li>
</ol>
<p><img src="https://gitee.com/jadepeng/blogpic/raw/master/pic/27/1535337727679.png" alt="Dapper的分布式跟踪"></p>
<p>Dapper是如何来跟踪记录这次请求呢？</p>
<h4 id="1-3-1-跟踪树和span"><a href="#1-3-1-跟踪树和span" class="headerlink" title="1.3.1  跟踪树和span"></a>1.3.1  <strong>跟踪树和span</strong></h4><p>Span是dapper的<strong>基本工作单元</strong>，一次链路调用（可以是RPC，DB等没有特定的限制）创建一个span，通过一个64位ID标识它；同时附加（Annotation）作为payload负载信息，用于记录性能等数据。</p>
<p><img src="https://gitee.com/jadepeng/blogpic/raw/master/pic/27/1535338174615.png" alt="5个span在Dapper跟踪树种短暂的关联关系"></p>
<p>上图说明了span在一次大的跟踪过程中是什么样的。<strong>Dapper记录了span名称，以及每个span的ID和父ID，以重建在一次追踪过程中不同span之间的关系</strong>。如果一个span没有父ID被称为root span。<strong>所有span都挂在一个特定的跟踪上，也共用一个跟踪id</strong>。</p>
<p>再来看下<strong>Span的细节</strong>：</p>
<p><img src="https://gitee.com/jadepeng/blogpic/raw/master/pic/27/1535338251754.png" alt="一个单独的span的细节图"></p>
<p><strong>Span数据结构</strong>：</p>
<pre><code>type Span struct &#123;
    TraceID    int64 // 用于标示一次完整的请求id
    Name       string
    ID         int64 // 当前这次调用span_id
    ParentID   int64 // 上层服务的调用span_id  最上层服务parent_id为null
    Annotation []Annotation // 用于标记的时间戳
    Debug      bool
&#125;
</code></pre>
<h4 id="1-3-2-TraceID"><a href="#1-3-2-TraceID" class="headerlink" title="1.3.2 TraceID"></a>1.3.2 TraceID</h4><p>类似于 <strong>树结构的Span集合</strong>，表示一次完整的跟踪，从请求到服务器开始，服务器返回response结束，跟踪每次rpc调用的耗时，存在唯一标识trace_id。比如：你运行的分布式大数据存储一次Trace就由你的一次请求组成。</p>
<p><img src="https://user-gold-cdn.xitu.io/2018/6/4/163c9bee3a9d029a?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="Trace"></p>
<p>每种颜色的note标注了一个span，一条链路通过TraceId唯一标识，Span标识发起的请求信息。<strong>树节点是整个架构的基本单元，而每一个节点又是对span的引用</strong>。节点之间的连线表示的span和它的父span直接的关系。虽然span在日志文件中只是简单的代表span的开始和结束时间，他们在整个树形结构中却是相对独立的。</p>
<h4 id="1-3-3-Annotation"><a href="#1-3-3-Annotation" class="headerlink" title="1.3.3 Annotation"></a>1.3.3 Annotation</h4><p>Dapper允许应用程序开发人员在Dapper跟踪的过程中添加额外的信息，以监控更高级别的系统行为，或帮助调试问题。这就是Annotation：</p>
<p><strong>Annotation</strong>，用来记录请求特定事件相关信息（例如时间），<strong>一个span中会有多个annotation注解描述</strong>。通常包含四个注解信息：</p>
<blockquote>
<p>(1) <strong>cs</strong>：Client Start，表示客户端发起请求<br> (2) <strong>sr</strong>：Server Receive，表示服务端收到请求<br> (3) <strong>ss</strong>：Server Send，表示服务端完成处理，并将结果发送给客户端<br> (4) <strong>cr</strong>：Client Received，表示客户端获取到服务端返回信息</p>
</blockquote>
<p><strong>Annotation数据结构</strong>：</p>
<pre><code>type Annotation struct &#123;
    Timestamp int64
    Value     string
    Host      Endpoint
    Duration  int32
&#125;
</code></pre>
<h4 id="1-3-4-采样率"><a href="#1-3-4-采样率" class="headerlink" title="1.3.4 采样率"></a>1.3.4 采样率</h4><p>低损耗的是Dapper的一个关键的设计目标，因为如果这个工具价值未被证实但又对性能有影响的话，你可以理解服务运营人员为什么不愿意部署它。</p>
<p>另外，某些类型的Web服务对植入带来的性能损耗确实非常敏感。</p>
<p>因此，除了把Dapper的收集工作对基本组件的性能损耗限制的尽可能小之外，Dapper支持设置采样率来减少性能损耗，同时支持<strong>可变采样</strong>。</p>
<h2 id="2-APM组件选型"><a href="#2-APM组件选型" class="headerlink" title="2. APM组件选型"></a>2. APM组件选型</h2><p>市面上的全链路监控理论模型大多都是借鉴Google Dapper论文，重点关注以下三种APM组件：</p>
<blockquote>
<ol>
<li>**<a href="https://link.juejin.im/?target=http://zipkin.io/">Zipkin</a>**：由Twitter公司开源，开放源代码分布式的跟踪系统，用于收集服务的定时数据，以解决微服务架构中的延迟问题，包括：数据的收集、存储、查找和展现。</li>
<li>**<a href="https://link.juejin.im/?target=https://github.com/naver/pinpoint">Pinpoint</a>**：一款对Java编写的大规模分布式系统的APM工具，由韩国人开源的分布式跟踪组件。</li>
<li>**<a href="https://link.juejin.im/?target=http://skywalking.org/">Skywalking</a>**：国产的优秀APM组件，是一个对JAVA分布式应用程序集群的业务运行情况进行追踪、告警和分析的系统。</li>
</ol>
</blockquote>
<h3 id="2-1-对比项"><a href="#2-1-对比项" class="headerlink" title="2.1 对比项"></a>2.1 对比项</h3><p>主要对比项：</p>
<ol>
<li><strong>探针的性能</strong><br> 主要是agent对服务的吞吐量、CPU和内存的影响。微服务的规模和动态性使得数据收集的成本大幅度提高。</li>
<li><strong>collector的可扩展性</strong><br> 能够水平扩展以便支持大规模服务器集群。</li>
<li><strong>全面的调用链路数据分析</strong><br> 提供代码级别的可见性以便轻松定位失败点和瓶颈。</li>
<li><strong>对于开发透明，容易开关</strong><br> 添加新功能而无需修改代码，容易启用或者禁用。</li>
<li><strong>完整的调用链应用拓扑</strong><br> 自动检测应用拓扑，帮助你搞清楚应用的架构</li>
</ol>
<h3 id="2-2-探针的性能"><a href="#2-2-探针的性能" class="headerlink" title="2.2 探针的性能"></a>2.2 探针的性能</h3><p>比较关注探针的性能，毕竟APM定位还是工具，如果启用了链路监控组建后，直接导致吞吐量降低过半，那也是不能接受的。对skywalking、zipkin、pinpoint进行了压测，并与基线（未使用探针）的情况进行了对比。</p>
<p>选用了一个常见的基于Spring的应用程序，他包含Spring Boot, Spring MVC，redis客户端，mysql。 监控这个应用程序，每个trace，探针会抓取5个span(1 Tomcat, 1 SpringMVC, 2 Jedis, 1 Mysql)。这边基本和 <a href="https://link.juejin.im/?target=https://link.juejin.im?target=https%253A%252F%252Fskywalkingtest.github.io%252FAgent-Benchmarks%252FREADME_zh.html">skywalkingtest</a> 的测试应用差不多。</p>
<p>模拟了三种并发用户：500，750，1000。使用jmeter测试，每个线程发送30个请求，设置思考时间为10ms。使用的采样率为1，即100%，这边与生产可能有差别。pinpoint默认的采样率为20，即50%，通过设置agent的配置文件改为100%。zipkin默认也是1。组合起来，一共有12种。下面看下汇总表：</p>
<p><img src="https://gitee.com/jadepeng/blogpic/raw/master/pic/27/1535339573733.png" alt="探针性能"></p>
<p>从上表可以看出，在三种链路监控组件中，<strong>skywalking的探针对吞吐量的影响最小，zipkin的吞吐量居中。pinpoint的探针对吞吐量的影响较为明显</strong>，在500并发用户时，测试服务的吞吐量从1385降低到774，影响很大。然后再看下CPU和memory的影响，在内部服务器进行的压测，对CPU和memory的影响都差不多在10%之内。</p>
<h3 id="2-3-collector的可扩展性"><a href="#2-3-collector的可扩展性" class="headerlink" title="2.3 collector的可扩展性"></a>2.3 collector的可扩展性</h3><p>collector的可扩展性，使得能够水平扩展以便支持大规模服务器集群。</p>
<ol>
<li><strong>zipkin</strong><br> 开发zipkin-Server（其实就是提供的开箱即用包），zipkin-agent与zipkin-Server通过http或者mq进行通信，<strong>http通信会对正常的访问造成影响，所以还是推荐基于mq异步方式通信</strong>，zipkin-Server通过订阅具体的topic进行消费。这个当然是可以扩展的，<strong>多个zipkin-Server实例进行异步消费mq中的监控信息</strong>。</li>
<li><strong>skywalking</strong><br> skywalking的collector支持两种部署方式：<strong>单机和集群模式。collector与agent之间的通信使用了gRPC</strong>。</li>
<li><strong>pinpoint</strong><br> 同样，pinpoint也是支持集群和单机部署的。<strong>pinpoint agent通过thrift通信框架，发送链路信息到collector</strong>。</li>
</ol>
<h3 id="2-4-全面的调用链路数据分析"><a href="#2-4-全面的调用链路数据分析" class="headerlink" title="2.4 全面的调用链路数据分析"></a>2.4 全面的调用链路数据分析</h3><p>全面的调用链路数据分析，提供代码级别的可见性以便轻松定位失败点和瓶颈。</p>
<p><strong>zipkin</strong></p>
<p><img src="https://gitee.com/jadepeng/blogpic/raw/master/pic/27/1535339676013.png" alt="zipkin"><br><strong>zipkin的链路监控粒度相对没有那么细</strong>，从上图可以看到调用链中具体到接口级别，再进一步的调用信息并未涉及。</p>
<p><strong>skywalking</strong></p>
<p><img src="https://gitee.com/jadepeng/blogpic/raw/master/pic/27/1535339690665.png" alt="skywalking"></p>
<pre><code>**skywalking 还支持20+的中间件、框架、类库**，比如：主流的dubbo、Okhttp，还有DB和消息中间件。上图skywalking链路调用分析截取的比较简单，网关调用user服务，**由于支持众多的中间件，所以skywalking链路调用分析比zipkin完备些**。
</code></pre>
<p><strong>pinpoint</strong></p>
<p><img src="https://gitee.com/jadepeng/blogpic/raw/master/pic/27/1535339702378.png" alt="pinpoint"><br> pinpoint应该是这三种APM组件中，<strong>数据分析最为完备的组件</strong>。提供代码级别的可见性以便轻松定位失败点和瓶颈，上图可以看到对于执行的sql语句，都进行了记录。还可以配置报警规则等，设置每个应用对应的负责人，根据配置的规则报警，支持的中间件和框架也比较完备。</p>
<h3 id="2-5-对于开发透明，容易开关"><a href="#2-5-对于开发透明，容易开关" class="headerlink" title="2.5  对于开发透明，容易开关"></a>2.5  对于开发透明，容易开关</h3><p>对于开发透明，容易开关，添加新功能而无需修改代码，容易启用或者禁用。我们期望功能可以不修改代码就工作并希望得到代码级别的可见性。</p>
<p>对于这一点，<strong>Zipkin 使用修改过的类库和它自己的容器(Finagle)来提供分布式事务跟踪的功能</strong>。但是，它要求在需要时修改代码。<strong>skywalking和pinpoint都是基于字节码增强的方式，开发人员不需要修改代码，并且可以收集到更多精确的数据因为有字节码中的更多信息</strong>。</p>
<h3 id="2-6-完整的调用链应用拓扑"><a href="#2-6-完整的调用链应用拓扑" class="headerlink" title="2.6  完整的调用链应用拓扑"></a>2.6  完整的调用链应用拓扑</h3><p>自动检测应用拓扑，帮助你搞清楚应用的架构。</p>
<p>zipkin链路拓扑：<br><img src="https://gitee.com/jadepeng/blogpic/raw/master/pic/27/1535339925728.png" alt="zipkin链路拓扑"></p>
<p>skywalking链路拓扑：</p>
<p><img src="https://gitee.com/jadepeng/blogpic/raw/master/pic/27/1535339959895.png" alt="skywalking链路拓扑"></p>
<p><img src="https://gitee.com/jadepeng/blogpic/raw/master/pic/27/1535339973274.png" alt="pinpoint"></p>
<p>三个组件都能实现完整的调用链应用拓扑。相对来说：</p>
<ul>
<li>pinpoint界面显示的更加丰富，具体到调用的DB名</li>
<li>zipkin的拓扑局限于服务于服务之间</li>
</ul>
<h3 id="2-7-社区支持"><a href="#2-7-社区支持" class="headerlink" title="2.7  社区支持"></a>2.7  社区支持</h3><p>Zipkin 由 Twitter 开发，可以算得上是明星团队，而 pinpoint的Naver 的团队只是一个默默无闻的小团队，skywalking是国内的明星项目，目前属于apache孵化项目，社区活跃。</p>
<h3 id="2-8-总结"><a href="#2-8-总结" class="headerlink" title="2.8  总结"></a>2.8  总结</h3><table>
<thead>
<tr>
<th></th>
<th>zipkin</th>
<th>pinpoint</th>
<th>skywalking</th>
</tr>
</thead>
<tbody><tr>
<td>探针性能</td>
<td>中</td>
<td>低</td>
<td><strong>高</strong></td>
</tr>
<tr>
<td>collector扩展性</td>
<td><strong>高</strong></td>
<td>中</td>
<td><strong>高</strong></td>
</tr>
<tr>
<td>调用链路数据分析</td>
<td>低</td>
<td><strong>高</strong></td>
<td>中</td>
</tr>
<tr>
<td>对开发透明性</td>
<td>中</td>
<td><strong>高</strong></td>
<td><strong>高</strong></td>
</tr>
<tr>
<td>调用链应用拓扑</td>
<td>中</td>
<td><strong>高</strong></td>
<td>中</td>
</tr>
<tr>
<td>社区支持</td>
<td><strong>高</strong></td>
<td>中</td>
<td><strong>高</strong></td>
</tr>
</tbody></table>
<p>相对来说，skywalking更占优，因此团队采用skywalking作为APM工具。</p>
<h2 id="3-参考内容"><a href="#3-参考内容" class="headerlink" title="3. 参考内容"></a>3. 参考内容</h2><p>本文主要内容参考下文：<br><a target="_blank" rel="noopener" href="https://juejin.im/post/5a7a9e0af265da4e914b46f1">https://juejin.im/post/5a7a9e0af265da4e914b46f1</a><br><a target="_blank" rel="noopener" href="http://bigbully.github.io/Dapper-translation/">http://bigbully.github.io/Dapper-translation/</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://blog.iflyresearch.com/2018/08/24/jqpeng-%E7%BB%9F%E4%B8%80%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E9%80%89%E5%9E%8B%E5%AF%B9%E6%AF%94/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="JadePeng">
      <meta itemprop="description" content="JadePeng的技术笔记本">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JadePeng的技术笔记本">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/08/24/jqpeng-%E7%BB%9F%E4%B8%80%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E9%80%89%E5%9E%8B%E5%AF%B9%E6%AF%94/" class="post-title-link" itemprop="url">统一配置中心选型对比</a>
        </h2>

        <div class="post-meta">

         
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-08-24 11:03:00" itemprop="dateCreated datePublished" datetime="2018-08-24T11:03:00+08:00">2018-08-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-14 17:52:26" itemprop="dateModified" datetime="2021-05-14T17:52:26+08:00">2021-05-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%8D%9A%E5%AE%A2/" itemprop="url" rel="index"><span itemprop="name">博客</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%8D%9A%E5%AE%A2/jqpeng/" itemprop="url" rel="index"><span itemprop="name">jqpeng</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>2.1k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>文章作者:jqpeng<br>原文链接: <a target="_blank" rel="noopener" href="https://www.cnblogs.com/xiaoqi/p/configserver-compair.html">统一配置中心选型对比</a></p>
<p>整理笔记时发现之前整理的一些东西，分享给大家。</p>
<h2 id="为什么需要集中配置"><a href="#为什么需要集中配置" class="headerlink" title="为什么需要集中配置"></a>为什么需要集中配置</h2><p><strong>程序的发展，需要引入集中配置</strong>：</p>
<ul>
<li>随着程序功能的日益复杂，程序的配置日益增多：各种功能的开关、参数的配置、服务器的地址……</li>
<li>并且对配置的期望也越来越高，配置修改后实时生效，灰度发布，分环境、分集群管理配置，完善的权限、审核机制……</li>
<li>并且随着采用分布式的开发模式，项目之间的相互引用随着服务的不断增多，相互之间的调用复杂度成指数升高，每次投产或者上线新的项目时苦不堪言，因此需要引用配置中心治理。</li>
</ul>
<p><strong>已有zookeeper、etcd还需要引入吗</strong>？</p>
<ul>
<li>之前的音乐服务项目，通过etcd实现了服务的注册与发现，且一些业务配置也存储到etcd中，通过实践我们收获了集中配置带来的优势</li>
<li>但是etcd并没有方便的UI管理工具，且缺乏权限、审核等机制</li>
<li>最重要的是，etcd和zookeeper通常定义为<strong>服务注册中心</strong>，统一配置中心的事情交给专业的工具去解决。</li>
</ul>
<h2 id="有哪些开源配置中心"><a href="#有哪些开源配置中心" class="headerlink" title="有哪些开源配置中心"></a>有哪些开源配置中心</h2><ol>
<li>spring-cloud/spring-cloud-config<br><a target="_blank" rel="noopener" href="https://github.com/spring-cloud/spring-cloud-config">https://github.com/spring-cloud/spring-cloud-config</a><br>spring出品，可以和spring cloud无缝配合</li>
<li>淘宝 diamond<br><a target="_blank" rel="noopener" href="https://github.com/takeseem/diamond">https://github.com/takeseem/diamond</a><br>已经不维护</li>
<li>disconf<br><a target="_blank" rel="noopener" href="https://github.com/knightliao/disconf">https://github.com/knightliao/disconf</a><br>java开发，蚂蚁金服技术专家发起，业界使用广泛</li>
<li>ctrip apollo<br><a target="_blank" rel="noopener" href="https://github.com/ctripcorp/apollo/">https://github.com/ctripcorp/apollo/</a><br>Apollo（阿波罗）是携程框架部门研发的开源配置管理中心，具备规范的权限、流程治理等特性。</li>
</ol>
<h2 id="配置中心对别"><a href="#配置中心对别" class="headerlink" title="配置中心对别"></a>配置中心对别</h2><h3 id="功能特性"><a href="#功能特性" class="headerlink" title="功能特性"></a>功能特性</h3><p>我们先从功能层面来对别</p>
<table>
<thead>
<tr>
<th><strong>功能点</strong></th>
<th><strong>优先级</strong></th>
<th><strong>spring-cloud-config</strong></th>
<th><strong>ctrip apollo</strong></th>
<th><strong>disconf</strong></th>
<th><strong>备注</strong></th>
</tr>
</thead>
<tbody><tr>
<td>静态配置管理</td>
<td>高</td>
<td>基于file</td>
<td>支持</td>
<td>支持</td>
<td></td>
</tr>
<tr>
<td>动态配置管理</td>
<td>高</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
<td></td>
</tr>
<tr>
<td>统一管理</td>
<td>高</td>
<td>无，需要github</td>
<td>支持</td>
<td>支持</td>
<td></td>
</tr>
<tr>
<td>多环境</td>
<td>中</td>
<td>无，需要github</td>
<td>支持</td>
<td>支持</td>
<td></td>
</tr>
<tr>
<td>本地配置缓存</td>
<td>高</td>
<td>无</td>
<td>支持</td>
<td>支持</td>
<td></td>
</tr>
<tr>
<td>配置锁</td>
<td>中</td>
<td>支持</td>
<td>不支持</td>
<td>不支持</td>
<td>不允许动态及远程更新</td>
</tr>
<tr>
<td>配置校验</td>
<td>中</td>
<td>无</td>
<td>无</td>
<td>无</td>
<td>如：ip地址校验，配置</td>
</tr>
<tr>
<td>配置生效时间</td>
<td></td>
<td>重启生效，或手动refresh生效</td>
<td>实时</td>
<td>实时</td>
<td>需要结合热加载管理， springcloudconfig需要 git webhook+rabbitmq 实时生效</td>
</tr>
<tr>
<td>配置更新推送</td>
<td>高</td>
<td>需要手工触发</td>
<td>支持</td>
<td>支持</td>
<td></td>
</tr>
<tr>
<td>配置定时拉取</td>
<td>高</td>
<td>无</td>
<td>支持</td>
<td>配置更新目前依赖事件驱动， client重启或者server端推送操作</td>
<td></td>
</tr>
<tr>
<td>用户权限管理</td>
<td>中</td>
<td>无，需要github</td>
<td>支持</td>
<td>支持</td>
<td>现阶段可以人工处理</td>
</tr>
<tr>
<td>授权、审核、审计</td>
<td>中</td>
<td>无，需要github</td>
<td>支持</td>
<td>无</td>
<td>现阶段可以人工处理</td>
</tr>
<tr>
<td>配置版本管理</td>
<td>高</td>
<td>Git做版本管理</td>
<td>界面上直接提供发布历史和回滚按钮</td>
<td>操作记录有落数据库，但无查询接口</td>
<td></td>
</tr>
<tr>
<td>配置合规检测</td>
<td>高</td>
<td>不支持</td>
<td>支持（但还需完善）</td>
<td></td>
<td></td>
</tr>
<tr>
<td>实例配置监控</td>
<td>高</td>
<td>需要结合springadmin</td>
<td>支持</td>
<td>支持，可以查看每个配置在哪些机器上加载</td>
<td></td>
</tr>
<tr>
<td>灰度发布</td>
<td>中</td>
<td>不支持</td>
<td>支持</td>
<td>不支持部分更新</td>
<td>现阶段可以人工处理</td>
</tr>
<tr>
<td>告警通知</td>
<td>中</td>
<td>不支持</td>
<td>支持，邮件方式告警</td>
<td>支持，邮件方式告警</td>
<td></td>
</tr>
<tr>
<td>依赖关系</td>
<td>高</td>
<td>不支持</td>
<td>不支持</td>
<td>不支持</td>
<td>配置与系统版本的依赖系统运行时的依赖关系</td>
</tr>
</tbody></table>
<h3 id="技术路线兼容性"><a href="#技术路线兼容性" class="headerlink" title="技术路线兼容性"></a>技术路线兼容性</h3><p>引入配置中心，需要考虑和现有项目的兼容性，以及是否引入额外的第三方组件。我们的java项目以SpringBoot为主，需要重点关注springboot支持性。</p>
<table>
<thead>
<tr>
<th><strong>功能点</strong></th>
<th><strong>优先级</strong></th>
<th><strong>spring-cloud-config</strong></th>
<th><strong>ctrip apollo</strong></th>
<th><strong>disconf</strong></th>
<th><strong>备注</strong></th>
</tr>
</thead>
<tbody><tr>
<td>SpringBoot支持</td>
<td>高</td>
<td>原生支持</td>
<td>支持</td>
<td>与spring boot无相关</td>
<td></td>
</tr>
<tr>
<td>SpringCloud支持</td>
<td>高</td>
<td>原生支持</td>
<td>支持</td>
<td>与spring cloud无相关</td>
<td></td>
</tr>
<tr>
<td>客户端支持</td>
<td>低</td>
<td>Java</td>
<td>Java、.Net</td>
<td>java</td>
<td></td>
</tr>
<tr>
<td>业务系统侵入性</td>
<td>高</td>
<td>侵入性弱</td>
<td>侵入性弱</td>
<td>侵入性弱，支持注解及xml方式</td>
<td></td>
</tr>
<tr>
<td>依赖组件</td>
<td>高</td>
<td>Eureka</td>
<td>Eureka</td>
<td>zookeeper</td>
<td></td>
</tr>
</tbody></table>
<h3 id="可用性与易用性"><a href="#可用性与易用性" class="headerlink" title="可用性与易用性"></a>可用性与易用性</h3><p>引入配置中心后，所有的应用都需要依赖配置中心，因此可用性需要重点关注，另外管理的易用性也需要关注。</p>
<table>
<thead>
<tr>
<th><strong>功能点</strong></th>
<th><strong>优先级</strong></th>
<th><strong>spring-cloud-config</strong></th>
<th><strong>ctrip apollo</strong></th>
<th><strong>disconf</strong></th>
<th><strong>备注</strong></th>
</tr>
</thead>
<tbody><tr>
<td>单点故障（SPOF）</td>
<td>高</td>
<td>支持HA部署</td>
<td>支持HA部署</td>
<td>支持HA部署，高可用由zookeeper保证</td>
<td></td>
</tr>
<tr>
<td>多数据中心部署</td>
<td>高</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
<td></td>
</tr>
<tr>
<td>配置获取性能</td>
<td>高</td>
<td>unkown</td>
<td>unkown（官方说比spring快）</td>
<td></td>
<td></td>
</tr>
<tr>
<td>配置界面</td>
<td>中</td>
<td>无，需要通过git操作</td>
<td>统一界面（ng编写）</td>
<td>统一界面</td>
<td></td>
</tr>
</tbody></table>
<h2 id="最终选择"><a href="#最终选择" class="headerlink" title="最终选择"></a>最终选择</h2><p>综上，ctrip applo是较好的选择方案，最终选择applo。</p>
<ul>
<li>支持不同环境（开发、测试、生产）、不同集群</li>
<li>完善的管理系统，权限管理、发布审核、操作审计</li>
<li>SpringBoot集成友好 ，较小的迁移成本</li>
<li>配置修改实时生效（热发布）</li>
<li>版本发布管理</li>
</ul>
<h3 id="部署情况"><a href="#部署情况" class="headerlink" title="部署情况"></a>部署情况</h3><ul>
<li>管理Web：<a target="_blank" rel="noopener" href="http://config/">http://config</a>.***.com/</li>
<li>三个环境MetaServer：<ul>
<li>Dev： config.devmeta.***.com</li>
<li>Test： config.testmeta.***.com</li>
<li>PRO: config.prometa.***.com</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://blog.iflyresearch.com/2018/08/19/jqpeng-Spring%20boot%E5%9B%BD%E9%99%85%E5%8C%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="JadePeng">
      <meta itemprop="description" content="JadePeng的技术笔记本">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JadePeng的技术笔记本">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/08/19/jqpeng-Spring%20boot%E5%9B%BD%E9%99%85%E5%8C%96/" class="post-title-link" itemprop="url">Spring boot国际化</a>
        </h2>

        <div class="post-meta">

         
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-08-19 13:27:00" itemprop="dateCreated datePublished" datetime="2018-08-19T13:27:00+08:00">2018-08-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-14 17:52:26" itemprop="dateModified" datetime="2021-05-14T17:52:26+08:00">2021-05-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%8D%9A%E5%AE%A2/" itemprop="url" rel="index"><span itemprop="name">博客</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%8D%9A%E5%AE%A2/jqpeng/" itemprop="url" rel="index"><span itemprop="name">jqpeng</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>5.7k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>5 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>文章作者:jqpeng<br>原文链接: <a target="_blank" rel="noopener" href="https://www.cnblogs.com/xiaoqi/p/spring-boot-i18n.html">Spring boot国际化</a></p>
<p>国际化主要是引入了MessageSource，我们简单看下如何使用，以及其原理。</p>
<h2 id="1-1-设置资源文件"><a href="#1-1-设置资源文件" class="headerlink" title="1.1 设置资源文件"></a>1.1 设置资源文件</h2><p>在 properties新建i18n目录</p>
<p>新建message文件：</p>
<p>messages.properties</p>
<pre><code>error.title=Your request cannot be processed
</code></pre>
<p>messages_zh_CN.properties</p>
<pre><code>error.title=您的请求无法处理
</code></pre>
<h2 id="1-2-配置"><a href="#1-2-配置" class="headerlink" title="1.2 配置"></a>1.2 配置</h2><p>修改properties文件的目录：在application.yml或者application.properties中配置 spring.message.basename</p>
<pre><code>spring:
    application:
        name: test-worklog
    messages:
        basename: i18n/messages
        encoding: UTF-8
</code></pre>
<h2 id="1-3-使用"><a href="#1-3-使用" class="headerlink" title="1.3 使用"></a>1.3 使用</h2><p>引用自动注解的MessageSource,调用<code>messageSource.getMessage</code>即可，注意，需要通过<code> LocaleContextHolder.getLocale()</code>获取当前的地区。</p>
<pre><code>@Autowired
private MessageSource messageSource;
/**
 * 国际化
 *
 * @param result
 * @return
 */
public String getMessage(String result, Object[] params) &#123;
    String message = &quot;&quot;;
    try &#123;
        Locale locale = LocaleContextHolder.getLocale();
        message = messageSource.getMessage(result, params, locale);
    &#125; catch (Exception e) &#123;
        LOGGER.error(&quot;parse message error! &quot;, e);
    &#125;
    return message;
&#125;
</code></pre>
<p>如何设置个性化的地区呢? <code>forLanguageTag</code> 即可</p>
<pre><code> Locale locale = Locale.forLanguageTag(user.getLangKey());
</code></pre>
<h2 id="1-4-原理分析"><a href="#1-4-原理分析" class="headerlink" title="1.4 原理分析"></a>1.4 原理分析</h2><p><code>MessageSourceAutoConfiguration</code>中，实现了autoconfig</p>
<pre><code>@Configuration
@ConditionalOnMissingBean(value = MessageSource.class, search = SearchStrategy.CURRENT)
@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE)
@Conditional(ResourceBundleCondition.class)
@EnableConfigurationProperties
@ConfigurationProperties(prefix = &quot;spring.messages&quot;)
public class MessageSourceAutoConfiguration &#123;
</code></pre>
<p>该类一方面读取配置文件，一方面创建了MessageSource的实例:</p>
<pre><code>@Beanpublic MessageSource messageSource() &#123;    ResourceBundleMessageSource messageSource = new ResourceBundleMessageSource();    if (StringUtils.hasText(this.basename)) &#123;        messageSource.setBasenames(StringUtils.commaDelimitedListToStringArray(                StringUtils.trimAllWhitespace(this.basename)));    &#125;    if (this.encoding != null) &#123;        messageSource.setDefaultEncoding(this.encoding.name());    &#125;    messageSource.setFallbackToSystemLocale(this.fallbackToSystemLocale);    messageSource.setCacheSeconds(this.cacheSeconds);    messageSource.setAlwaysUseMessageFormat(this.alwaysUseMessageFormat);    return messageSource;&#125;
</code></pre>
<p>因此，默认是加载的<code>ResourceBundleMessageSource</code>，该类派生与于AbstractResourceBasedMessageSource</p>
<p><img src="http://oyqmmpkcm.bkt.clouddn.com/1532590285975.jpg" alt="enter description here" title="1532590285975"></p>
<pre><code>@Overridepublic final String getMessage(String code, Object[] args, String defaultMessage, Locale locale) &#123;    String msg = getMessageInternal(code, args, locale);    if (msg != null) &#123;        return msg;    &#125;    if (defaultMessage == null) &#123;        String fallback = getDefaultMessage(code);        if (fallback != null) &#123;            return fallback;        &#125;    &#125;    return renderDefaultMessage(defaultMessage, args, locale);&#125;
</code></pre>
<p>最终是调用resolveCode来获取message，通过ResourceBundle来获取message</p>
<pre><code>    @Overrideprotected MessageFormat resolveCode(String code, Locale locale) &#123;    // 遍历语言文件路径    Set&lt;String&gt; basenames = getBasenameSet();    for (String basename : basenames) &#123;        ResourceBundle bundle = getResourceBundle(basename, locale);        if (bundle != null) &#123;            MessageFormat messageFormat = getMessageFormat(bundle, code, locale);            if (messageFormat != null) &#123;                return messageFormat;            &#125;        &#125;    &#125;    return null;&#125;
// 获取ResourceBundle    
protected ResourceBundle getResourceBundle(String basename, Locale locale) &#123;    if (getCacheMillis() &gt;= 0) &#123;        // Fresh ResourceBundle.getBundle call in order to let ResourceBundle        // do its native caching, at the expense of more extensive lookup steps.        return doGetBundle(basename, locale);    &#125;    else &#123;        // Cache forever: prefer locale cache over repeated getBundle calls.        synchronized (this.cachedResourceBundles) &#123;            Map&lt;Locale, ResourceBundle&gt; localeMap = this.cachedResourceBundles.get(basename);            if (localeMap != null) &#123;                ResourceBundle bundle = localeMap.get(locale);                if (bundle != null) &#123;                    return bundle;                &#125;            &#125;            try &#123;                ResourceBundle bundle = doGetBundle(basename, locale);                if (localeMap == null) &#123;                    localeMap = new HashMap&lt;Locale, ResourceBundle&gt;();                    this.cachedResourceBundles.put(basename, localeMap);                &#125;                localeMap.put(locale, bundle);                return bundle;            &#125;            catch (MissingResourceException ex) &#123;                if (logger.isWarnEnabled()) &#123;                    logger.warn(&quot;ResourceBundle [&quot; + basename + &quot;] not found for MessageSource: &quot; + ex.getMessage());                &#125;                // Assume bundle not found                // -&gt; do NOT throw the exception to allow for checking parent message source.                return null;            &#125;        &#125;    &#125;&#125;

//  ResourceBundle    
protected ResourceBundle doGetBundle(String basename, Locale locale) throws MissingResourceException &#123;    return ResourceBundle.getBundle(basename, locale, getBundleClassLoader(), new MessageSourceControl());
&#125;
</code></pre>
<p>最后来看getMessageFormat：</p>
<pre><code>/** * Return a MessageFormat for the given bundle and code, * fetching already generated MessageFormats from the cache. * @param bundle the ResourceBundle to work on * @param code the message code to retrieve * @param locale the Locale to use to build the MessageFormat * @return the resulting MessageFormat, or &#123;@code null&#125; if no message * defined for the given code * @throws MissingResourceException if thrown by the ResourceBundle */protected MessageFormat getMessageFormat(ResourceBundle bundle, String code, Locale locale)        throws MissingResourceException &#123;
    synchronized (this.cachedBundleMessageFormats) &#123;        // 从缓存读取        Map&lt;String, Map&lt;Locale, MessageFormat&gt;&gt; codeMap = this.cachedBundleMessageFormats.get(bundle);        Map&lt;Locale, MessageFormat&gt; localeMap = null;        if (codeMap != null) &#123;            localeMap = codeMap.get(code);            if (localeMap != null) &#123;                MessageFormat result = localeMap.get(locale);                if (result != null) &#123;                    return result;                &#125;            &#125;        &#125;        // 缓存miss，从bundle读取        String msg = getStringOrNull(bundle, code);        if (msg != null) &#123;            if (codeMap == null) &#123;                codeMap = new HashMap&lt;String, Map&lt;Locale, MessageFormat&gt;&gt;();                this.cachedBundleMessageFormats.put(bundle, codeMap);            &#125;            if (localeMap == null) &#123;                localeMap = new HashMap&lt;Locale, MessageFormat&gt;();                codeMap.put(code, localeMap);            &#125;            MessageFormat result = createMessageFormat(msg, locale);            localeMap.put(locale, result);            return result;        &#125;
        return null;    &#125;&#125;
</code></pre>
<hr>
<blockquote>
<p>作者：Jadepeng<br> 出处：jqpeng的技术记事本–<a target="_blank" rel="noopener" href="http://www.cnblogs.com/xiaoqi">http://www.cnblogs.com/xiaoqi</a><br> 您的支持是对博主最大的鼓励，感谢您的认真阅读。<br> 本文版权归作者所有，欢迎转载，但未经作者同意必须保留此段声明，且在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。</p>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://blog.iflyresearch.com/2018/08/09/jqpeng-%E7%AE%A1%E7%90%86%E5%9F%B9%E8%AE%AD%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="JadePeng">
      <meta itemprop="description" content="JadePeng的技术笔记本">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JadePeng的技术笔记本">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/08/09/jqpeng-%E7%AE%A1%E7%90%86%E5%9F%B9%E8%AE%AD%E7%AC%94%E8%AE%B0/" class="post-title-link" itemprop="url">管理培训笔记</a>
        </h2>

        <div class="post-meta">

         
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-08-09 10:41:00" itemprop="dateCreated datePublished" datetime="2018-08-09T10:41:00+08:00">2018-08-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-14 17:52:26" itemprop="dateModified" datetime="2021-05-14T17:52:26+08:00">2021-05-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%8D%9A%E5%AE%A2/" itemprop="url" rel="index"><span itemprop="name">博客</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%8D%9A%E5%AE%A2/jqpeng/" itemprop="url" rel="index"><span itemprop="name">jqpeng</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>1k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>文章作者:jqpeng<br>原文链接: <a target="_blank" rel="noopener" href="https://www.cnblogs.com/xiaoqi/p/9447480.html">管理培训笔记</a></p>
<h2 id="开启-领导之路"><a href="#开启-领导之路" class="headerlink" title="开启 领导之路"></a>开启 领导之路</h2><h3 id="建立团队"><a href="#建立团队" class="headerlink" title="建立团队"></a>建立团队</h3><h4 id="什么是团队？"><a href="#什么是团队？" class="headerlink" title="什么是团队？"></a>什么是团队？</h4><ol>
<li>一群人为了共同目的而奋斗，惟有通过成员间有效合作共事才能达成目标</li>
<li>团队具有共同的目的：使命、职责、目标</li>
</ol>
<h4 id="使命"><a href="#使命" class="headerlink" title="使命"></a>使命</h4><p>包含三个方面：</p>
<ol>
<li>团队是谁</li>
<li>团队存在的理由</li>
<li>团队支持何种组织目标的实现</li>
</ol>
<h4 id="职责"><a href="#职责" class="headerlink" title="职责"></a>职责</h4><p>团队所负责的具体职责，是具体的可落地工作：</p>
<p>对于一个IT团队，可能的职责是：</p>
<ol>
<li>推动公司内部管理信息化， 负责内部网络信息系统的建设</li>
<li>负责公司电子商务 的应用推广工作</li>
<li>负责公司员工 电子商务系统应用的培训</li>
</ol>
<h4 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h4><p>目标是短期、中长期具体工作规划。制定目标需要符合SMART原则。</p>
<p><img src="http://oyqmmpkcm.bkt.clouddn.com/1532672418534.jpg" alt="SMART原则" title="SMART原则"></p>
<p>建立团队规范：<br> 沟通、会议、决策、冲突</p>
<h2 id="保障-运营卓越"><a href="#保障-运营卓越" class="headerlink" title="保障 运营卓越"></a>保障 运营卓越</h2><p><img src="http://oyqmmpkcm.bkt.clouddn.com/1532672674475.jpg" alt=" 任务规划与执行的步骤" title="1532672674475"></p>
<h3 id="1-明确需求"><a href="#1-明确需求" class="headerlink" title="1. 明确需求"></a>1. 明确需求</h3><h4 id="什么是计划"><a href="#什么是计划" class="headerlink" title="什么是计划"></a>什么是计划</h4><p>为实现目标，而规划自己与他人的行动</p>
<h4 id="什么是“执行力”？"><a href="#什么是“执行力”？" class="headerlink" title="什么是“执行力”？"></a>什么是“执行力”？</h4><p>有效运用资源，达成目标的能力</p>
<h4 id="任务规划与执行的步骤"><a href="#任务规划与执行的步骤" class="headerlink" title="任务规划与执行的步骤"></a>任务规划与执行的步骤</h4><ul>
<li>建立信息基础，分析整理已知信息，计划需要收集的信息</li>
<li>信息基础：假设、准则/条件、资源、行动</li>
<li>考虑个人特质： 客观、远见、主动</li>
</ul>
<h3 id="2-定计划"><a href="#2-定计划" class="headerlink" title="2. 定计划"></a>2. 定计划</h3><ul>
<li><p>任务和行动：</p>
<ul>
<li>任务并非单一的行动，而是若干个单一行动组成的</li>
<li>行动是可执行的步骤，是能够推进任务完成的、具体的、可实施的行动</li>
<li>行动需要为任务服务</li>
</ul>
</li>
<li><p>注意行动排序</p>
<ul>
<li>识别任务清单中各项行动的相互关联与依赖关系</li>
<li>并据各项行动的先后顺序，安排和确定工作</li>
</ul>
</li>
<li><p>评估风险、机会 四象限</p>
<ul>
<li>从影响大小、概率高低</li>
</ul>
<p>  <img src="http://oyqmmpkcm.bkt.clouddn.com/1532672842584.jpg" alt="评估风险/机会" title="1532672842584"></p>
</li>
</ul>
<h3 id="3-分职责"><a href="#3-分职责" class="headerlink" title="3. 分职责"></a>3. 分职责</h3><ul>
<li>团队分工：RACI<ul>
<li>Responsible 负责人</li>
<li>Accountable 当责人</li>
<li>Consult 被咨询人</li>
<li>Inform 知情者</li>
</ul>
</li>
</ul>
<p>需要注意，负责人和当责人之间的三不管地带：</p>
<p><img src="http://oyqmmpkcm.bkt.clouddn.com/1532672894561.jpg" alt="团队分工:RACI" title="1532672894561"></p>
<p>任务分配时，需要明确期待的结果，方便跟踪和评价。</p>
<p>同时注意，选择合适人员  </p>
<ul>
<li>客观条件  </li>
<li>人员意愿  </li>
</ul>
<ul>
<li>不会做  </li>
<li>不能做  </li>
<li>不想做</li>
</ul>
<p><img src="http://oyqmmpkcm.bkt.clouddn.com/1532673100397.jpg" alt="enter description here" title="1532673100397"></p>
<h3 id="4-做追踪"><a href="#4-做追踪" class="headerlink" title="4. 做追踪"></a>4. 做追踪</h3><blockquote>
<p>郭士纳说：人们不会做你希望的，只会做你检查的；如果你强调什么，你就检查什么，你不检查就等于不重视</p>
</blockquote>
<p>因此，你强调什么，就一定要检查什么！</p>
<p>追踪流程：  </p>
<ul>
<li> 收集资料  </li>
<li> 对标找差  </li>
<li> 纠偏强化</li>
</ul>
<p>追踪需要重点关注结果和行为。</p>
<p>常见的追踪方法：  </p>
<ul>
<li> 召集 会议  </li>
<li> 观察 检查  </li>
<li> 定期反馈 及报告</li>
</ul>
<p>如何有效追踪：</p>
<p><img src="http://oyqmmpkcm.bkt.clouddn.com/1532673452477.jpg" alt="如何有效追踪" title="如何有效追踪"></p>
<h2 id="确保-沟通有效"><a href="#确保-沟通有效" class="headerlink" title="确保 沟通有效"></a>确保 沟通有效</h2><h3 id="破除沟通障碍"><a href="#破除沟通障碍" class="headerlink" title="破除沟通障碍"></a>破除沟通障碍</h3><h4 id="常见沟通障碍"><a href="#常见沟通障碍" class="headerlink" title="常见沟通障碍"></a>常见沟通障碍</h4><p>认知偏差、听不到位 无效表达、缺乏参与</p>
<h4 id="破除沟通障碍三法宝：-听、问、说"><a href="#破除沟通障碍三法宝：-听、问、说" class="headerlink" title="破除沟通障碍三法宝： 听、问、说"></a>破除沟通障碍三法宝： 听、问、说</h4><p>提高沟通效能</p>
<p>互动五流程：</p>
<ol>
<li>定方向</li>
<li>理情况</li>
<li>想方法</li>
<li>明作法</li>
<li>做总结</li>
</ol>
<h4 id="观人沟通术"><a href="#观人沟通术" class="headerlink" title="观人沟通术"></a>观人沟通术</h4><p>人际矩阵</p>
<p>理解自己，理解他人-PDP</p>
<p>利用PDP与风格不同的人更 好合作</p>
<h2 id="辅导员工"><a href="#辅导员工" class="headerlink" title="辅导员工"></a>辅导员工</h2><h3 id="主管，你是教练"><a href="#主管，你是教练" class="headerlink" title="主管，你是教练"></a>主管，你是教练</h3><p>常见辅导议题</p>
<h3 id="发现辅导机会"><a href="#发现辅导机会" class="headerlink" title="发现辅导机会"></a>发现辅导机会</h3><p>发现征兆、收集信息</p>
<p>检验原因、做出判断</p>
<h3 id="进行有效辅导"><a href="#进行有效辅导" class="headerlink" title="进行有效辅导"></a>进行有效辅导</h3><p>利用沟通三法宝和互动五流 程进行有效辅导</p>
<h3 id="辅导反馈与跟进"><a href="#辅导反馈与跟进" class="headerlink" title="辅导反馈与跟进"></a>辅导反馈与跟进</h3><p>有效反馈要诀： 及时、平衡、具体<br> 两种反馈工具： 正面反馈(STAR) 改进型反馈(STAR/AR)</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://blog.iflyresearch.com/2018/07/05/jqpeng-Jhipster%20Registry%EF%BC%88Eureka%20Server%EF%BC%89%20Docker%E5%8F%8C%E5%90%91%E8%81%94%E9%80%9A%E4%B8%8E%E9%AB%98%E5%8F%AF%E7%94%A8%E9%83%A8%E7%BD%B2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="JadePeng">
      <meta itemprop="description" content="JadePeng的技术笔记本">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JadePeng的技术笔记本">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/07/05/jqpeng-Jhipster%20Registry%EF%BC%88Eureka%20Server%EF%BC%89%20Docker%E5%8F%8C%E5%90%91%E8%81%94%E9%80%9A%E4%B8%8E%E9%AB%98%E5%8F%AF%E7%94%A8%E9%83%A8%E7%BD%B2/" class="post-title-link" itemprop="url">Jhipster Registry（Eureka Server） Docker双向联通与高可用部署</a>
        </h2>

        <div class="post-meta">

         
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-07-05 09:56:00" itemprop="dateCreated datePublished" datetime="2018-07-05T09:56:00+08:00">2018-07-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-14 17:52:26" itemprop="dateModified" datetime="2021-05-14T17:52:26+08:00">2021-05-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%8D%9A%E5%AE%A2/" itemprop="url" rel="index"><span itemprop="name">博客</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%8D%9A%E5%AE%A2/jqpeng/" itemprop="url" rel="index"><span itemprop="name">jqpeng</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>2.4k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>文章作者:jqpeng<br>原文链接: <a target="_blank" rel="noopener" href="https://www.cnblogs.com/xiaoqi/p/9266722.html">Jhipster Registry（Eureka Server） Docker双向联通与高可用部署</a></p>
<p>使用Compose来编排这个Eureka Server集群：</p>
<h2 id="peer1配置："><a href="#peer1配置：" class="headerlink" title="peer1配置："></a>peer1配置：</h2><pre><code>server:
    port: 8761

eureka:
    instance:
        hostname: eureka-peer-1
    server:
        # see discussion about enable-self-preservation:
        # https://github.com/jhipster/generator-jhipster/issues/3654
        enable-self-preservation: false
        registry-sync-retry-wait-ms: 500
        a-sgcache-expiry-timeout-ms: 60000
        eviction-interval-timer-in-ms: 30000
        peer-eureka-nodes-update-interval-ms: 30000
        renewal-threshold-update-interval-ms: 15000
    client:
        fetch-registry: true
        register-with-eureka: true
        service-url:
            defaultZone: http://admin:$&#123;spring.security.user.password:admin&#125;@eureka-peer-2:8762/eureka/
</code></pre>
<h2 id="peer2配置："><a href="#peer2配置：" class="headerlink" title="peer2配置："></a>peer2配置：</h2><pre><code>server:
    port: 8762

eureka:
    instance:
        hostname: eureka-peer-2
    server:
        # see discussion about enable-self-preservation:
        # https://github.com/jhipster/generator-jhipster/issues/3654
        enable-self-preservation: false
        registry-sync-retry-wait-ms: 500
        a-sgcache-expiry-timeout-ms: 60000
        eviction-interval-timer-in-ms: 30000
        peer-eureka-nodes-update-interval-ms: 30000
        renewal-threshold-update-interval-ms: 15000
    client:
        fetch-registry: true
        register-with-eureka: true
        service-url:
            defaultZone: http://admin:$&#123;spring.security.user.password:admin&#125;@eureka-peer-1:8761/eureka/
</code></pre>
<h2 id="构建Image"><a href="#构建Image" class="headerlink" title="构建Image"></a>构建Image</h2><p>使用官方的DockerFile：</p>
<pre><code>FROM openjdk:8-jre-alpine

ENV SPRING_OUTPUT_ANSI_ENABLED=ALWAYS \
    JAVA_OPTS=&quot;&quot; \
    JHIPSTER_SLEEP=0

VOLUME /tmp
EXPOSE 8761
CMD echo &quot;The application will start in $&#123;JHIPSTER_SLEEP&#125;s...&quot; &amp;&amp; \
    sleep $&#123;JHIPSTER_SLEEP&#125; &amp;&amp; \
    java $&#123;JAVA_OPTS&#125; -Djava.security.egd=file:/dev/./urandom -jar /app.war

# add directly the war
ADD *.war /app.war
</code></pre>
<p>构建Image并push到registry，这里是192.168.86.8:5000/registry-dev</p>
<h2 id="编写compose文件："><a href="#编写compose文件：" class="headerlink" title="编写compose文件："></a>编写compose文件：</h2><pre><code>version: &quot;3&quot; 
services:
  eureka-peer-1 :
    image: 192.168.86.8:5000/registry-dev:latest
    links:
      - eureka-peer-2
    ports:
      - &quot;8761:8761&quot;
    environment:
      spring.profiles.active: oauth2,peer1,swagger
    entrypoint:
      - java
      - -Dspring.profiles.active=oauth2,peer1,swagger
      - -Djava.security.egd=file:/dev/./urandom
      - -jar
      - /app.war
  eureka-peer-2:
    image: 192.168.86.8:5000/registry-dev:latest
    links:
      - eureka-peer-1
    expose:
      - &quot;8762&quot;
    ports:
      - &quot;8762:8762&quot;
    environment:
      spring.profiles.active: oauth2,peer2,swagger
    entrypoint:
      - java
      - -Dspring.profiles.active=oauth2,peer2,swagger
      - -Djava.security.egd=file:/dev/./urandom
      - -jar
      - /app.war
</code></pre>
<p>启动即可。</p>
<hr>
<blockquote>
<p>作者：Jadepeng<br> 出处：jqpeng的技术记事本–<a target="_blank" rel="noopener" href="http://www.cnblogs.com/xiaoqi">http://www.cnblogs.com/xiaoqi</a><br> 您的支持是对博主最大的鼓励，感谢您的认真阅读。<br> 本文版权归作者所有，欢迎转载，但未经作者同意必须保留此段声明，且在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。</p>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://blog.iflyresearch.com/2018/06/29/jqpeng-%EF%BC%88%E8%BD%AC%E9%98%AE%E4%B8%80%E5%B3%B0%EF%BC%89%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3OAuth%202.0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="JadePeng">
      <meta itemprop="description" content="JadePeng的技术笔记本">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JadePeng的技术笔记本">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/06/29/jqpeng-%EF%BC%88%E8%BD%AC%E9%98%AE%E4%B8%80%E5%B3%B0%EF%BC%89%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3OAuth%202.0/" class="post-title-link" itemprop="url">（转阮一峰）深入理解OAuth 2.0</a>
        </h2>

        <div class="post-meta">

         
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-06-29 08:51:00" itemprop="dateCreated datePublished" datetime="2018-06-29T08:51:00+08:00">2018-06-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-14 17:52:26" itemprop="dateModified" datetime="2021-05-14T17:52:26+08:00">2021-05-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%8D%9A%E5%AE%A2/" itemprop="url" rel="index"><span itemprop="name">博客</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%8D%9A%E5%AE%A2/jqpeng/" itemprop="url" rel="index"><span itemprop="name">jqpeng</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>7.2k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>7 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>文章作者:jqpeng<br>原文链接: <a target="_blank" rel="noopener" href="https://www.cnblogs.com/xiaoqi/p/9241712.html">（转阮一峰）深入理解OAuth 2.0</a></p>
<p><a target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/OAuth">OAuth</a>是一个关于授权（authorization）的开放网络标准，在全世界得到广泛应用，目前的版本是2.0版。</p>
<p>本文对OAuth 2.0的设计思路和运行流程，做一个简明通俗的解释，主要参考材料为<a target="_blank" rel="noopener" href="http://www.rfcreader.com/#rfc6749">RFC 6749</a>。</p>
<p><img src="http://www.ruanyifeng.com/blogimg/asset/2014/bg2014051201.png" alt="OAuth Logo"></p>
<h2 id="一、应用场景"><a href="#一、应用场景" class="headerlink" title="一、应用场景"></a>一、应用场景</h2><p>为了理解OAuth的适用场合，让我举一个假设的例子。</p>
<p>有一个”云冲印”的网站，可以将用户储存在Google的照片，冲印出来。用户为了使用该服务，必须让”云冲印”读取自己储存在Google上的照片。</p>
<p><img src="http://www.ruanyifeng.com/blogimg/asset/2014/bg2014051202.png" alt="云冲印"></p>
<p>问题是只有得到用户的授权，Google才会同意”云冲印”读取这些照片。那么，”云冲印”怎样获得用户的授权呢？</p>
<p>传统方法是，用户将自己的Google用户名和密码，告诉”云冲印”，后者就可以读取用户的照片了。这样的做法有以下几个严重的缺点。</p>
<blockquote>
<p>（1）”云冲印”为了后续的服务，会保存用户的密码，这样很不安全。</p>
<p>（2）Google不得不部署密码登录，而我们知道，单纯的密码登录并不安全。</p>
<p>（3）”云冲印”拥有了获取用户储存在Google所有资料的权力，用户没法限制”云冲印”获得授权的范围和有效期。</p>
<p>（4）用户只有修改密码，才能收回赋予”云冲印”的权力。但是这样做，会使得其他所有获得用户授权的第三方应用程序全部失效。</p>
<p>（5）只要有一个第三方应用程序被破解，就会导致用户密码泄漏，以及所有被密码保护的数据泄漏。</p>
</blockquote>
<p>OAuth就是为了解决上面这些问题而诞生的。</p>
<h2 id="二、名词定义"><a href="#二、名词定义" class="headerlink" title="二、名词定义"></a>二、名词定义</h2><p>在详细讲解OAuth 2.0之前，需要了解几个专用名词。它们对读懂后面的讲解，尤其是几张图，至关重要。</p>
<blockquote>
<p>（1） <strong>Third-party application</strong>：第三方应用程序，本文中又称”客户端”（client），即上一节例子中的”云冲印”。</p>
<p>（2）<strong>HTTP service</strong>：HTTP服务提供商，本文中简称”服务提供商”，即上一节例子中的Google。</p>
<p>（3）<strong>Resource Owner</strong>：资源所有者，本文中又称”用户”（user）。</p>
<p>（4）<strong>User Agent</strong>：用户代理，本文中就是指浏览器。</p>
<p>（5）<strong>Authorization server</strong>：认证服务器，即服务提供商专门用来处理认证的服务器。</p>
<p>（6）<strong>Resource server</strong>：资源服务器，即服务提供商存放用户生成的资源的服务器。它与认证服务器，可以是同一台服务器，也可以是不同的服务器。</p>
</blockquote>
<p>知道了上面这些名词，就不难理解，OAuth的作用就是让”客户端”安全可控地获取”用户”的授权，与”服务商提供商”进行互动。</p>
<h2 id="三、OAuth的思路"><a href="#三、OAuth的思路" class="headerlink" title="三、OAuth的思路"></a>三、OAuth的思路</h2><p>OAuth在”客户端”与”服务提供商”之间，设置了一个授权层（authorization layer）。”客户端”不能直接登录”服务提供商”，只能登录授权层，以此将用户与客户端区分开来。”客户端”登录授权层所用的令牌（token），与用户的密码不同。用户可以在登录的时候，指定授权层令牌的权限范围和有效期。</p>
<p>“客户端”登录授权层以后，”服务提供商”根据令牌的权限范围和有效期，向”客户端”开放用户储存的资料。</p>
<h2 id="四、运行流程"><a href="#四、运行流程" class="headerlink" title="四、运行流程"></a>四、运行流程</h2><p>OAuth 2.0的运行流程如下图，摘自RFC 6749。</p>
<p><img src="http://www.ruanyifeng.com/blogimg/asset/2014/bg2014051203.png" alt="OAuth运行流程"></p>
<blockquote>
<p>（A）用户打开客户端以后，客户端要求用户给予授权。</p>
<p>（B）用户同意给予客户端授权。</p>
<p>（C）客户端使用上一步获得的授权，向认证服务器申请令牌。</p>
<p>（D）认证服务器对客户端进行认证以后，确认无误，同意发放令牌。</p>
<p>（E）客户端使用令牌，向资源服务器申请获取资源。</p>
<p>（F）资源服务器确认令牌无误，同意向客户端开放资源。</p>
</blockquote>
<p>不难看出来，上面六个步骤之中，B是关键，即用户怎样才能给于客户端授权。有了这个授权以后，客户端就可以获取令牌，进而凭令牌获取资源。</p>
<p>下面一一讲解客户端获取授权的四种模式。</p>
<h2 id="五、客户端的授权模式"><a href="#五、客户端的授权模式" class="headerlink" title="五、客户端的授权模式"></a>五、客户端的授权模式</h2><p>客户端必须得到用户的授权（authorization grant），才能获得令牌（access token）。OAuth 2.0定义了四种授权方式。</p>
<ul>
<li>授权码模式（authorization code）</li>
<li>简化模式（implicit）</li>
<li>密码模式（resource owner password credentials）</li>
<li>客户端模式（client credentials）</li>
</ul>
<h2 id="六、授权码模式"><a href="#六、授权码模式" class="headerlink" title="六、授权码模式"></a>六、授权码模式</h2><p>授权码模式（authorization code）是功能最完整、流程最严密的授权模式。它的特点就是通过客户端的后台服务器，与”服务提供商”的认证服务器进行互动。</p>
<p><img src="http://www.ruanyifeng.com/blogimg/asset/2014/bg2014051204.png" alt="授权码模式"></p>
<p>它的步骤如下：</p>
<blockquote>
<p>（A）用户访问客户端，后者将前者导向认证服务器。</p>
<p>（B）用户选择是否给予客户端授权。</p>
<p>（C）假设用户给予授权，认证服务器将用户导向客户端事先指定的”重定向URI”（redirection URI），同时附上一个授权码。</p>
<p>（D）客户端收到授权码，附上早先的”重定向URI”，向认证服务器申请令牌。这一步是在客户端的后台的服务器上完成的，对用户不可见。</p>
<p>（E）认证服务器核对了授权码和重定向URI，确认无误后，向客户端发送访问令牌（access token）和更新令牌（refresh token）。</p>
</blockquote>
<p>下面是上面这些步骤所需要的参数。</p>
<p>A步骤中，客户端申请认证的URI，包含以下参数：</p>
<ul>
<li>response_type：表示授权类型，必选项，此处的值固定为”code”</li>
<li>client_id：表示客户端的ID，必选项</li>
<li>redirect_uri：表示重定向URI，可选项</li>
<li>scope：表示申请的权限范围，可选项</li>
<li>state：表示客户端的当前状态，可以指定任意值，认证服务器会原封不动地返回这个值。</li>
</ul>
<p>下面是一个例子。</p>
<blockquote>
<p>GET /authorize?response_type=code&amp;client_id=s6BhdRkqt3&amp;state=xyz<br>            &amp;redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb HTTP/1.1<br>    Host: server.example.com</p>
</blockquote>
<p>C步骤中，服务器回应客户端的URI，包含以下参数：</p>
<ul>
<li>code：表示授权码，必选项。该码的有效期应该很短，通常设为10分钟，客户端只能使用该码一次，否则会被授权服务器拒绝。该码与客户端ID和重定向URI，是一一对应关系。</li>
<li>state：如果客户端的请求中包含这个参数，认证服务器的回应也必须一模一样包含这个参数。</li>
</ul>
<p>下面是一个例子。</p>
<blockquote>
<p>HTTP/1.1 302 Found<br>    Location: <a target="_blank" rel="noopener" href="https://client.example.com/cb?code=SplxlOBeZQQYbYS6WxSbIA">https://client.example.com/cb?code=SplxlOBeZQQYbYS6WxSbIA</a><br>              &amp;state=xyz</p>
</blockquote>
<p>D步骤中，客户端向认证服务器申请令牌的HTTP请求，包含以下参数：</p>
<ul>
<li>grant_type：表示使用的授权模式，必选项，此处的值固定为”authorization_code”。</li>
<li>code：表示上一步获得的授权码，必选项。</li>
<li>redirect_uri：表示重定向URI，必选项，且必须与A步骤中的该参数值保持一致。</li>
<li>client_id：表示客户端ID，必选项。</li>
</ul>
<p>下面是一个例子。</p>
<blockquote>
<p>POST /token HTTP/1.1<br>    Host: server.example.com<br>    Authorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW<br>    Content-Type: application/x-www-form-urlencoded</p>
<pre><code>grant_type=authorization_code&amp;code=SplxlOBeZQQYbYS6WxSbIA
&amp;redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb
</code></pre>
</blockquote>
<p>E步骤中，认证服务器发送的HTTP回复，包含以下参数：</p>
<ul>
<li>access_token：表示访问令牌，必选项。</li>
<li>token_type：表示令牌类型，该值大小写不敏感，必选项，可以是bearer类型或mac类型。</li>
<li>expires_in：表示过期时间，单位为秒。如果省略该参数，必须其他方式设置过期时间。</li>
<li>refresh_token：表示更新令牌，用来获取下一次的访问令牌，可选项。</li>
<li>scope：表示权限范围，如果与客户端申请的范围一致，此项可省略。</li>
</ul>
<p>下面是一个例子。</p>
<blockquote>
<p>HTTP/1.1 200 OK<br>         Content-Type: application/json;charset=UTF-8<br>         Cache-Control: no-store<br>         Pragma: no-cache</p>
<pre><code>     &#123;
       &quot;access_token&quot;:&quot;2YotnFZFEjr1zCsicMWpAA&quot;,
       &quot;token_type&quot;:&quot;example&quot;,
       &quot;expires_in&quot;:3600,
       &quot;refresh_token&quot;:&quot;tGzv3JOkF0XG5Qx2TlKWIA&quot;,
       &quot;example_parameter&quot;:&quot;example_value&quot;
     &#125;
</code></pre>
</blockquote>
<p>从上面代码可以看到，相关参数使用JSON格式发送（Content-Type: application/json）。此外，HTTP头信息中明确指定不得缓存。</p>
<h2 id="七、简化模式"><a href="#七、简化模式" class="headerlink" title="七、简化模式"></a>七、简化模式</h2><p>简化模式（implicit grant type）不通过第三方应用程序的服务器，直接在浏览器中向认证服务器申请令牌，跳过了”授权码”这个步骤，因此得名。所有步骤在浏览器中完成，令牌对访问者是可见的，且客户端不需要认证。</p>
<p><img src="http://www.ruanyifeng.com/blogimg/asset/2014/bg2014051205.png" alt="简化模式"></p>
<p>它的步骤如下：</p>
<blockquote>
<p>（A）客户端将用户导向认证服务器。</p>
<p>（B）用户决定是否给于客户端授权。</p>
<p>（C）假设用户给予授权，认证服务器将用户导向客户端指定的”重定向URI”，并在URI的Hash部分包含了访问令牌。</p>
<p>（D）浏览器向资源服务器发出请求，其中不包括上一步收到的Hash值。</p>
<p>（E）资源服务器返回一个网页，其中包含的代码可以获取Hash值中的令牌。</p>
<p>（F）浏览器执行上一步获得的脚本，提取出令牌。</p>
<p>（G）浏览器将令牌发给客户端。</p>
</blockquote>
<p>下面是上面这些步骤所需要的参数。</p>
<p>A步骤中，客户端发出的HTTP请求，包含以下参数：</p>
<ul>
<li>response_type：表示授权类型，此处的值固定为”token”，必选项。</li>
<li>client_id：表示客户端的ID，必选项。</li>
<li>redirect_uri：表示重定向的URI，可选项。</li>
<li>scope：表示权限范围，可选项。</li>
<li>state：表示客户端的当前状态，可以指定任意值，认证服务器会原封不动地返回这个值。</li>
</ul>
<p>下面是一个例子。</p>
<blockquote>
<p>GET /authorize?response_type=token&amp;client_id=s6BhdRkqt3&amp;state=xyz<br>            &amp;redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb HTTP/1.1<br>        Host: server.example.com</p>
</blockquote>
<p>C步骤中，认证服务器回应客户端的URI，包含以下参数：</p>
<ul>
<li>access_token：表示访问令牌，必选项。</li>
<li>token_type：表示令牌类型，该值大小写不敏感，必选项。</li>
<li>expires_in：表示过期时间，单位为秒。如果省略该参数，必须其他方式设置过期时间。</li>
<li>scope：表示权限范围，如果与客户端申请的范围一致，此项可省略。</li>
<li>state：如果客户端的请求中包含这个参数，认证服务器的回应也必须一模一样包含这个参数。</li>
</ul>
<p>下面是一个例子。</p>
<blockquote>
<p>HTTP/1.1 302 Found<br>         Location: <a target="_blank" rel="noopener" href="http://example.com/cb#access_token=2YotnFZFEjr1zCsicMWpAA">http://example.com/cb#access_token=2YotnFZFEjr1zCsicMWpAA</a><br>                   &amp;state=xyz&amp;token_type=example&amp;expires_in=3600</p>
</blockquote>
<p>在上面的例子中，认证服务器用HTTP头信息的Location栏，指定浏览器重定向的网址。注意，在这个网址的Hash部分包含了令牌。</p>
<p>根据上面的D步骤，下一步浏览器会访问Location指定的网址，但是Hash部分不会发送。接下来的E步骤，服务提供商的资源服务器发送过来的代码，会提取出Hash中的令牌。</p>
<h2 id="八、密码模式"><a href="#八、密码模式" class="headerlink" title="八、密码模式"></a>八、密码模式</h2><p>密码模式（Resource Owner Password Credentials Grant）中，用户向客户端提供自己的用户名和密码。客户端使用这些信息，向”服务商提供商”索要授权。</p>
<p>在这种模式中，用户必须把自己的密码给客户端，但是客户端不得储存密码。这通常用在用户对客户端高度信任的情况下，比如客户端是操作系统的一部分，或者由一个著名公司出品。而认证服务器只有在其他授权模式无法执行的情况下，才能考虑使用这种模式。</p>
<p><img src="http://www.ruanyifeng.com/blogimg/asset/2014/bg2014051206.png" alt="密码模式"></p>
<p>它的步骤如下：</p>
<blockquote>
<p>（A）用户向客户端提供用户名和密码。</p>
<p>（B）客户端将用户名和密码发给认证服务器，向后者请求令牌。</p>
<p>（C）认证服务器确认无误后，向客户端提供访问令牌。</p>
</blockquote>
<p>B步骤中，客户端发出的HTTP请求，包含以下参数：</p>
<ul>
<li>grant_type：表示授权类型，此处的值固定为”password”，必选项。</li>
<li>username：表示用户名，必选项。</li>
<li>password：表示用户的密码，必选项。</li>
<li>scope：表示权限范围，可选项。</li>
</ul>
<p>下面是一个例子。</p>
<blockquote>
<p>POST /token HTTP/1.1<br>         Host: server.example.com<br>         Authorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW<br>         Content-Type: application/x-www-form-urlencoded</p>
<pre><code>     grant_type=password&amp;username=johndoe&amp;password=A3ddj3w
</code></pre>
</blockquote>
<p>C步骤中，认证服务器向客户端发送访问令牌，下面是一个例子。</p>
<blockquote>
<p>HTTP/1.1 200 OK<br>         Content-Type: application/json;charset=UTF-8<br>         Cache-Control: no-store<br>         Pragma: no-cache</p>
<pre><code>     &#123;
       &quot;access_token&quot;:&quot;2YotnFZFEjr1zCsicMWpAA&quot;,
       &quot;token_type&quot;:&quot;example&quot;,
       &quot;expires_in&quot;:3600,
       &quot;refresh_token&quot;:&quot;tGzv3JOkF0XG5Qx2TlKWIA&quot;,
       &quot;example_parameter&quot;:&quot;example_value&quot;
     &#125;
</code></pre>
</blockquote>
<p>上面代码中，各个参数的含义参见《授权码模式》一节。</p>
<p>整个过程中，客户端不得保存用户的密码。</p>
<h2 id="九、客户端模式"><a href="#九、客户端模式" class="headerlink" title="九、客户端模式"></a>九、客户端模式</h2><p>客户端模式（Client Credentials Grant）指客户端以自己的名义，而不是以用户的名义，向”服务提供商”进行认证。严格地说，客户端模式并不属于OAuth框架所要解决的问题。在这种模式中，用户直接向客户端注册，客户端以自己的名义要求”服务提供商”提供服务，其实不存在授权问题。</p>
<p><img src="http://www.ruanyifeng.com/blogimg/asset/2014/bg2014051207.png" alt="客户端模式"></p>
<p>它的步骤如下：</p>
<blockquote>
<p>（A）客户端向认证服务器进行身份认证，并要求一个访问令牌。</p>
<p>（B）认证服务器确认无误后，向客户端提供访问令牌。</p>
</blockquote>
<p>A步骤中，客户端发出的HTTP请求，包含以下参数：</p>
<ul>
<li>grant_type：表示授权类型，此处的值固定为”client_credentials”，必选项。</li>
<li>scope：表示权限范围，可选项。</li>
</ul>
<blockquote>
<p>POST /token HTTP/1.1<br>         Host: server.example.com<br>         Authorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW<br>         Content-Type: application/x-www-form-urlencoded</p>
<pre><code>     grant_type=client_credentials
</code></pre>
</blockquote>
<p>认证服务器必须以某种方式，验证客户端身份。</p>
<p>B步骤中，认证服务器向客户端发送访问令牌，下面是一个例子。</p>
<blockquote>
<p>HTTP/1.1 200 OK<br>         Content-Type: application/json;charset=UTF-8<br>         Cache-Control: no-store<br>         Pragma: no-cache</p>
<pre><code>     &#123;
       &quot;access_token&quot;:&quot;2YotnFZFEjr1zCsicMWpAA&quot;,
       &quot;token_type&quot;:&quot;example&quot;,
       &quot;expires_in&quot;:3600,
       &quot;example_parameter&quot;:&quot;example_value&quot;
     &#125;
</code></pre>
</blockquote>
<p>上面代码中，各个参数的含义参见《授权码模式》一节。</p>
<h2 id="十、更新令牌"><a href="#十、更新令牌" class="headerlink" title="十、更新令牌"></a>十、更新令牌</h2><p>如果用户访问的时候，客户端的”访问令牌”已经过期，则需要使用”更新令牌”申请一个新的访问令牌。</p>
<p>客户端发出更新令牌的HTTP请求，包含以下参数：</p>
<ul>
<li>grant_type：表示使用的授权模式，此处的值固定为”refresh_token”，必选项。</li>
<li>refresh_token：表示早前收到的更新令牌，必选项。</li>
<li>scope：表示申请的授权范围，不可以超出上一次申请的范围，如果省略该参数，则表示与上一次一致。</li>
</ul>
<p>下面是一个例子。</p>
<blockquote>
<p>POST /token HTTP/1.1<br>         Host: server.example.com<br>         Authorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW<br>         Content-Type: application/x-www-form-urlencoded</p>
<pre><code>     grant_type=refresh_token&amp;refresh_token=tGzv3JOkF0XG5Qx2TlKWIA
</code></pre>
</blockquote>
<p>（完）</p>
<hr>
<p>出处：<a target="_blank" rel="noopener" href="http://www.ruanyifeng.com/2014/05/oauth_2_0.html">http://www.ruanyifeng.com/2014/05/oauth_2_0.html</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://blog.iflyresearch.com/2018/06/14/jqpeng-%E5%9F%BA%E4%BA%8Espring%20security%20%E5%AE%9E%E7%8E%B0%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E9%A1%B9%E7%9B%AE%E6%9D%83%E9%99%90%E6%8E%A7%E5%88%B6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="JadePeng">
      <meta itemprop="description" content="JadePeng的技术笔记本">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JadePeng的技术笔记本">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/06/14/jqpeng-%E5%9F%BA%E4%BA%8Espring%20security%20%E5%AE%9E%E7%8E%B0%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E9%A1%B9%E7%9B%AE%E6%9D%83%E9%99%90%E6%8E%A7%E5%88%B6/" class="post-title-link" itemprop="url">基于spring security 实现前后端分离项目权限控制</a>
        </h2>

        <div class="post-meta">

         
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-06-14 09:04:00" itemprop="dateCreated datePublished" datetime="2018-06-14T09:04:00+08:00">2018-06-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-14 17:52:26" itemprop="dateModified" datetime="2021-05-14T17:52:26+08:00">2021-05-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%8D%9A%E5%AE%A2/" itemprop="url" rel="index"><span itemprop="name">博客</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%8D%9A%E5%AE%A2/jqpeng/" itemprop="url" rel="index"><span itemprop="name">jqpeng</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>11k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>10 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>文章作者:jqpeng<br>原文链接: <a target="_blank" rel="noopener" href="https://www.cnblogs.com/xiaoqi/p/spring-security-usage.html">基于spring security 实现前后端分离项目权限控制</a></p>
<p>前后端分离的项目，前端有菜单（menu），后端有API（backendApi），一个menu对应的页面有N个API接口来支持，本文介绍如何基于spring security实现前后端的同步权限控制。</p>
<h2 id="实现思路"><a href="#实现思路" class="headerlink" title="实现思路"></a>实现思路</h2><p>还是基于Role来实现，具体的思路是，一个Role拥有多个Menu，一个menu有多个backendApi，其中Role和menu，以及menu和backendApi都是ManyToMany关系。</p>
<p>验证授权也很简单，用户登陆系统时，获取Role关联的Menu，页面访问后端API时，再验证下用户是否有访问API的权限。</p>
<h3 id="domain定义"><a href="#domain定义" class="headerlink" title="domain定义"></a>domain定义</h3><p>我们用JPA来实现，先来定义Role</p>
<pre><code>public class Role implements Serializable &#123;


    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;

    /**
     * 名称
     */
    @NotNull
    @ApiModelProperty(value = &quot;名称&quot;, required = true)
    @Column(name = &quot;name&quot;, nullable = false)
    private String name;

    /**
     * 备注
     */
    @ApiModelProperty(value = &quot;备注&quot;)
    @Column(name = &quot;remark&quot;)
    private String remark;

    @JsonIgnore
    @ManyToMany
    @JoinTable(
        name = &quot;role_menus&quot;,
        joinColumns = &#123;@JoinColumn(name = &quot;role_id&quot;, referencedColumnName = &quot;id&quot;)&#125;,
        inverseJoinColumns = &#123;@JoinColumn(name = &quot;menu_id&quot;, referencedColumnName = &quot;id&quot;)&#125;)
    @Cache(usage = CacheConcurrencyStrategy.NONSTRICT_READ_WRITE)
    @BatchSize(size = 100)
    private Set&lt;Menu&gt; menus = new HashSet&lt;&gt;();&#125;
</code></pre>
<p>以及Menu：</p>
<pre><code>public class Menu implements Serializable &#123;


    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;

    @Column(name = &quot;parent_id&quot;)
    private Integer parentId;

    /**
     * 文本
     */
    @ApiModelProperty(value = &quot;文本&quot;)
    @Column(name = &quot;text&quot;)
    private String text;@ApiModelProperty(value = &quot;angular路由&quot;)
    @Column(name = &quot;link&quot;)
    private String link;
    @ManyToMany
    @JsonIgnore
    @JoinTable(name = &quot;backend_api_menus&quot;,
        joinColumns = @JoinColumn(name=&quot;menus_id&quot;, referencedColumnName=&quot;id&quot;),
        inverseJoinColumns = @JoinColumn(name=&quot;backend_apis_id&quot;, referencedColumnName=&quot;id&quot;))
    @Cache(usage = CacheConcurrencyStrategy.NONSTRICT_READ_WRITE)
    private Set&lt;BackendApi&gt; backendApis = new HashSet&lt;&gt;();

    @ManyToMany(mappedBy = &quot;menus&quot;)
    @JsonIgnore
    private Set&lt;Role&gt; roles = new HashSet&lt;&gt;();&#125;
</code></pre>
<p>最后是BackendApi，区分method（HTTP请求方法）、tag（哪一个Controller）和path（API请求路径）：</p>
<pre><code>public class BackendApi implements Serializable &#123;

    private static final long serialVersionUID = 1L;

    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;

    @Column(name = &quot;tag&quot;)
    private String tag;

    @Column(name = &quot;path&quot;)
    private String path;

    @Column(name = &quot;method&quot;)
    private String method;

    @Column(name = &quot;summary&quot;)
    private String summary;

    @Column(name = &quot;operation_id&quot;)
    private String operationId;

    @ManyToMany(mappedBy = &quot;backendApis&quot;)
    @Cache(usage = CacheConcurrencyStrategy.NONSTRICT_READ_WRITE)
    private Set&lt;Menu&gt; menus = new HashSet&lt;&gt;();&#125;
</code></pre>
<h2 id="管理页面实现"><a href="#管理页面实现" class="headerlink" title="管理页面实现"></a>管理页面实现</h2><p>Menu菜单是业务需求确定的，因此提供CRUD编辑即可。<br> BackendAPI，可以通过swagger来获取。<br> 前端选择ng-algin，参见<a target="_blank" rel="noopener" href="https://www.cnblogs.com/xiaoqi/p/angular-ng-alain.html">Angular 中后台前端解决方案 - Ng Alain 介绍</a></p>
<h3 id="通过swagger获取BackendAPI"><a href="#通过swagger获取BackendAPI" class="headerlink" title="通过swagger获取BackendAPI"></a>通过swagger获取BackendAPI</h3><p>获取swagger api有多种方法，最简单的就是访问http接口获取json，然后解析，这很简单，这里不赘述，还有一种就是直接调用相关API获取Swagger对象。</p>
<p>查看官方的web代码，可以看到获取数据大概是这样的：</p>
<pre><code>        String groupName = Optional.fromNullable(swaggerGroup).or(Docket.DEFAULT_GROUP_NAME);
        Documentation documentation = documentationCache.documentationByGroup(groupName);
        if (documentation == null) &#123;
            return new ResponseEntity&lt;Json&gt;(HttpStatus.NOT_FOUND);
        &#125;
        Swagger swagger = mapper.mapDocumentation(documentation);
        UriComponents uriComponents = componentsFrom(servletRequest, swagger.getBasePath());
        swagger.basePath(Strings.isNullOrEmpty(uriComponents.getPath()) ? &quot;/&quot; : uriComponents.getPath());
        if (isNullOrEmpty(swagger.getHost())) &#123;
            swagger.host(hostName(uriComponents));
        &#125;
        return new ResponseEntity&lt;Json&gt;(jsonSerializer.toJson(swagger), HttpStatus.OK);
</code></pre>
<p>其中的documentationCache、environment、mapper等可以直接Autowired获得：</p>
<pre><code>@Autowired
    public SwaggerResource(
        Environment environment,
        DocumentationCache documentationCache,
        ServiceModelToSwagger2Mapper mapper,
        BackendApiRepository backendApiRepository,
        JsonSerializer jsonSerializer) &#123;

        this.hostNameOverride = environment.getProperty(&quot;springfox.documentation.swagger.v2.host&quot;, &quot;DEFAULT&quot;);
        this.documentationCache = documentationCache;
        this.mapper = mapper;
        this.jsonSerializer = jsonSerializer;

        this.backendApiRepository = backendApiRepository;

    &#125;
</code></pre>
<p>然后我们自动加载就简单了，写一个updateApi接口，读取swagger对象，然后解析成BackendAPI，存储到数据库：</p>
<pre><code>@RequestMapping(
        value = &quot;/api/updateApi&quot;,
        method = RequestMethod.GET,
        produces = &#123; APPLICATION_JSON_VALUE, HAL_MEDIA_TYPE &#125;)
    @PropertySourcedMapping(
        value = &quot;$&#123;springfox.documentation.swagger.v2.path&#125;&quot;,
        propertyKey = &quot;springfox.documentation.swagger.v2.path&quot;)
    @ResponseBody
    public ResponseEntity&lt;Json&gt; updateApi(
        @RequestParam(value = &quot;group&quot;, required = false) String swaggerGroup) &#123;

        // 加载已有的api
        Map&lt;String,Boolean&gt; apiMap = Maps.newHashMap();
        List&lt;BackendApi&gt; apis = backendApiRepository.findAll();
        apis.stream().forEach(api-&gt;apiMap.put(api.getPath()+api.getMethod(),true));

        // 获取swagger
        String groupName = Optional.fromNullable(swaggerGroup).or(Docket.DEFAULT_GROUP_NAME);
        Documentation documentation = documentationCache.documentationByGroup(groupName);
        if (documentation == null) &#123;
            return new ResponseEntity&lt;Json&gt;(HttpStatus.NOT_FOUND);
        &#125;
        Swagger swagger = mapper.mapDocumentation(documentation);

        // 加载到数据库
        for(Map.Entry&lt;String, Path&gt; item : swagger.getPaths().entrySet())&#123;
            String path = item.getKey();
            Path pathInfo = item.getValue();
            createApiIfNeeded(apiMap, path,  pathInfo.getGet(), HttpMethod.GET.name());
            createApiIfNeeded(apiMap, path,  pathInfo.getPost(), HttpMethod.POST.name());
            createApiIfNeeded(apiMap, path,  pathInfo.getDelete(), HttpMethod.DELETE.name());
            createApiIfNeeded(apiMap, path,  pathInfo.getPut(), HttpMethod.PUT.name());
        &#125;
        return new ResponseEntity&lt;Json&gt;(HttpStatus.OK);
    &#125;
</code></pre>
<p>其中createApiIfNeeded，先判断下是否存在，不存在的则新增：</p>
<pre><code> private void createApiIfNeeded(Map&lt;String, Boolean&gt; apiMap, String path, Operation operation, String method) &#123;
        if(operation==null) &#123;
            return;
        &#125;
        if(!apiMap.containsKey(path+ method))&#123;
            apiMap.put(path+ method,true);

            BackendApi api = new BackendApi();
            api.setMethod( method);
            api.setOperationId(operation.getOperationId());
            api.setPath(path);
            api.setTag(operation.getTags().get(0));
            api.setSummary(operation.getSummary());

            // 保存
            this.backendApiRepository.save(api);
        &#125;
    &#125;
</code></pre>
<p>最后，做一个简单页面展示即可：</p>
<p><img src="https://gitee.com/jadepeng/blogpic/raw/master/pic/2018/1528886480360.jpg" alt="enter description here" title="1528886480360"></p>
<h3 id="菜单管理"><a href="#菜单管理" class="headerlink" title="菜单管理"></a>菜单管理</h3><p>新增和修改页面，可以选择上级菜单，后台API做成按tag分组，可多选即可：</p>
<p><img src="https://gitee.com/jadepeng/blogpic/raw/master/pic/2018/1528886647893.jpg" alt="enter description here" title="1528886647893"></p>
<p>列表页面</p>
<p><img src="https://gitee.com/jadepeng/blogpic/raw/master/pic/2018/1528886586348.jpg" alt="enter description here" title="1528886586348"></p>
<h3 id="角色管理"><a href="#角色管理" class="headerlink" title="角色管理"></a>角色管理</h3><p>普通的CRUD，最主要的增加一个菜单授权页面，菜单按层级显示即可：</p>
<p><img src="https://gitee.com/jadepeng/blogpic/raw/master/pic/2018/1528886692091.jpg" alt="enter description here" title="1528886692091"></p>
<h2 id="认证实现"><a href="#认证实现" class="headerlink" title="认证实现"></a>认证实现</h2><p>管理页面可以做成千奇百样，最核心的还是如何实现认证。</p>
<p>在上一篇文章<a target="_blank" rel="noopener" href="https://www.cnblogs.com/xiaoqi/p/spring-security-rabc.html">spring security实现动态配置url权限的两种方法</a>里我们说了，可以自定义<code>FilterInvocationSecurityMetadataSource</code>来实现。</p>
<p>实现<code>FilterInvocationSecurityMetadataSource</code>接口即可，核心是根据FilterInvocation的Request的method和path，获取对应的Role，然后交给RoleVoter去判断是否有权限。</p>
<h3 id="自定义FilterInvocationSecurityMetadataSource"><a href="#自定义FilterInvocationSecurityMetadataSource" class="headerlink" title="自定义FilterInvocationSecurityMetadataSource"></a>自定义FilterInvocationSecurityMetadataSource</h3><p>我们新建一个DaoSecurityMetadataSource实现FilterInvocationSecurityMetadataSource接口，主要看getAttributes方法：</p>
<pre><code>     @Override
    public Collection&lt;ConfigAttribute&gt; getAttributes(Object object) throws IllegalArgumentException &#123;
        FilterInvocation fi = (FilterInvocation) object;

        List&lt;Role&gt; neededRoles = this.getRequestNeededRoles(fi.getRequest().getMethod(), fi.getRequestUrl());

        if (neededRoles != null) &#123;
            return SecurityConfig.createList(neededRoles.stream().map(role -&gt; role.getName()).collect(Collectors.toList()).toArray(new String[]&#123;&#125;));
        &#125;

        //  返回默认配置
        return superMetadataSource.getAttributes(object);
    &#125;
</code></pre>
<p>核心是getRequestNeededRoles怎么实现，获取到干净的RequestUrl（去掉参数）,然后看是否有对应的backendAPI，如果没有，则有可能该API有path参数，我们可以去掉最后的path，去库里模糊匹配，直到找到。</p>
<pre><code> public List&lt;Role&gt; getRequestNeededRoles(String method, String path) &#123;
        String rawPath = path;
        //  remove parameters
        if(path.indexOf(&quot;?&quot;)&gt;-1)&#123;
            path = path.substring(0,path.indexOf(&quot;?&quot;));
        &#125;
        // /menus/&#123;id&#125;
        BackendApi api = backendApiRepository.findByPathAndMethod(path, method);
        if (api == null)&#123;
            // try fetch by remove last path
            api = loadFromSimilarApi(method, path, rawPath);
        &#125;

        if (api != null &amp;&amp; api.getMenus().size() &gt; 0) &#123;
            return api.getMenus()
                .stream()
                .flatMap(menu -&gt; menuRepository.findOneWithRolesById(menu.getId()).getRoles().stream())
                .collect(Collectors.toList());
        &#125;
        return null;
    &#125;

    private BackendApi loadFromSimilarApi(String method, String path, String rawPath) &#123;
        if(path.lastIndexOf(&quot;/&quot;)&gt;-1)&#123;
            path = path.substring(0,path.lastIndexOf(&quot;/&quot;));
            List&lt;BackendApi&gt; apis = backendApiRepository.findByPathStartsWithAndMethod(path, method);

            // 如果为空，再去掉一层path
            while(apis==null)&#123;
                if(path.lastIndexOf(&quot;/&quot;)&gt;-1) &#123;
                    path = path.substring(0, path.lastIndexOf(&quot;/&quot;));
                    apis = backendApiRepository.findByPathStartsWithAndMethod(path, method);
                &#125;else&#123;
                    break;
                &#125;
            &#125;

            if(apis!=null)&#123;
                for(BackendApi backendApi : apis)&#123;
                    if (antPathMatcher.match(backendApi.getPath(), rawPath)) &#123;
                        return backendApi;
                    &#125;
                &#125;
            &#125;
        &#125;
        return null;
    &#125;
</code></pre>
<p>其中，BackendApiRepository：</p>
<pre><code>    @EntityGraph(attributePaths = &quot;menus&quot;)
    BackendApi findByPathAndMethod(String path,String method);

    @EntityGraph(attributePaths = &quot;menus&quot;)
    List&lt;BackendApi&gt; findByPathStartsWithAndMethod(String path,String method);
</code></pre>
<p>以及MenuRepository</p>
<pre><code>    @EntityGraph(attributePaths = &quot;roles&quot;)
    Menu findOneWithRolesById(long id);
</code></pre>
<h3 id="使用DaoSecurityMetadataSource"><a href="#使用DaoSecurityMetadataSource" class="headerlink" title="使用DaoSecurityMetadataSource"></a>使用DaoSecurityMetadataSource</h3><p>需要注意的是，在DaoSecurityMetadataSource里，不能直接注入Repository，我们可以给DaoSecurityMetadataSource添加一个方法，方便传入：</p>
<pre><code>   public void init(MenuRepository menuRepository, BackendApiRepository backendApiRepository) &#123;
        this.menuRepository = menuRepository;
        this.backendApiRepository = backendApiRepository;
    &#125;
</code></pre>
<p>然后建立一个容器，存储实例化的DaoSecurityMetadataSource，我们可以建立如下的ApplicationContext来作为对象容器，存取对象：</p>
<pre><code>public class ApplicationContext &#123;
    static Map&lt;Class&lt;?&gt;,Object&gt; beanMap = Maps.newConcurrentMap();

    public static &lt;T&gt; T getBean(Class&lt;T&gt; requireType)&#123;
        return (T) beanMap.get(requireType);
    &#125;

    public static void registerBean(Object item)&#123;
        beanMap.put(item.getClass(),item);
    &#125;
&#125;
</code></pre>
<p>在SecurityConfiguration配置中使用<code>DaoSecurityMetadataSource</code>，并通过<code> ApplicationContext.registerBean</code>将<code>DaoSecurityMetadataSource</code>注册：</p>
<pre><code> @Override
    protected void configure(HttpSecurity http) throws Exception &#123;
        http
            .addFilterBefore(corsFilter, UsernamePasswordAuthenticationFilter.class)
            .exceptionHandling()
            .authenticationEntryPoint(problemSupport)
            .accessDeniedHandler(problemSupport)        ....
           // .withObjectPostProcessor()
            // 自定义accessDecisionManager
            .accessDecisionManager(accessDecisionManager())
            // 自定义FilterInvocationSecurityMetadataSource
            .withObjectPostProcessor(new ObjectPostProcessor&lt;FilterSecurityInterceptor&gt;() &#123;
                @Override
                public &lt;O extends FilterSecurityInterceptor&gt; O postProcess(
                    O fsi) &#123;
                    fsi.setSecurityMetadataSource(daoSecurityMetadataSource(fsi.getSecurityMetadataSource()));
                    return fsi;
                &#125;
            &#125;)
        .and()
            .apply(securityConfigurerAdapter());

    &#125;

    @Bean
    public DaoSecurityMetadataSource daoSecurityMetadataSource(FilterInvocationSecurityMetadataSource filterInvocationSecurityMetadataSource) &#123;
        DaoSecurityMetadataSource securityMetadataSource = new DaoSecurityMetadataSource(filterInvocationSecurityMetadataSource);
        ApplicationContext.registerBean(securityMetadataSource);
        return securityMetadataSource;
    &#125;
</code></pre>
<p>最后，在程序启动后，通过<code>ApplicationContext.getBean</code>获取到daoSecurityMetadataSource，然后调用init注入Repository</p>
<pre><code> public static void postInit()&#123;
        ApplicationContext
            .getBean(DaoSecurityMetadataSource.class)
 .init(applicationContext.getBean(MenuRepository.class),applicationContext.getBean(BackendApiRepository.class));
    &#125;

    static ConfigurableApplicationContext applicationContext;

    public static void main(String[] args) throws UnknownHostException &#123;
        SpringApplication app = new SpringApplication(UserCenterApp.class);
        DefaultProfileUtil.addDefaultProfile(app);
        applicationContext = app.run(args);

        // 后初始化
        postInit();
&#125;
</code></pre>
<p>大功告成！</p>
<h2 id="延伸阅读"><a href="#延伸阅读" class="headerlink" title="延伸阅读"></a>延伸阅读</h2><ul>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/xiaoqi/p/spring-security-rabc.html">spring security实现动态配置url权限的两种方法</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/xiaoqi/p/spring-security.html">Spring Security 架构与源码分析</a></li>
</ul>
<hr>
<blockquote>
<p>作者：Jadepeng<br> 出处：jqpeng的技术记事本–<a target="_blank" rel="noopener" href="http://www.cnblogs.com/xiaoqi">http://www.cnblogs.com/xiaoqi</a><br> 您的支持是对博主最大的鼓励，感谢您的认真阅读。<br> 本文版权归作者所有，欢迎转载，但未经作者同意必须保留此段声明，且在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。</p>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://blog.iflyresearch.com/2018/06/07/jqpeng-spring%20security%E5%AE%9E%E7%8E%B0%E5%8A%A8%E6%80%81%E9%85%8D%E7%BD%AEurl%E6%9D%83%E9%99%90%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="JadePeng">
      <meta itemprop="description" content="JadePeng的技术笔记本">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JadePeng的技术笔记本">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/06/07/jqpeng-spring%20security%E5%AE%9E%E7%8E%B0%E5%8A%A8%E6%80%81%E9%85%8D%E7%BD%AEurl%E6%9D%83%E9%99%90%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95/" class="post-title-link" itemprop="url">spring security实现动态配置url权限的两种方法</a>
        </h2>

        <div class="post-meta">

         
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-06-07 15:33:00" itemprop="dateCreated datePublished" datetime="2018-06-07T15:33:00+08:00">2018-06-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-14 17:52:26" itemprop="dateModified" datetime="2021-05-14T17:52:26+08:00">2021-05-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%8D%9A%E5%AE%A2/" itemprop="url" rel="index"><span itemprop="name">博客</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%8D%9A%E5%AE%A2/jqpeng/" itemprop="url" rel="index"><span itemprop="name">jqpeng</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>9.3k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>8 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>文章作者:jqpeng<br>原文链接: <a target="_blank" rel="noopener" href="https://www.cnblogs.com/xiaoqi/p/spring-security-rabc.html">spring security实现动态配置url权限的两种方法</a></p>
<h2 id="缘起"><a href="#缘起" class="headerlink" title="缘起"></a>缘起</h2><p>标准的RABC, 权限需要支持动态配置，spring security默认是在代码里约定好权限，真实的业务场景通常需要可以支持动态配置角色访问权限，即在运行时去配置url对应的访问角色。</p>
<p>基于spring security，如何实现这个需求呢？</p>
<p>最简单的方法就是自定义一个Filter去完成权限判断，但这脱离了spring security框架，如何基于spring security优雅的实现呢？</p>
<h2 id="spring-security-授权回顾"><a href="#spring-security-授权回顾" class="headerlink" title="spring security 授权回顾"></a>spring security 授权回顾</h2><p>spring security 通过FilterChainProxy作为注册到web的filter，FilterChainProxy里面一次包含了内置的多个过滤器，我们首先需要了解spring security内置的各种filter：</p>
<table>
<thead>
<tr>
<th>Alias</th>
<th>Filter Class</th>
<th>Namespace Element or Attribute</th>
</tr>
</thead>
<tbody><tr>
<td>CHANNEL_FILTER</td>
<td>ChannelProcessingFilter</td>
<td>http/intercept-url@requires-channel</td>
</tr>
<tr>
<td>SECURITY_CONTEXT_FILTER</td>
<td>SecurityContextPersistenceFilter</td>
<td>http</td>
</tr>
<tr>
<td>CONCURRENT_SESSION_FILTER</td>
<td>ConcurrentSessionFilter</td>
<td>session-management/concurrency-control</td>
</tr>
<tr>
<td>HEADERS_FILTER</td>
<td>HeaderWriterFilter</td>
<td>http/headers</td>
</tr>
<tr>
<td>CSRF_FILTER</td>
<td>CsrfFilter</td>
<td>http/csrf</td>
</tr>
<tr>
<td>LOGOUT_FILTER</td>
<td>LogoutFilter</td>
<td>http/logout</td>
</tr>
<tr>
<td>X509_FILTER</td>
<td>X509AuthenticationFilter</td>
<td>http/x509</td>
</tr>
<tr>
<td>PRE_AUTH_FILTER</td>
<td>AbstractPreAuthenticatedProcessingFilter Subclasses</td>
<td>N/A</td>
</tr>
<tr>
<td>CAS_FILTER</td>
<td>CasAuthenticationFilter</td>
<td>N/A</td>
</tr>
<tr>
<td>FORM_LOGIN_FILTER</td>
<td>UsernamePasswordAuthenticationFilter</td>
<td>http/form-login</td>
</tr>
<tr>
<td>BASIC_AUTH_FILTER</td>
<td>BasicAuthenticationFilter</td>
<td>http/http-basic</td>
</tr>
<tr>
<td>SERVLET_API_SUPPORT_FILTER</td>
<td>SecurityContextHolderAwareRequestFilter</td>
<td>http/@servlet-api-provision</td>
</tr>
<tr>
<td>JAAS_API_SUPPORT_FILTER</td>
<td>JaasApiIntegrationFilter</td>
<td>http/@jaas-api-provision</td>
</tr>
<tr>
<td>REMEMBER_ME_FILTER</td>
<td>RememberMeAuthenticationFilter</td>
<td>http/remember-me</td>
</tr>
<tr>
<td>ANONYMOUS_FILTER</td>
<td>AnonymousAuthenticationFilter</td>
<td>http/anonymous</td>
</tr>
<tr>
<td>SESSION_MANAGEMENT_FILTER</td>
<td>SessionManagementFilter</td>
<td>session-management</td>
</tr>
<tr>
<td>EXCEPTION_TRANSLATION_FILTER</td>
<td>ExceptionTranslationFilter</td>
<td>http</td>
</tr>
<tr>
<td>FILTER_SECURITY_INTERCEPTOR</td>
<td>FilterSecurityInterceptor</td>
<td>http</td>
</tr>
<tr>
<td>SWITCH_USER_FILTER</td>
<td>SwitchUserFilter</td>
<td>N/A</td>
</tr>
</tbody></table>
<p>最重要的是<code>FilterSecurityInterceptor</code>，该过滤器实现了主要的鉴权逻辑，最核心的代码在这里：</p>
<pre><code>protected InterceptorStatusToken beforeInvocation(Object object) &#123;    // 获取访问URL所需权限    Collection&lt;ConfigAttribute&gt; attributes = this.obtainSecurityMetadataSource()            .getAttributes(object);
    Authentication authenticated = authenticateIfRequired();
    // 通过accessDecisionManager鉴权    try &#123;        this.accessDecisionManager.decide(authenticated, object, attributes);    &#125;    catch (AccessDeniedException accessDeniedException) &#123;        publishEvent(new AuthorizationFailureEvent(object, attributes, authenticated,                accessDeniedException));
        throw accessDeniedException;    &#125;
    if (debug) &#123;        logger.debug(&quot;Authorization successful&quot;);    &#125;
    if (publishAuthorizationSuccess) &#123;        publishEvent(new AuthorizedEvent(object, attributes, authenticated));    &#125;
    // Attempt to run as a different user    Authentication runAs = this.runAsManager.buildRunAs(authenticated, object,            attributes);
    if (runAs == null) &#123;        if (debug) &#123;            logger.debug(&quot;RunAsManager did not change Authentication object&quot;);        &#125;
        // no further work post-invocation        return new InterceptorStatusToken(SecurityContextHolder.getContext(), false,                attributes, object);    &#125;    else &#123;        if (debug) &#123;            logger.debug(&quot;Switching to RunAs Authentication: &quot; + runAs);        &#125;
        SecurityContext origCtx = SecurityContextHolder.getContext();        SecurityContextHolder.setContext(SecurityContextHolder.createEmptyContext());        SecurityContextHolder.getContext().setAuthentication(runAs);
        // need to revert to token.Authenticated post-invocation        return new InterceptorStatusToken(origCtx, true, attributes, object);    &#125;&#125;
</code></pre>
<p>从上面可以看出，要实现动态鉴权，可以从两方面着手：</p>
<ul>
<li>自定义SecurityMetadataSource，实现从数据库加载ConfigAttribute</li>
<li>另外就是可以自定义accessDecisionManager，官方的UnanimousBased其实足够使用，并且他是基于AccessDecisionVoter来实现权限认证的，因此我们只需要自定义一个AccessDecisionVoter就可以了</li>
</ul>
<p>下面来看分别如何实现。</p>
<h2 id="自定义AccessDecisionManager"><a href="#自定义AccessDecisionManager" class="headerlink" title="自定义AccessDecisionManager"></a>自定义AccessDecisionManager</h2><p>官方的三个AccessDecisionManager都是基于AccessDecisionVoter来实现权限认证的，因此我们只需要自定义一个AccessDecisionVoter就可以了。</p>
<p>自定义主要是实现<code>AccessDecisionVoter</code>接口，我们可以仿照官方的RoleVoter实现一个：</p>
<pre><code>public class RoleBasedVoter implements AccessDecisionVoter&lt;Object&gt; &#123;

    @Override
    public boolean supports(ConfigAttribute attribute) &#123;
        return true;
    &#125;

    @Override
    public int vote(Authentication authentication, Object object, Collection&lt;ConfigAttribute&gt; attributes) &#123;
        if(authentication == null) &#123;
            return ACCESS_DENIED;
        &#125;
        int result = ACCESS_ABSTAIN;
        Collection&lt;? extends GrantedAuthority&gt; authorities = extractAuthorities(authentication);

        for (ConfigAttribute attribute : attributes) &#123;
            if(attribute.getAttribute()==null)&#123;
                continue;
            &#125;
            if (this.supports(attribute)) &#123;
                result = ACCESS_DENIED;

                // Attempt to find a matching granted authority
                for (GrantedAuthority authority : authorities) &#123;
                    if (attribute.getAttribute().equals(authority.getAuthority())) &#123;
                        return ACCESS_GRANTED;
                    &#125;
                &#125;
            &#125;
        &#125;

        return result;
    &#125;

    Collection&lt;? extends GrantedAuthority&gt; extractAuthorities(
        Authentication authentication) &#123;
        return authentication.getAuthorities();
    &#125;

    @Override
    public boolean supports(Class clazz) &#123;
        return true;
    &#125;
&#125;
</code></pre>
<p>如何加入动态权限呢？</p>
<p><code>vote(Authentication authentication, Object object, Collection&lt;ConfigAttribute&gt; attributes) </code>里的<code>Object object</code>的类型是<code>FilterInvocation</code>，可以通过<code>getRequestUrl</code>获取当前请求的URL:</p>
<pre><code>  FilterInvocation fi = (FilterInvocation) object;
  String url = fi.getRequestUrl();
</code></pre>
<p>因此这里扩展空间就大了，可以从DB动态加载，然后判断URL的ConfigAttribute就可以了。</p>
<p>如何使用这个RoleBasedVoter呢？在configure里使用accessDecisionManager方法自定义，我们还是使用官方的<code>UnanimousBased</code>，然后将自定义的RoleBasedVoter加入即可。</p>
<pre><code>@EnableWebSecurity
@EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true)
public class SecurityConfiguration extends WebSecurityConfigurerAdapter &#123;

 
    @Override
    protected void configure(HttpSecurity http) throws Exception &#123;
        http
            .addFilterBefore(corsFilter, UsernamePasswordAuthenticationFilter.class)
            .exceptionHandling()
            .authenticationEntryPoint(problemSupport)
            .accessDeniedHandler(problemSupport)
        .and()
            .csrf()
            .disable()
            .headers()
            .frameOptions()
            .disable()
        .and()
            .sessionManagement()
            .sessionCreationPolicy(SessionCreationPolicy.STATELESS)
        .and()
            .authorizeRequests()
            // 自定义accessDecisionManager
            .accessDecisionManager(accessDecisionManager())
          
        .and()
            .apply(securityConfigurerAdapter());

    &#125;


    @Bean
    public AccessDecisionManager accessDecisionManager() &#123;
        List&lt;AccessDecisionVoter&lt;? extends Object&gt;&gt; decisionVoters
            = Arrays.asList(
            new WebExpressionVoter(),
            // new RoleVoter(),
            new RoleBasedVoter(),
            new AuthenticatedVoter());
        return new UnanimousBased(decisionVoters);
    &#125;
</code></pre>
<h2 id="自定义SecurityMetadataSource"><a href="#自定义SecurityMetadataSource" class="headerlink" title="自定义SecurityMetadataSource"></a>自定义SecurityMetadataSource</h2><p>自定义FilterInvocationSecurityMetadataSource只要实现接口即可，在接口里从DB动态加载规则。</p>
<p>为了复用代码里的定义，我们可以将代码里生成的SecurityMetadataSource带上，在构造函数里传入默认的FilterInvocationSecurityMetadataSource。</p>
<pre><code>public class AppFilterInvocationSecurityMetadataSource implements org.springframework.security.web.access.intercept.FilterInvocationSecurityMetadataSource &#123;

    private FilterInvocationSecurityMetadataSource  superMetadataSource;

    @Override
    public Collection&lt;ConfigAttribute&gt; getAllConfigAttributes() &#123;
        return null;
    &#125;

    public AppFilterInvocationSecurityMetadataSource(FilterInvocationSecurityMetadataSource expressionBasedFilterInvocationSecurityMetadataSource)&#123;
         this.superMetadataSource = expressionBasedFilterInvocationSecurityMetadataSource;

         // TODO 从数据库加载权限配置
    &#125;

    private final AntPathMatcher antPathMatcher = new AntPathMatcher();
    // 这里的需要从DB加载
    private final Map&lt;String,String&gt; urlRoleMap = new HashMap&lt;String,String&gt;()&#123;&#123;
            put("/open/**","ROLE_ANONYMOUS");
            put("/health","ROLE_ANONYMOUS");
            put("/restart","ROLE_ADMIN");
            put("/demo","ROLE_USER");
        &#125;&#125;;

    @Override
    public Collection&lt;ConfigAttribute&gt; getAttributes(Object object) throws IllegalArgumentException &#123;
        FilterInvocation fi = (FilterInvocation) object;
        String url = fi.getRequestUrl();

        for(Map.Entry&lt;String,String&gt; entry:urlRoleMap.entrySet())&#123;
            if(antPathMatcher.match(entry.getKey(),url))&#123;
                return SecurityConfig.createList(entry.getValue());
            &#125;
        &#125;

        //  返回代码定义的默认配置
        return superMetadataSource.getAttributes(object);
    &#125;



    @Override
    public boolean supports(Class&lt;?&gt; clazz) &#123;
        return FilterInvocation.class.isAssignableFrom(clazz);
    &#125;
&#125;
</code></pre>
<p>怎么使用？和<code>accessDecisionManager</code>不一样，<code>ExpressionUrlAuthorizationConfigurer</code> 并没有提供set方法设置<code>FilterSecurityInterceptor</code>的<code>FilterInvocationSecurityMetadataSource</code>，how to do?</p>
<p>发现一个扩展方法<code>withObjectPostProcessor</code>，通过该方法自定义一个处理<code>FilterSecurityInterceptor</code>类型的<code>ObjectPostProcessor</code>就可以修改<code>FilterSecurityInterceptor</code>。</p>
<pre><code>@EnableWebSecurity
@EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true)
public class SecurityConfiguration extends WebSecurityConfigurerAdapter &#123;

 
    @Override
    protected void configure(HttpSecurity http) throws Exception &#123;
        http
            .addFilterBefore(corsFilter, UsernamePasswordAuthenticationFilter.class)
            .exceptionHandling()
            .authenticationEntryPoint(problemSupport)
            .accessDeniedHandler(problemSupport)
        .and()
            .csrf()
            .disable()
            .headers()
            .frameOptions()
            .disable()
        .and()
            .sessionManagement()
            .sessionCreationPolicy(SessionCreationPolicy.STATELESS)
        .and()
            .authorizeRequests()
              // 自定义FilterInvocationSecurityMetadataSource
            .withObjectPostProcessor(new ObjectPostProcessor&lt;FilterSecurityInterceptor&gt;() &#123;
                @Override
                public &lt;O extends FilterSecurityInterceptor&gt; O postProcess(
                    O fsi) &#123;
                    fsi.setSecurityMetadataSource(mySecurityMetadataSource(fsi.getSecurityMetadataSource()));
                    return fsi;
                &#125;
            &#125;)
        .and()
            .apply(securityConfigurerAdapter());

    &#125;


    @Bean
    public AppFilterInvocationSecurityMetadataSource mySecurityMetadataSource(FilterInvocationSecurityMetadataSource filterInvocationSecurityMetadataSource) &#123;
        AppFilterInvocationSecurityMetadataSource securityMetadataSource = new AppFilterInvocationSecurityMetadataSource(filterInvocationSecurityMetadataSource);
        return securityMetadataSource;
&#125;
</code></pre>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文介绍了两种基于spring security实现动态权限的方法，一是自定义accessDecisionManager，二是自定义FilterInvocationSecurityMetadataSource。实际项目里可以根据需要灵活选择。</p>
<p>延伸阅读:</p>
<p><a target="_blank" rel="noopener" href="http://www.cnblogs.com/xiaoqi/p/spring-security.html">Spring Security 架构与源码分析</a></p>
<hr>
<blockquote>
<p>作者：Jadepeng<br> 出处：jqpeng的技术记事本–<a target="_blank" rel="noopener" href="http://www.cnblogs.com/xiaoqi">http://www.cnblogs.com/xiaoqi</a><br> 您的支持是对博主最大的鼓励，感谢您的认真阅读。<br> 本文版权归作者所有，欢迎转载，但未经作者同意必须保留此段声明，且在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。</p>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/6/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><span class="page-number current">7</span><a class="page-number" href="/page/8/">8</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><a class="extend next" rel="next" href="/page/8/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="JadePeng"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">JadePeng</p>
  <div class="site-description" itemprop="description">JadePeng的技术笔记本</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">100</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">87</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">JadePeng</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">644k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">9:45</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>









<script>
document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});
</script>


<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js', () => {
    mermaid.initialize({
      theme    : 'forest',
      logLevel : 3,
      flowchart: { curve     : 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 }
    });
  }, window.mermaid);
}
</script>


  

  

</body>
</html>
